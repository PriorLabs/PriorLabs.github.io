<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/01af0fc7b4278e65-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/3d9ea938b6afa941-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/4f05ba3a6752a328-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/7e6a2e30184bb114-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/ae0a0c671023eecc-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/b4f46b1ccc361ec4-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/vision/title.png"/><link rel="stylesheet" href="/_next/static/css/fe75a68bdb2aebce.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/59f806dbf2a0b375.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/c7be8c723596c368.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-5c4816f6c5350863.js"/><script src="/_next/static/chunks/4bd1b696-226306243a82ccd8.js" async=""></script><script src="/_next/static/chunks/517-7bfa349d4ac79dc7.js" async=""></script><script src="/_next/static/chunks/main-app-72f5dcec58e212af.js" async=""></script><script src="/_next/static/chunks/30a37ab2-b2120806d300c7b3.js" async=""></script><script src="/_next/static/chunks/8e1d74a4-8f885b40f4f28395.js" async=""></script><script src="/_next/static/chunks/970-5107e36f7be1fbe6.js" async=""></script><script src="/_next/static/chunks/782-ea15e8a785d57004.js" async=""></script><script src="/_next/static/chunks/900-ad1908f72dbaabe7.js" async=""></script><script src="/_next/static/chunks/app/layout-cc98e0edfad47991.js" async=""></script><script src="/_next/static/chunks/219-7f18aac596925ef1.js" async=""></script><script src="/_next/static/chunks/app/vision/page-461f5cfb94f93803.js" async=""></script><meta name="next-size-adjust" content=""/><title>AI&#x27;s Blind Spot: The Structured Data Challenge | Prior Labs Vision | Prior Labs</title><meta name="description" content="Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry."/><link rel="author" href="https://priorlabs.ai"/><meta name="author" content="Prior Labs"/><meta name="keywords" content="TabPFN,Tabular Foundation Model,Structured Data AI,Prior Labs,Machine Learning,Data Science,AI Vision,Tabular Data,Foundation Models,Artificial Intelligence"/><meta name="publisher" content="Prior Labs"/><meta name="robots" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><meta name="structuredData" content="{
      &quot;@context&quot;: &quot;https://schema.org&quot;,
      &quot;@type&quot;: &quot;Article&quot;,
      &quot;mainEntityOfPage&quot;: {
        &quot;@type&quot;: &quot;WebPage&quot;,
        &quot;@id&quot;: &quot;https://priorlabs.ai/vision&quot;
      },
      &quot;headline&quot;: &quot;AI&#x27;s Blind Spot: The Structured Data Challenge | Prior Labs Vision&quot;,
      &quot;description&quot;: &quot;Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry.&quot;,
      &quot;image&quot;: &quot;https://priorlabs.ai/prior_labs_logo.svg&quot;,
      &quot;author&quot;: {
        &quot;@type&quot;: &quot;Organization&quot;,
        &quot;name&quot;: &quot;Prior Labs&quot;,
        &quot;url&quot;: &quot;https://priorlabs.ai&quot;
      },
      &quot;publisher&quot;: {
        &quot;@type&quot;: &quot;Organization&quot;,
        &quot;name&quot;: &quot;Prior Labs&quot;,
        &quot;logo&quot;: {
          &quot;@type&quot;: &quot;ImageObject&quot;,
          &quot;url&quot;: &quot;https://priorlabs.ai/prior_labs_logo.svg&quot;
        }
      },
      &quot;datePublished&quot;: &quot;2024-04-24&quot;,
      &quot;dateModified&quot;: &quot;2024-04-24&quot;
    }"/><link rel="canonical" href="https://priorlabs.ai/vision"/><meta property="og:title" content="AI&#x27;s Blind Spot: The Structured Data Challenge | Prior Labs Vision"/><meta property="og:description" content="Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry."/><meta property="og:url" content="https://priorlabs.ai/vision"/><meta property="og:site_name" content="Prior Labs Vision"/><meta property="og:image" content="https://priorlabs.ai/prior_labs_logo.svg"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Prior Labs Logo"/><meta property="og:image:type" content="image/svg+xml"/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="AI&#x27;s Blind Spot: The Structured Data Challenge | Prior Labs Vision"/><meta name="twitter:description" content="Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry."/><meta name="twitter:image" content="https://priorlabs.ai/prior_labs_logo.svg"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="256x256"/><link rel="icon" href="/icon.ico?addd072660dee037" type="image/x-icon" sizes="256x256"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="min-h-screen bg-background font-sans antialiased __className_9c011f __variable_b73baa __variable_4db51b __variable_8dfe08 __variable_abd653 __variable_5398f7 __variable_6e33a2"><div class="relative flex min-h-screen flex-col"><header class="sticky top-0 z-50 w-full border-b bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><div class="container flex h-16 items-center justify-between"><a class="flex items-center space-x-2" href="/"><img alt="Prior Labs" loading="lazy" width="155" height="0" decoding="async" data-nimg="1" class="w-[135px] md:w-[155px]" style="color:transparent" src="/_next/static/media/prior_labs_logo_horizontal.0a4698a1.png"/></a><nav class="hidden md:flex items-center gap-6"><a class="text-sm font-medium text-muted-foreground transition-colors hover:text-primary flex items-center gap-2" href="https://github.com/PriorLabs/TabPFN">Github</a><a class="text-sm font-medium text-muted-foreground transition-colors hover:text-primary" href="https://jobs.ashbyhq.com/prior-labs">Careers</a><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 h-8 rounded-md px-3 text-sm font-medium text-muted-foreground transition-colors hover:text-primary hover:bg-transparent" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R73b:" data-state="closed">Business</button><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-primary text-primary-foreground shadow hover:bg-primary/90 h-8 rounded-md px-3 text-xs" href="/docs">Try TabPFN</a></nav><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-9 w-9 md:hidden" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R1jb:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg><span class="sr-only">Toggle menu</span></button></div></header><main class="flex-1"><main class="relative min-h-screen flex items-center justify-center py-12 px-2"><div class="absolute inset-0 -z-10 pointer-events-none"><div class="absolute left-1/2 top-0 h-[900px] w-[900px] -translate-x-1/2 rounded-full bg-gradient-to-br from-primary/10 via-primary/5 to-transparent blur-3xl opacity-80 animate-pulse" style="opacity:0;transform:scale(0.92)"></div><div class="absolute right-0 bottom-0 h-64 w-64 rounded-full bg-gradient-to-br from-primary/20 via-primary/5 to-transparent blur-2xl opacity-60" style="opacity:0;transform:scale(0.8)"></div></div><article class="relative z-10 max-w-3xl w-full mx-auto px-4 py-10 font-dmsans text-lg leading-relaxed text-foreground"><h1 class="font-header text-4xl md:text-5xl font-bold mb-8 text-primary">AI&#x27;s Blind Spot: The Structured Data Challenge</h1><div class="w-full flex justify-center mb-10"><img alt="Vision Title" width="800" height="400" decoding="async" data-nimg="1" class="w-full max-w-xl rounded-xl shadow-lg object-cover" style="color:transparent" src="/vision/title.png"/></div><div class="mb-10"><div class="border-l-4 border-primary/50 pl-5 text-base leading-relaxed text-foreground/90"><span class="font-bold">TL;DR:</span> Structured data is the language of measurement and decision-making, yet AI still treats it as an afterthought. At Prior Labs, we&#x27;re building Multimodal Tabular Foundation Models (TFMs), starting with TabPFN, that understand tables natively—learning statistical reasoning directly from data. Our vision is broader: truly agentic AI systems capable of understanding high-level goals, fusing tables, language, and images to reason, integrate domain knowledge, infer causality, and adapt dynamically. This isn&#x27;t just better analytics—it&#x27;s a new foundation for discovery across science, medicine, and the global economy.</div></div><div class="mt-12"></div><p class="mb-6">While artificial intelligence masters language and vision, it remains surprisingly inept with structured data. This isn&#x27;t niche data – structured tables are the language of measurement and empirical observation. AI now generates art and poems but struggles to natively comprehend the core operational data in spreadsheets and databases driving most critical decisions across medicine, finance, science and virtually all industries. This isn&#x27;t just a gap; it&#x27;s a massive bottleneck holding back progress.</p><p class="mb-6">Imagine, instead, a future where AI doesn&#x27;t just interact with tables through brittle tools, but <em>understands</em> them. A future where intelligent agents can instantly forecast market trends from financial logs, accelerate the discovery of life-saving drugs by interpreting clinical trial data, optimize global supply chains using real-time sensor readings, prevent billions of dollars in fraud by spotting anomalies in transactions, and personalize medicine based on genomic insights. This isn&#x27;t merely about better analytics; it&#x27;s about transforming how discovery happens, how businesses operate, and how we tackle grand challenges like cancer and climate change. It promises to reshape data science itself, from university curricula to organizational structures. At Prior Labs, we are building this future.</p><h2 class="font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary">Why Structured Data Remains AI&#x27;s Unconquered Frontier</h2><p class="mb-6">Today, we witness iterative cycles where domain specialists brief data scientists, who then wrestle with outdated models, aggregate findings, report back, and painstakingly refine questions or data inputs—a process ill-suited to the pace of modern discovery and business. While LLMs can <em>call</em> tools to interact with tables, they lack a deep, <em>internal</em> understanding of the data itself, inheriting the limitations of the tools they use.</p><p class="mb-6">But, why has structured data proven so resistant to the foundation model revolution? Tables are different: <a href="https://www.vanderschaar-lab.com/why-tabular-foundation-models-should-be-a-research-priority/" target="_blank" rel="noopener noreferrer" class="text-primary underline">link</a></p><ul class="list-disc pl-8 mb-6 space-y-2"><li><strong>Data Accessibility Bias:</strong> AI&#x27;s growth was fuelled by public text/images. Critical tabular data often remains private (spreadsheets rarely go viral), reducing public data for large model training.</li><li><strong>Architectural Mismatch:</strong> Standard LLM models lack native mechanisms for tabular layouts and numerics. Their 1-dimensional sequential architecture is made to understand language not numbers. This is like grasping an image by hearing its pixels read aloud. We need AI designed <em>specifically</em> for data patterns.</li><li><strong>Inherent Complexity:</strong> Tables combine diverse data types while often encoding highly complex domains (e.g., genomics, physics, finance). Interpreting this deep semantic and structural complexity challenges standard AI architectures.</li></ul><h2 class="font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary">Building Native Intelligence for Tables</h2><p class="mb-6">Prior Labs is tackling this challenge by developing <strong>Tabular Foundation Models (TFMs)</strong>, marking a paradigm shift, away from training on specific downstream tasks to <em>teaching the model statistical reasoning itself</em>.</p><p class="mb-6">Our first major breakthrough, <strong>TabPFN</strong>, exemplifies this. TabPFN is a Transformer model, leveraging the compute and architectural power of the modern AI era, but pre-trained <em>exclusively</em> on millions of synthetic tabular datasets encompassing a vast diversity of underlying structures and patterns. This unique pre-training process imbues TabPFN with a rich statistical &quot;prior,&quot; allowing it to implicitly understand tabular data through a native architecture. It treats numbers as numbers, grasps 2D relationships, and avoids the information loss common with standard tokenization approaches.</p><p class="mb-6">TabPFN uses <strong>In-Context Learning (ICL)</strong>, processing new data examples at inference time for state-of-the-art predictions in seconds – zero-shot, without retraining or tuning. Validated in <em>Nature Magazine</em>, its speed, accuracy, and remarkable generalization confirm the power of this approach. <a href="https://www.nature.com/articles/s41586-024-08328-6" target="_blank" rel="noopener noreferrer" class="text-primary underline">link</a></p><h2 class="font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary">Multimodal Models for Truly Agentic Data Science</h2><p class="mb-6">TabPFN is a crucial first step, but our ultimate vision extends far beyond specialized tabular models. We are building the next generation: Multimodal TFMs designed for inherent multimodal understanding.</p><p class="mb-6">Imagine AI that doesn&#x27;t just call tools, but <em>natively fuses</em> the statistical patterns in tables with the semantic context of language and the perceptual information from images, all within a single, unified architecture.</p><p class="mb-6">Such integrated models will power AI agents capable of:</p><ul class="list-disc pl-8 mb-6 space-y-2"><li>Understanding high-level analytical goals expressed in natural language.</li><li>Intelligently gathering, querying, and integrating data from diverse sources.</li><li>Integrating common sense, users domain knowledge and additional information sources with statistical information to improve predictions.</li><li>Engaging in dynamic dialogue to explore results, refine hypotheses, and surface insights invisible to human analysis alone.</li></ul><p class="mb-6">Just as LLMs provided a foundational layer for language tasks, we envision TFMs becoming the core intelligence engine for reasoning over structured and multimodal data. They are designed to empower platforms like Snowflake, Databricks, SAP, and the broader ecosystem of companies building in the application layer by providing deep, native data understanding capabilities – the missing predictive and analytical intelligence layer needed to unlock the full potential of modern data infrastructure. This extends to robust outlier detection, accurate forecasting, high-fidelity synthetic data generation, and enabling analysis across entire heterogeneous databases.</p><h2 class="font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary">Tackling the Hard Questions</h2><p class="mb-6">Realizing this vision requires solving some of the most complex and fundamental challenges in AI, problems that have stumped the field for decades:</p><ul class="list-disc pl-8 mb-6 space-y-2"><li><strong>Semantic Reasoning:</strong> Truly blending statistical power with contextual and domain-specific knowledge within a unified architecture.</li><li><strong>Inferring Causality:</strong> Moving beyond correlation to identify the causal drivers.</li><li><strong>Ensuring Trust:</strong> Making complex AI reasoning transparent, fair, interpretable, and dependable.</li></ul><p class="mb-6">These questions define the cutting edge of AI, and answering them is core to our mission. Led and advised by pioneers in AI, AutoML and causality including Frank Hutter and Bernhard Schölkopf, we aim to build the world&#x27;s best team of researchers tackling these questions, driven by creating the best possible products, and aided by world class engineers without whom this wouldn&#x27;t be possible.</p><h2 class="font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary">Building the Future &amp; Ecosystem at Prior Labs</h2><p class="mb-6">Join us to solve deep AI problems with global impact, transforming how entire industries make decisions. We seek passionate world-class researchers and engineers to join our collaborative team, pioneer solutions to these fundamental challenges with significant compute resources, and build systems that unlock understanding, <em>using intelligence truly native to the data itself</em>.</p><p class="mb-6">Recognizing that optimal performance often requires domain-specific knowledge, we will launch a dedicated <strong>fine-tuning program</strong> in the coming days. This initiative will help organizations, particularly in complex fields like genomics, clinical trials, trading, and financial modeling, to adapt our models – more to follow soon!</p><p class="mb-6">Looking ahead throughout the year, we plan several impactful releases. Key developments will include scaling our models to handle up to one million samples, substantially reducing inference times, doubling down on time series forecasting, and introducing relational understanding. We will also launch a dedicated open-source repository to foster education, research and experimentation, alongside releasing a series of agentic features aimed at automating complex data science processes.</p><p class="mb-6">We believe that just as LLMs democratized interaction with language, TFMs will democratize deep data analysis and decision making. Let&#x27;s build the future of structured data together.</p><div class="mt-10 text-right font-semibold text-base">Frank, Noah &amp; Sauraj — April 24th, 2025</div></article></main></main><footer class="border-t bg-slate-50/50 backdrop-blur-sm"><div class="container py-12 md:py-16 lg:py-20"><div class="grid gap-8 lg:grid-cols-12"><div class="lg:col-span-4"><a class="inline-block" href="/"><img alt="Prior Labs" loading="lazy" width="155" height="0" decoding="async" data-nimg="1" style="color:transparent" src="/_next/static/media/prior_labs_logo_horizontal.0a4698a1.png"/></a><p class="mt-4 font-roboto text-sm text-muted-foreground">Supercharging data science teams with the tabular foundation model - TabPFN.</p></div><div class="lg:col-span-2 lg:col-start-6"><h4 class="font-roboto font-medium">Company</h4><ul class="mt-4 space-y-3 text-sm"><li><a class="text-muted-foreground transition-colors hover:text-primary" href="mailto:hello@priorlabs.ai">Contact</a></li><li><a class="text-muted-foreground transition-colors hover:text-primary" href="https://jobs.ashbyhq.com/prior-labs">Careers</a></li><li><a class="text-muted-foreground transition-colors hover:text-primary" href="/vision">Vision Blog</a></li></ul></div><div class="lg:col-span-2"><h4 class="font-medium">Social</h4><ul class="mt-4 space-y-3 text-sm"><li><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 text-muted-foreground transition-colors hover:text-primary" href="https://www.linkedin.com/company/prior-labs/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" class="h-4 w-4" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg>LinkedIn</a></li><li><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 text-muted-foreground transition-colors hover:text-primary" href="https://discord.com/invite/VJRuU3bSxt"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 640 512" class="h-4 w-4" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M524.531,69.836a1.5,1.5,0,0,0-.764-.7A485.065,485.065,0,0,0,404.081,32.03a1.816,1.816,0,0,0-1.923.91,337.461,337.461,0,0,0-14.9,30.6,447.848,447.848,0,0,0-134.426,0,309.541,309.541,0,0,0-15.135-30.6,1.89,1.89,0,0,0-1.924-.91A483.689,483.689,0,0,0,116.085,69.137a1.712,1.712,0,0,0-.788.676C39.068,183.651,18.186,294.69,28.43,404.354a2.016,2.016,0,0,0,.765,1.375A487.666,487.666,0,0,0,176.02,479.918a1.9,1.9,0,0,0,2.063-.676A348.2,348.2,0,0,0,208.12,430.4a1.86,1.86,0,0,0-1.019-2.588,321.173,321.173,0,0,1-45.868-21.853,1.885,1.885,0,0,1-.185-3.126c3.082-2.309,6.166-4.711,9.109-7.137a1.819,1.819,0,0,1,1.9-.256c96.229,43.917,200.41,43.917,295.5,0a1.812,1.812,0,0,1,1.924.233c2.944,2.426,6.027,4.851,9.132,7.16a1.884,1.884,0,0,1-.162,3.126,301.407,301.407,0,0,1-45.89,21.83,1.875,1.875,0,0,0-1,2.611,391.055,391.055,0,0,0,30.014,48.815,1.864,1.864,0,0,0,2.063.7A486.048,486.048,0,0,0,610.7,405.729a1.882,1.882,0,0,0,.765-1.352C623.729,277.594,590.933,167.465,524.531,69.836ZM222.491,337.58c-28.972,0-52.844-26.587-52.844-59.239S193.056,219.1,222.491,219.1c29.665,0,53.306,26.82,52.843,59.239C275.334,310.993,251.924,337.58,222.491,337.58Zm195.38,0c-28.971,0-52.843-26.587-52.843-59.239S388.437,219.1,417.871,219.1c29.667,0,53.307,26.82,52.844,59.239C470.715,310.993,447.538,337.58,417.871,337.58Z"></path></svg>Discord</a></li><li><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 text-muted-foreground transition-colors hover:text-primary" href="https://x.com/prior_labs"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" class="h-4 w-4" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>Twitter</a></li><li><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 text-muted-foreground transition-colors hover:text-primary" href="https://github.com/PriorLabs/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" class="h-4 w-4" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>GitHub</a></li><li><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-2 text-muted-foreground transition-colors hover:text-primary" href="https://huggingface.co/Prior-Labs"><svg stroke="currentColor" fill="currentColor" stroke-width="0" role="img" viewBox="0 0 24 24" class="h-4 w-4" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M1.4446 11.5059c0 1.1021.1673 2.1585.4847 3.1563-.0378-.0028-.0691-.0058-.1058-.0058-.4209 0-.8015.16-1.0704.4512-.3454.3737-.4984.8335-.4316 1.293a1.576 1.576 0 0 0 .2148.5978c-.2319.1864-.4018.4456-.4844.7578-.0646.2448-.131.7543.2149 1.2794a1.4552 1.4552 0 0 0-.0625.1055c-.208.3923-.2207.8372-.0371 1.25.2783.6258.9696 1.1175 2.3126 1.6467.8356.3292 1.5988.5411 1.6056.543 1.1046.2847 2.104.4277 2.969.4277 1.4173 0 2.4754-.3849 3.1525-1.1446 1.538.2651 2.791.1403 3.592.006.6773.7555 1.7332 1.1387 3.1467 1.1387.8649 0 1.8643-.143 2.969-.4278.0068-.0019.77-.2138 1.6056-.543 1.343-.5292 2.0343-1.0208 2.3126-1.6466.1836-.4129.171-.8577-.037-1.25a1.4685 1.4685 0 0 0-.0626-.1056c.346-.525.2795-1.0346.2149-1.2793-.0826-.3122-.2525-.5714-.4844-.7579.11-.1816.1831-.3788.2148-.5977.0669-.4595-.0862-.9193-.4316-1.293-.2688-.2913-.6495-.4513-1.0704-.4513-.0209 0-.0376.0008-.0588.0018.3162-.9966.4846-2.0518.4846-3.1523 0-5.807-4.7362-10.5144-10.5789-10.5144-5.8426 0-10.5788 4.7073-10.5788 10.5144Zm10.5788-9.4831c5.2727 0 9.5476 4.246 9.5476 9.483a9.4201 9.4201 0 0 1-.2696 2.2365c-.0039-.0047-.0079-.011-.0117-.0156-.274-.3255-.6679-.5059-1.1075-.5059-.352 0-.714.1155-1.0763.3438-.2403.1517-.5058.422-.7793.7598-.2534-.3492-.608-.5832-1.0137-.6465a1.5174 1.5174 0 0 0-.2344-.0176c-.9263 0-1.4828.7993-1.6935 1.5177-.1046.2426-.6065 1.3482-1.3614 2.0978-1.1681 1.1601-1.4458 2.3534-.8396 3.6382-.843.1029-1.5836.0927-2.365-.006.5906-1.212.3626-2.4388-.8426-3.6322-.755-.7496-1.2568-1.8552-1.3614-2.0978-.2107-.7184-.7673-1.5177-1.6935-1.5177-.078 0-.1568.0054-.2344.0176-.4057.0633-.7604.2973-1.0137.6465-.2735-.3379-.539-.6081-.7794-.7598-.3622-.2283-.7243-.3438-1.0762-.3438-.4266 0-.8094.171-1.0821.4786a9.4208 9.4208 0 0 1-.2598-2.1936c0-5.237 4.2749-9.483 9.5475-9.483zM8.6443 7.0036c-.4838.0043-.9503.2667-1.1934.7227-.3536.6633-.1006 1.4873.5645 1.84.351.1862.4883-.5261.836-.6485.3107-.1095.841.399 1.0078.086.3536-.6634.1025-1.4874-.5625-1.84a1.3659 1.3659 0 0 0-.6524-.1602Zm6.8403 0c-.2199-.002-.4426.05-.6504.1602-.665.3526-.9181 1.1766-.5645 1.84.1669.313.6971-.1955 1.0079-.086.3476.1224.4867.8347.838.6485.6649-.3527.916-1.1767.5624-1.84-.243-.456-.7096-.7184-1.1934-.7227Zm-9.7565 1.418a.8768.8768 0 0 0-.877.877c0 .4846.3925.877.877.877a.8768.8768 0 0 0 .877-.877.8768.8768 0 0 0-.877-.877zm12.6434 0c-.4845 0-.879.3925-.879.877 0 .4846.3945.877.879.877a.8768.8768 0 0 0 .877-.877.8768.8768 0 0 0-.877-.877zM8.7927 11.459c-.179-.003-.2793.1107-.2793.416 0 .8097.3874 2.125 1.4279 2.924.207-.7123 1.3453-1.2832 1.5079-1.2012.2315.1167.2191.4417.6074.7266.3884-.285.374-.6098.6056-.7266.1627-.082 1.3009.4889 1.5079 1.2012 1.0404-.799 1.4278-2.1144 1.4278-2.924 0-1.2212-1.583.6402-3.5413.6485-1.4686-.0061-2.7266-1.0558-3.2639-1.0645zM4.312 14.4768c.5792.365 1.6964 2.2751 2.1056 3.0177.1371.2488.371.3536.582.3536.4188 0 .7465-.4138.0391-.9395-1.0636-.791-.6914-2.0846-.1836-2.1642a.4302.4302 0 0 1 .0664-.004c.4616 0 .666.7892.666.7892s.5959 1.4898 1.6213 2.508c.942.9356 1.062 1.703.4961 2.6661-.0164-.004-.0159.0236-.1484.2149-.1853.2673-.4322.4688-.7188.6152-.5062.2269-1.1397.2696-1.7833.2696-1.037 0-2.1017-.1824-2.6975-.336-.0293-.0075-3.6505-.9567-3.1916-1.8224.0771-.1454.2033-.2031.3633-.2031.6463 0 1.823.9551 2.3283.9551.113 0 .196-.0865.2285-.2031.2249-.8045-3.2787-1.0522-2.9846-2.1642.0519-.1967.193-.2757.3907-.2754.854 0 2.7704 1.4923 3.172 1.4923.0307 0 .0525-.0085.0645-.0274.2012-.3227.1096-.5865-1.3087-1.4395-1.4182-.8533-2.4315-1.329-1.8653-1.9416.0651-.0707.1574-.1015.2695-.1015.8611.0002 2.8948 1.84 2.8948 1.84s.5487.5683.8809.5683c.0762 0 .1416-.0315.1855-.1054.2355-.3946-2.1858-2.2183-2.3224-2.971-.0926-.51.0641-.7676.3555-.7676-.0006.008.1701-.0285.4942.1759zm16.2257.5918c-.1366.7526-2.5579 2.5764-2.3224 2.9709.044.074.1092.1055.1855.1055.3321 0 .881-.5684.881-.5684s2.0336-1.8397 2.8947-1.84c.1121 0 .2044.0308.2695.1016.5662.6125-.447 1.0882-1.8653 1.9415-1.4183.853-1.51 1.1168-1.3087 1.4396.012.0188.0337.0273.0644.0273.4016 0 2.3181-1.4923 3.1721-1.4923.1977-.0002.3388.0787.3907.2754.294 1.112-3.2095 1.3597-2.9846 2.1642.0325.1166.1156.2032.2285.2032.5054 0 1.682-.9552 2.3283-.9552.16 0 .2862.0577.3633.2032.459.8656-3.1623 1.8149-3.1916 1.8224-.5958.1535-1.6605.336-2.6975.336-.6351 0-1.261-.0409-1.7638-.2599-.2949-.1472-.5488-.3516-.7383-.625-.0411-.0682-.1026-.1476-.1426-.205-.5726-.9679-.455-1.7371.4903-2.676 1.0254-1.0182 1.6212-2.508 1.6212-2.508s.2044-.7891.666-.7891a.4318.4318 0 0 1 .0665.0039c.5078.0796.88 1.3732-.1836 2.1642-.7074.5257-.3797.9395.039.9395.211 0 .445-.1047.5821-.3535.4092-.7426 1.5264-2.6527 2.1056-3.0178.5588-.3524.99-.1816.8497.5918z"></path></svg>Hugging Face</a></li></ul></div><div class="lg:col-span-4"><h4 class="font-medium">Stay updated</h4><p class="mt-2 text-sm text-muted-foreground">Subscribe to our newsletter for updates and insights.</p><form id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="mt-4" action="https://priorlabs.us9.list-manage.com/subscribe/post?u=802a2610cb5a7f59daab4771a&amp;id=ca948f4735&amp;v_id=4623&amp;f_id=002feae3f0" method="post" target="_blank"><div class="flex gap-2"><input type="email" id="mce-EMAIL" placeholder="Enter your email" required="" class="flex-1 rounded-md border bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring" name="EMAIL" value=""/><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-primary text-primary-foreground shadow hover:bg-primary/90 h-9 px-4 py-2" type="submit">Subscribe<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-send ml-2 h-4 w-4"><path d="M14.536 21.686a.5.5 0 0 0 .937-.024l6.5-19a.496.496 0 0 0-.635-.635l-19 6.5a.5.5 0 0 0-.024.937l7.93 3.18a2 2 0 0 1 1.112 1.11z"></path><path d="m21.854 2.147-10.94 10.939"></path></svg></button></div><div aria-hidden="true" style="position:absolute;left:-5000px"><input type="text" tabindex="-1" name="b_802a2610cb5a7f59daab4771a_ca948f4735" value=""/></div></form></div></div><div class="mt-12 flex flex-col items-center justify-between gap-4 border-t pt-8 text-sm text-muted-foreground md:flex-row"><p>© <!-- -->2025<!-- --> Prior Labs. All rights reserved.</p><div class="flex gap-4"><a class="hover:text-primary" href="https://priorlabs.ai/privacy_policy/">Privacy Policy</a><a class="hover:text-primary" href="https://priorlabs.ai/terms/">Terms of Service</a></div></div></div></footer><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section></div><script src="/_next/static/chunks/webpack-5c4816f6c5350863.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[5328,[\"362\",\"static/chunks/30a37ab2-b2120806d300c7b3.js\",\"711\",\"static/chunks/8e1d74a4-8f885b40f4f28395.js\",\"970\",\"static/chunks/970-5107e36f7be1fbe6.js\",\"782\",\"static/chunks/782-ea15e8a785d57004.js\",\"900\",\"static/chunks/900-ad1908f72dbaabe7.js\",\"177\",\"static/chunks/app/layout-cc98e0edfad47991.js\"],\"SiteHeader\"]\n3:I[5244,[],\"\"]\n4:I[3866,[],\"\"]\n5:I[1794,[\"362\",\"static/chunks/30a37ab2-b2120806d300c7b3.js\",\"711\",\"static/chunks/8e1d74a4-8f885b40f4f28395.js\",\"970\",\"static/chunks/970-5107e36f7be1fbe6.js\",\"782\",\"static/chunks/782-ea15e8a785d57004.js\",\"900\",\"static/chunks/900-ad1908f72dbaabe7.js\",\"177\",\"static/chunks/app/layout-cc98e0edfad47991.js\"],\"Footer\"]\n6:I[814,[\"362\",\"static/chunks/30a37ab2-b2120806d300c7b3.js\",\"711\",\"static/chunks/8e1d74a4-8f885b40f4f28395.js\",\"970\",\"static/chunks/970-5107e36f7be1fbe6.js\",\"782\",\"static/chunks/782-ea15e8a785d57004.js\",\"900\",\"static/chunks/900-ad1908f72dbaabe7.js\",\"177\",\"static/chunks/app/layout-cc98e0edfad47991.js\"],\"Toaster\"]\n7:I[4396,[\"970\",\"static/chunks/970-5107e36f7be1fbe6.js\",\"219\",\"static/chunks/219-7f18aac596925ef1.js\",\"351\",\"static/chunks/app/vision/page-461f5cfb94f93803.js\"],\"BlogBackground\"]\n8:I[7970,[\"970\",\"static/chunks/970-5107e36f7be1fbe6.js\",\"219\",\"static/chunks/219-7f18aac596925ef1.js\",\"351\",\"static/chunks/app/vision/page-461f5cfb94f93803.js\"],\"Image\"]\n9:I[6213,[],\"OutletBoundary\"]\nb:I[6213,[],\"MetadataBoundary\"]\nd:I[6213,[],\"ViewportBoundary\"]\nf:I[4835,[],\"\"]\n:HL[\"/_next/static/media/01af0fc7b4278e65-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/3d9ea938b6afa941-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/4f05ba3a6752a328-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/7e6a2e30184bb114-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/ae0a0c671023eecc-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font"])</script><script>self.__next_f.push([1,"/woff2\"}]\n:HL[\"/_next/static/media/b4f46b1ccc361ec4-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/fe75a68bdb2aebce.css\",\"style\"]\n:HL[\"/_next/static/css/59f806dbf2a0b375.css\",\"style\"]\n:HL[\"/_next/static/css/c7be8c723596c368.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"Tdghc6wEdyqfclh56XJc5\",\"p\":\"\",\"c\":[\"\",\"vision\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"vision\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/fe75a68bdb2aebce.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/59f806dbf2a0b375.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c7be8c723596c368.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"min-h-screen bg-background font-sans antialiased __className_9c011f __variable_b73baa __variable_4db51b __variable_8dfe08 __variable_abd653 __variable_5398f7 __variable_6e33a2\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative flex min-h-screen flex-col\",\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L5\",null,{}],[\"$\",\"$L6\",null,{}]]}]}]}]]}],{\"children\":[\"vision\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"vision\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"className\":\"relative min-h-screen flex items-center justify-center py-12 px-2\",\"children\":[[\"$\",\"$L7\",null,{}],[\"$\",\"article\",null,{\"className\":\"relative z-10 max-w-3xl w-full mx-auto px-4 py-10 font-dmsans text-lg leading-relaxed text-foreground\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"font-header text-4xl md:text-5xl font-bold mb-8 text-primary\",\"children\":\"AI's Blind Spot: The Structured Data Challenge\"}],[\"$\",\"div\",null,{\"className\":\"w-full flex justify-center mb-10\",\"children\":[\"$\",\"$L8\",null,{\"src\":\"/vision/title.png\",\"alt\":\"Vision Title\",\"width\":800,\"height\":400,\"priority\":true,\"className\":\"w-full max-w-xl rounded-xl shadow-lg object-cover\"}]}],[\"$\",\"div\",null,{\"className\":\"mb-10\",\"children\":[\"$\",\"div\",null,{\"className\":\"border-l-4 border-primary/50 pl-5 text-base leading-relaxed text-foreground/90\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-bold\",\"children\":\"TL;DR:\"}],\" Structured data is the language of measurement and decision-making, yet AI still treats it as an afterthought. At Prior Labs, we're building Multimodal Tabular Foundation Models (TFMs), starting with TabPFN, that understand tables natively—learning statistical reasoning directly from data. Our vision is broader: truly agentic AI systems capable of understanding high-level goals, fusing tables, language, and images to reason, integrate domain knowledge, infer causality, and adapt dynamically. This isn't just better analytics—it's a new foundation for discovery across science, medicine, and the global economy.\"]}]}],[\"$\",\"div\",null,{\"className\":\"mt-12\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"While artificial intelligence masters language and vision, it remains surprisingly inept with structured data. This isn't niche data – structured tables are the language of measurement and empirical observation. AI now generates art and poems but struggles to natively comprehend the core operational data in spreadsheets and databases driving most critical decisions across medicine, finance, science and virtually all industries. This isn't just a gap; it's a massive bottleneck holding back progress.\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"Imagine, instead, a future where AI doesn't just interact with tables through brittle tools, but \",[\"$\",\"em\",null,{\"children\":\"understands\"}],\" them. A future where intelligent agents can instantly forecast market trends from financial logs, accelerate the discovery of life-saving drugs by interpreting clinical trial data, optimize global supply chains using real-time sensor readings, prevent billions of dollars in fraud by spotting anomalies in transactions, and personalize medicine based on genomic insights. This isn't merely about better analytics; it's about transforming how discovery happens, how businesses operate, and how we tackle grand challenges like cancer and climate change. It promises to reshape data science itself, from university curricula to organizational structures. At Prior Labs, we are building this future.\"]}],[\"$\",\"h2\",null,{\"className\":\"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary\",\"children\":\"Why Structured Data Remains AI's Unconquered Frontier\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"Today, we witness iterative cycles where domain specialists brief data scientists, who then wrestle with outdated models, aggregate findings, report back, and painstakingly refine questions or data inputs—a process ill-suited to the pace of modern discovery and business. While LLMs can \",[\"$\",\"em\",null,{\"children\":\"call\"}],\" tools to interact with tables, they lack a deep, \",[\"$\",\"em\",null,{\"children\":\"internal\"}],\" understanding of the data itself, inheriting the limitations of the tools they use.\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"But, why has structured data proven so resistant to the foundation model revolution? Tables are different: \",[\"$\",\"a\",null,{\"href\":\"https://www.vanderschaar-lab.com/why-tabular-foundation-models-should-be-a-research-priority/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary underline\",\"children\":\"link\"}]]}],[\"$\",\"ul\",null,{\"className\":\"list-disc pl-8 mb-6 space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Data Accessibility Bias:\"}],\" AI's growth was fuelled by public text/images. Critical tabular data often remains private (spreadsheets rarely go viral), reducing public data for large model training.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Architectural Mismatch:\"}],\" Standard LLM models lack native mechanisms for tabular layouts and numerics. Their 1-dimensional sequential architecture is made to understand language not numbers. This is like grasping an image by hearing its pixels read aloud. We need AI designed \",[\"$\",\"em\",null,{\"children\":\"specifically\"}],\" for data patterns.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Inherent Complexity:\"}],\" Tables combine diverse data types while often encoding highly complex domains (e.g., genomics, physics, finance). Interpreting this deep semantic and structural complexity challenges standard AI architectures.\"]}]]}],[\"$\",\"h2\",null,{\"className\":\"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary\",\"children\":\"Building Native Intelligence for Tables\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"Prior Labs is tackling this challenge by developing \",[\"$\",\"strong\",null,{\"children\":\"Tabular Foundation Models (TFMs)\"}],\", marking a paradigm shift, away from training on specific downstream tasks to \",[\"$\",\"em\",null,{\"children\":\"teaching the model statistical reasoning itself\"}],\".\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"Our first major breakthrough, \",[\"$\",\"strong\",null,{\"children\":\"TabPFN\"}],\", exemplifies this. TabPFN is a Transformer model, leveraging the compute and architectural power of the modern AI era, but pre-trained \",[\"$\",\"em\",null,{\"children\":\"exclusively\"}],\" on millions of synthetic tabular datasets encompassing a vast diversity of underlying structures and patterns. This unique pre-training process imbues TabPFN with a rich statistical \\\"prior,\\\" allowing it to implicitly understand tabular data through a native architecture. It treats numbers as numbers, grasps 2D relationships, and avoids the information loss common with standard tokenization approaches.\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"TabPFN uses \",[\"$\",\"strong\",null,{\"children\":\"In-Context Learning (ICL)\"}],\", processing new data examples at inference time for state-of-the-art predictions in seconds – zero-shot, without retraining or tuning. Validated in \",[\"$\",\"em\",null,{\"children\":\"Nature Magazine\"}],\", its speed, accuracy, and remarkable generalization confirm the power of this approach. \",[\"$\",\"a\",null,{\"href\":\"https://www.nature.com/articles/s41586-024-08328-6\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary underline\",\"children\":\"link\"}]]}],[\"$\",\"h2\",null,{\"className\":\"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary\",\"children\":\"Multimodal Models for Truly Agentic Data Science\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"TabPFN is a crucial first step, but our ultimate vision extends far beyond specialized tabular models. We are building the next generation: Multimodal TFMs designed for inherent multimodal understanding.\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"Imagine AI that doesn't just call tools, but \",[\"$\",\"em\",null,{\"children\":\"natively fuses\"}],\" the statistical patterns in tables with the semantic context of language and the perceptual information from images, all within a single, unified architecture.\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"Such integrated models will power AI agents capable of:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc pl-8 mb-6 space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":\"Understanding high-level analytical goals expressed in natural language.\"}],[\"$\",\"li\",null,{\"children\":\"Intelligently gathering, querying, and integrating data from diverse sources.\"}],[\"$\",\"li\",null,{\"children\":\"Integrating common sense, users domain knowledge and additional information sources with statistical information to improve predictions.\"}],[\"$\",\"li\",null,{\"children\":\"Engaging in dynamic dialogue to explore results, refine hypotheses, and surface insights invisible to human analysis alone.\"}]]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"Just as LLMs provided a foundational layer for language tasks, we envision TFMs becoming the core intelligence engine for reasoning over structured and multimodal data. They are designed to empower platforms like Snowflake, Databricks, SAP, and the broader ecosystem of companies building in the application layer by providing deep, native data understanding capabilities – the missing predictive and analytical intelligence layer needed to unlock the full potential of modern data infrastructure. This extends to robust outlier detection, accurate forecasting, high-fidelity synthetic data generation, and enabling analysis across entire heterogeneous databases.\"}],[\"$\",\"h2\",null,{\"className\":\"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary\",\"children\":\"Tackling the Hard Questions\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"Realizing this vision requires solving some of the most complex and fundamental challenges in AI, problems that have stumped the field for decades:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc pl-8 mb-6 space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Semantic Reasoning:\"}],\" Truly blending statistical power with contextual and domain-specific knowledge within a unified architecture.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Inferring Causality:\"}],\" Moving beyond correlation to identify the causal drivers.\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Ensuring Trust:\"}],\" Making complex AI reasoning transparent, fair, interpretable, and dependable.\"]}]]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"These questions define the cutting edge of AI, and answering them is core to our mission. Led and advised by pioneers in AI, AutoML and causality including Frank Hutter and Bernhard Schölkopf, we aim to build the world's best team of researchers tackling these questions, driven by creating the best possible products, and aided by world class engineers without whom this wouldn't be possible.\"}],[\"$\",\"h2\",null,{\"className\":\"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary\",\"children\":\"Building the Future \u0026 Ecosystem at Prior Labs\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"Join us to solve deep AI problems with global impact, transforming how entire industries make decisions. We seek passionate world-class researchers and engineers to join our collaborative team, pioneer solutions to these fundamental challenges with significant compute resources, and build systems that unlock understanding, \",[\"$\",\"em\",null,{\"children\":\"using intelligence truly native to the data itself\"}],\".\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":[\"Recognizing that optimal performance often requires domain-specific knowledge, we will launch a dedicated \",[\"$\",\"strong\",null,{\"children\":\"fine-tuning program\"}],\" in the coming days. This initiative will help organizations, particularly in complex fields like genomics, clinical trials, trading, and financial modeling, to adapt our models – more to follow soon!\"]}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"Looking ahead throughout the year, we plan several impactful releases. Key developments will include scaling our models to handle up to one million samples, substantially reducing inference times, doubling down on time series forecasting, and introducing relational understanding. We will also launch a dedicated open-source repository to foster education, research and experimentation, alongside releasing a series of agentic features aimed at automating complex data science processes.\"}],[\"$\",\"p\",null,{\"className\":\"mb-6\",\"children\":\"We believe that just as LLMs democratized interaction with language, TFMs will democratize deep data analysis and decision making. Let's build the future of structured data together.\"}],[\"$\",\"div\",null,{\"className\":\"mt-10 text-right font-semibold text-base\",\"children\":\"Frank, Noah \u0026 Sauraj — April 24th, 2025\"}]]}]]}],null,[\"$\",\"$L9\",null,{\"children\":\"$La\"}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"SJeBG_m-lbzXi15LDK57p\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision | Prior Labs\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry.\"}],[\"$\",\"link\",\"3\",{\"rel\":\"author\",\"href\":\"https://priorlabs.ai\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"Prior Labs\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"TabPFN,Tabular Foundation Model,Structured Data AI,Prior Labs,Machine Learning,Data Science,AI Vision,Tabular Data,Foundation Models,Artificial Intelligence\"}],[\"$\",\"meta\",\"6\",{\"name\":\"publisher\",\"content\":\"Prior Labs\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"meta\",\"8\",{\"name\":\"structuredData\",\"content\":\"{\\n      \\\"@context\\\": \\\"https://schema.org\\\",\\n      \\\"@type\\\": \\\"Article\\\",\\n      \\\"mainEntityOfPage\\\": {\\n        \\\"@type\\\": \\\"WebPage\\\",\\n        \\\"@id\\\": \\\"https://priorlabs.ai/vision\\\"\\n      },\\n      \\\"headline\\\": \\\"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision\\\",\\n      \\\"description\\\": \\\"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry.\\\",\\n      \\\"image\\\": \\\"https://priorlabs.ai/prior_labs_logo.svg\\\",\\n      \\\"author\\\": {\\n        \\\"@type\\\": \\\"Organization\\\",\\n        \\\"name\\\": \\\"Prior Labs\\\",\\n        \\\"url\\\": \\\"https://priorlabs.ai\\\"\\n      },\\n      \\\"publisher\\\": {\\n        \\\"@type\\\": \\\"Organization\\\",\\n        \\\"name\\\": \\\"Prior Labs\\\",\\n        \\\"logo\\\": {\\n          \\\"@type\\\": \\\"ImageObject\\\",\\n          \\\"url\\\": \\\"https://priorlabs.ai/prior_labs_logo.svg\\\"\\n        }\\n      },\\n      \\\"datePublished\\\": \\\"2024-04-24\\\",\\n      \\\"dateModified\\\": \\\"2024-04-24\\\"\\n    }\"}],[\"$\",\"link\",\"9\",{\"rel\":\"canonical\",\"href\":\"https://priorlabs.ai/vision\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://priorlabs.ai/vision\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"Prior Labs Vision\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image\",\"content\":\"https://priorlabs.ai/prior_labs_logo.svg\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image:alt\",\"content\":\"Prior Labs Logo\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:image:type\",\"content\":\"image/svg+xml\"}],[\"$\",\"meta\",\"19\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:title\",\"content\":\"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:description\",\"content\":\"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry.\"}],[\"$\",\"meta\",\"23\",{\"name\":\"twitter:image\",\"content\":\"https://priorlabs.ai/prior_labs_logo.svg\"}],[\"$\",\"link\",\"24\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}],[\"$\",\"link\",\"25\",{\"rel\":\"icon\",\"href\":\"/icon.ico?addd072660dee037\",\"type\":\"image/x-icon\",\"sizes\":\"256x256\"}]]\n"])</script><script>self.__next_f.push([1,"a:null\n"])</script></body></html>