{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"","text":"<p>PriorLabs is building breakthrough foundation models that understand spreadsheets and databases. While foundation models have transformed text and images, tabular data has remained largely untouched. We're tackling this opportunity with technology that could revolutionize how we approach scientific discovery, medical research, financial modeling, and business intelligence.</p>"},{"location":"#why-tabpfn","title":"Why TabPFN","text":"<ul> <li> <p> Rapid Training</p> <p>TabPFN significantly reduces training time, outperforming traditional models tuned for hours in just a few seconds. For instance, it surpasses an ensemble of the strongest baselines in 2.8 seconds compared to 4 hours of tuning.</p> </li> <li> <p> Superior Accuracy</p> <p>TabPFN consistently outperforms state-of-the-art methods like gradient-boosted decision trees (GBDTs) on datasets with up to 10,000 samples. It achieves higher accuracy and better performance metrics across a range of classification and regression tasks.</p> </li> <li> <p> Robustness</p> <p>The model demonstrates robustness to various dataset characteristics, including uninformative features, outliers, and missing values, maintaining high performance where other methods struggle.</p> </li> <li> <p> Generative Capabilities</p> <p>As a generative transformer-based model, TabPFN can be fine-tuned for specific tasks, generate synthetic data, estimate densities, and learn reusable embeddings. This makes it versatile for various applications beyond standard prediction tasks.</p> </li> <li> <p> Sklearn Interface</p> <p>TabPFN follows the interfaces provided by scikit-learn, making it easy to integrate into existing workflows and utilize familiar functions for fitting, predicting, and evaluating models.</p> </li> <li> <p> Minimal Preprocessing</p> <p>The model handles various types of raw data, including missing values and categorical variables, with minimal preprocessing. This reduces the burden on users to perform extensive data preparation.</p> </li> </ul>"},{"location":"#tabpfn-integrations","title":"TabPFN Integrations","text":"<ul> <li> <p> API Client</p> <p>The fastest way to get started with TabPFN. Access our models through the cloud without requiring local GPU resources.</p> </li> <li> <p> User Interface</p> <p>Visual interface for no-code interaction with TabPFN. Perfect for quick experimentation and visualization.</p> <p> Access GUI</p> </li> <li> <p> Python Package</p> <p>Coming soon! Local installation with GPU support and scikit-learn compatible interface.</p> </li> <li> <p> R Integration</p> <p>Currently in development. Bringing TabPFN's capabilities to the R ecosystem for data scientists and researchers.</p> </li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>You can access our models through our API (https://github.com/automl/tabpfn-client) or via our user interface built on top of the API (https://ux.priorlabs.ai/). We will release open weights models soon, currently we are available via api and via our user interface built on top of the API.</p> Python API Client (No GPU, Online)Python Local (GPU) <pre><code>pip install tabpfn-client\n</code></pre> <p>Warning</p> <p>Not released yet</p> <p> </p>"},{"location":"cla/","title":"Contributor Agreement","text":""},{"location":"cla/#individual-contributor-exclusive-license-agreement","title":"Individual Contributor Exclusive License Agreement","text":""},{"location":"cla/#including-the-traditional-patent-license-option","title":"(including the Traditional Patent License OPTION)","text":"<p>Thank you for your interest in contributing to PriorLabs's TabPFN (\"We\" or \"Us\").</p> <p>The purpose of this contributor agreement (\"Agreement\") is to clarify and document the rights granted by contributors to Us. To make this document effective, please follow the instructions at https://www.priorlabs.ai/sign-cla.</p>"},{"location":"cla/#how-to-use-this-contributor-agreement","title":"How to use this Contributor Agreement","text":"<p>If You are an employee and have created the Contribution as part of your employment, You need to have Your employer approve this Agreement or sign the Entity version of this document. If You do not own the Copyright in the entire work of authorship, any other author of the Contribution should also sign this \u2013 in any event, please contact Us at noah.homa@gmail.com</p>"},{"location":"cla/#1-definitions","title":"1. Definitions","text":"<p>\"You\" means the individual Copyright owner who Submits a Contribution to Us.</p> <p>\"Contribution\" means any original work of authorship, including any original modifications or additions to an existing work of authorship, Submitted by You to Us, in which You own the Copyright.</p> <p>\"Copyright\" means all rights protecting works of authorship, including copyright, moral and neighboring rights, as appropriate, for the full term of their existence.</p> <p>\"Material\" means the software or documentation made available by Us to third parties. When this Agreement covers more than one software project, the Material means the software or documentation to which the Contribution was Submitted. After You Submit the Contribution, it may be included in the Material.</p> <p>\"Submit\" means any act by which a Contribution is transferred to Us by You by means of tangible or intangible media, including but not limited to electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, Us, but excluding any transfer that is conspicuously marked or otherwise designated in writing by You as \"Not a Contribution.\"</p> <p>\"Documentation\" means any non-software portion of a Contribution.</p>"},{"location":"cla/#2-license-grant","title":"2. License grant","text":""},{"location":"cla/#21-copyright-license-to-us","title":"2.1 Copyright license to Us","text":"<p>Subject to the terms and conditions of this Agreement, You hereby grant to Us a worldwide, royalty-free, Exclusive, perpetual and irrevocable (except as stated in Section 8.2) license, with the right to transfer an unlimited number of non-exclusive licenses or to grant sublicenses to third parties, under the Copyright covering the Contribution to use the Contribution by all means, including, but not limited to:</p> <ul> <li>publish the Contribution,</li> <li>modify the Contribution,</li> <li>prepare derivative works based upon or containing the Contribution and/or to combine the Contribution with other Materials,</li> <li>reproduce the Contribution in original or modified form,</li> <li>distribute, to make the Contribution available to the public, display and publicly perform the Contribution in original or modified form.</li> </ul>"},{"location":"cla/#22-moral-rights","title":"2.2 Moral rights","text":"<p>Moral Rights remain unaffected to the extent they are recognized and not waivable by applicable law. Notwithstanding, You may add your name to the attribution mechanism customary used in the Materials you Contribute to, such as the header of the source code files of Your Contribution, and We will respect this attribution when using Your Contribution.</p>"},{"location":"cla/#23-copyright-license-back-to-you","title":"2.3 Copyright license back to You","text":"<p>Upon such grant of rights to Us, We immediately grant to You a worldwide, royalty-free, non-exclusive, perpetual and irrevocable license, with the right to transfer an unlimited number of non-exclusive licenses or to grant sublicenses to third parties, under the Copyright covering the Contribution to use the Contribution by all means, including, but not limited to:</p> <ul> <li>publish the Contribution,</li> <li>modify the Contribution,</li> <li>prepare derivative works based upon or containing the Contribution and/or to combine the Contribution with other Materials,</li> <li>reproduce the Contribution in original or modified form,</li> <li>distribute, to make the Contribution available to the public, display and publicly perform the Contribution in original or modified form.</li> </ul> <p>This license back is limited to the Contribution and does not provide any rights to the Material.</p>"},{"location":"cla/#3-patents","title":"3. Patents","text":""},{"location":"cla/#31-patent-license","title":"3.1 Patent license","text":"<p>Subject to the terms and conditions of this Agreement You hereby grant to Us and to recipients of Materials distributed by Us a worldwide, royalty-free, non-exclusive, perpetual and irrevocable (except as stated in Section 3.2) patent license, with the right to transfer an unlimited number of non-exclusive licenses or to grant sublicenses to third parties, to make, have made, use, sell, offer for sale, import and otherwise transfer the Contribution and the Contribution in combination with any Material (and portions of such combination). This license applies to all patents owned or controlled by You, whether already acquired or hereafter acquired, that would be infringed by making, having made, using, selling, offering for sale, importing or otherwise transferring of Your Contribution(s) alone or by combination of Your Contribution(s) with any Material.</p>"},{"location":"cla/#32-revocation-of-patent-license","title":"3.2 Revocation of patent license","text":"<p>You reserve the right to revoke the patent license stated in section 3.1 if We make any infringement claim that is targeted at your Contribution and not asserted for a Defensive Purpose. An assertion of claims of the Patents shall be considered for a \"Defensive Purpose\" if the claims are asserted against an entity that has filed, maintained, threatened, or voluntarily participated in a patent infringement lawsuit against Us or any of Our licensees.</p>"},{"location":"cla/#4-license-obligations-by-us","title":"4. License obligations by Us","text":"<p>We agree to license the Contribution only under the terms of the license or licenses that We are using on the Submission Date for the Material (including any rights to adopt any future version of a license).</p> <p>In addition, We may use the following licenses for Documentation in the Contribution: CC-BY-4.0, CC-BY-ND-4.0, CC-BY-NC-4.0, CC-BY-NC-ND-4.0, CC-BY-NC-SA-4.0, CC-BY-SA-4.0, CC0-1.0, MIT License, Apache License, GNU General Public License (GPL) v2.0, GNU General Public License (GPL) v3.0, GNU Affero General Public License v3.0, GNU Lesser General Public License (LGPL) v2.1, GNU Lesser General Public License (LGPL) v3.0, Mozilla Public License 2.0, Eclipse Public License 2.0, Microsoft Public License (Ms-PL), Microsoft Reciprocal License (Ms-RL), BSD 2-Clause \"Simplified\" or \"FreeBSD\" license, BSD 3-Clause \"New\" or \"Revised\" license (including any right to adopt any future version of a license).</p> <p>We agree to license patents owned or controlled by You only to the extent necessary to (sub)license Your Contribution(s) and the combination of Your Contribution(s) with the Material under the terms of the license or licenses that We are using on the Submission Date.</p>"},{"location":"cla/#5-disclaimer","title":"5. Disclaimer","text":"<p>THE CONTRIBUTION IS PROVIDED \"AS IS\". MORE PARTICULARLY, ALL EXPRESS OR IMPLIED WARRANTIES INCLUDING, WITHOUT LIMITATION, ANY IMPLIED WARRANTY OF SATISFACTORY QUALITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT ARE EXPRESSLY DISCLAIMED BY YOU TO US AND BY US TO YOU. TO THE EXTENT THAT ANY SUCH WARRANTIES CANNOT BE DISCLAIMED, SUCH WARRANTY IS LIMITED IN DURATION AND EXTENT TO THE MINIMUM PERIOD AND EXTENT PERMITTED BY LAW.</p>"},{"location":"cla/#6-consequential-damage-waiver","title":"6. Consequential damage waiver","text":"<p>TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL YOU OR WE BE LIABLE FOR ANY LOSS OF PROFITS, LOSS OF ANTICIPATED SAVINGS, LOSS OF DATA, INDIRECT, SPECIAL, INCIDENTAL, CONSEQUENTIAL AND EXEMPLARY DAMAGES ARISING OUT OF THIS AGREEMENT REGARDLESS OF THE LEGAL OR EQUITABLE THEORY (CONTRACT, TORT OR OTHERWISE) UPON WHICH THE CLAIM IS BASED.</p>"},{"location":"cla/#7-approximation-of-disclaimer-and-damage-waiver","title":"7. Approximation of disclaimer and damage waiver","text":"<p>IF THE DISCLAIMER AND DAMAGE WAIVER MENTIONED IN SECTION 5. AND SECTION 6. CANNOT BE GIVEN LEGAL EFFECT UNDER APPLICABLE LOCAL LAW, REVIEWING COURTS SHALL APPLY LOCAL LAW THAT MOST CLOSELY APPROXIMATES AN ABSOLUTE WAIVER OF ALL CIVIL OR CONTRACTUAL LIABILITY IN CONNECTION WITH THE CONTRIBUTION.</p>"},{"location":"cla/#8-term","title":"8. Term","text":"<p>8.1 This Agreement shall come into effect upon Your acceptance of the terms and conditions.</p> <p>8.2 This Agreement shall apply for the term of the copyright and patents licensed here. However, You shall have the right to terminate the Agreement if We do not fulfill the obligations as set forth in Section 4. Such termination must be made in writing.</p> <p>8.3 In the event of a termination of this Agreement Sections 5, 6, 7, 8 and 9 shall survive such termination and shall remain in full force thereafter. For the avoidance of doubt, Free and Open Source Software (sub)licenses that have already been granted for Contributions at the date of the termination shall remain in full force after the termination of this Agreement.</p>"},{"location":"cla/#9-miscellaneous","title":"9. Miscellaneous","text":"<p>9.1 This Agreement and all disputes, claims, actions, suits or other proceedings arising out of this agreement or relating in any way to it shall be governed by the laws of Germany excluding its private international law provisions.</p> <p>9.2 This Agreement sets out the entire agreement between You and Us for Your Contributions to Us and overrides all other agreements or understandings.</p> <p>9.3 In case of Your death, this agreement shall continue with Your heirs. In case of more than one heir, all heirs must exercise their rights through a commonly authorized person.</p> <p>9.4 If any provision of this Agreement is found void and unenforceable, such provision will be replaced to the extent possible with a provision that comes closest to the meaning of the original provision and that is enforceable. The terms and conditions set forth in this Agreement shall apply notwithstanding any failure of essential purpose of this Agreement or any limited remedy to the maximum extent possible under law.</p> <p>9.5 You agree to notify Us of any facts or circumstances of which you become aware that would make this Agreement inaccurate in any respect.</p>"},{"location":"code_download/","title":"Code download","text":"<p>Our code is currently stored in a private repository on GitHub, to avoid indexing at this point. We do not share this links on this public website. To access our code and any example notebooks, please use the notebook provided in the links to our submission via the \u201clinktree\u201d in our main paper or the code submission checklist. </p>"},{"location":"contribute/","title":"Contribute","text":"<p>Put out project that people could contribute to and provide instructions for contributing</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#citing","title":"Citing","text":""},{"location":"credits/#acknowledgments","title":"Acknowledgments","text":"<p>We express our gratitude to the following individuals for their valuable contributions and support:</p> <p>Eddie Bergman for his assistance with the evaluation of TabPFN and for his efforts in improving the code quality and documentation. His contributions were instrumental in benchmarking TabPFN and ensuring the reproducibility of our results.</p> <p>Liam Shi Bin Hoo, Anshul Gupta, and David Otte for their work on the Inference Server, which enables the fast deployment of TabPFN without the need for a local GPU. Their efforts have greatly enhanced the accessibility and usability of TabPFN.</p> <p>David Schnurr and Kai Helli for their work on visualization, and David Schnurr for his specific contributions related to handling missing values. Lukas Schweizer for his work on exploring the Random Forest preprocessing for TabPFN further.</p> <p>Andreas M\u00fcller for the insightful discussions related to TabPFN training and for his guidance on identifying and mitigating biases in the prior. His expertise has been invaluable in refining the TabPFN methodology.</p> <p>Stefan St\u00e4glich for his diligent maintenance of the cluster infrastructure.</p> <p>We also extend our thanks to Claudia Langenberg and Maik Pietzner for providing insights on medical applications.</p> <p>We are grateful for the computational resources that were available for this research. Specifically, we acknowledge support by the state of Baden-W\u00fcrttemberg through bwHPC and the German Research Foundation (DFG) through grant no INST 39/963-1 FUGG (bwForCluster NEMO), and by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under grant number 417962828.</p> <p>We gratefully acknowledge funding by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under SFB 1597 (SmallData), grant number 499552394, and by the European Union (via ERC Consolidator Grant DeepLearning 2.0, grant no.~101045765). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them. </p>"},{"location":"enterprise/","title":"TabPFN Enterprise","text":"<p>Transform your organization's data analytics capabilities with TabPFN Enterprise, offering state-of-the-art performance and dedicated support for your mission-critical applications.</p>"},{"location":"enterprise/#why-tabpfn-enterprise","title":"Why TabPFN Enterprise?","text":""},{"location":"enterprise/#superior-model-performance","title":"Superior Model Performance","text":"<ul> <li>Industry-Leading Accuracy: Outperforms traditional methods on 96% of use cases</li> <li>Unprecedented Speed: Get results up to 3,400x faster than traditional approaches</li> <li>Data Efficiency: Achieve the same accuracy with 50% less training data</li> <li>Robust Handling: Native support for missing values, categorical data, and outliers</li> </ul>"},{"location":"enterprise/#enterprise-grade-features","title":"Enterprise-Grade Features","text":"<ul> <li>Priority Access: Get early access to new features and model improvements</li> <li>Custom Development: Request feature development tailored to your specific needs</li> <li>Flexible Deployment: On-premise deployment options and cloud integration support</li> <li>Enhanced Security: Enterprise-grade security features and compliance support</li> </ul>"},{"location":"enterprise/#comprehensive-support","title":"Comprehensive Support","text":"<ul> <li>Dedicated Support Team: Direct access to our technical experts</li> <li>Implementation Assistance: Guidance for optimal integration into your workflow</li> <li>Custom Training: Specialized training sessions for your team</li> <li>Priority Issue Resolution: Guaranteed response times for critical issues</li> </ul> Get In Touch Email Address * First Name * Last Name * Company size * 1-49 50-249 250-999 1000+ Company Website * What are you interested in? *<ul> <li>I want to use Prior Labs products for my business</li> <li>I have a press/event request</li> <li>Other</li> </ul> Marketing Permissions <p>Please select all the ways you would like to hear from PriorLabs:</p> Email <p>You can unsubscribe at any time by clicking the link in the footer of our emails.</p> <p>We use Mailchimp as our marketing platform. By clicking below to subscribe, you acknowledge that your information will be transferred to Mailchimp for processing. Learn more about Mailchimp's privacy practices.</p>"},{"location":"newsletter/","title":"Stay Updated with TabPFN","text":"<p>Join our newsletter to get the latest updates on TabPFN's development, best practices, and breakthrough research in tabular machine learning.</p>"},{"location":"newsletter/#what-youll-get","title":"What You'll Get","text":"<ul> <li>Early Access: Be the first to know about new releases and features</li> <li>Technical Insights: Deep dives into TabPFN's architecture and capabilities</li> <li>Best Practices: Tips and tricks for getting the most out of TabPFN</li> <li>Research Updates: Latest developments in tabular foundation models</li> <li>Community Highlights: Featured projects and use cases from our community</li> </ul> Email Address * Marketing Permissions <p>Please select all the ways you would like to hear from PriorLabs:</p> Email <p>You can unsubscribe at any time by clicking the link in the footer of our emails.</p> <p>We use Mailchimp as our marketing platform. By clicking below to subscribe, you acknowledge that your information will be transferred to Mailchimp for processing. Learn more about Mailchimp's privacy practices.</p>"},{"location":"release_notes/","title":"Release notes","text":"<pre><code># Changelog\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [1.0.0] - 2017-06-20\n</code></pre>"},{"location":"tabpfn-nature/","title":"Highly Accurate Predictions for Small Data With the Tabular Foundation Model TabPFN","text":"<p>Warning</p> <p>This is a beta version of our documentation created for the review phase. Please do not share this review version.</p> <p>Our code is currently stored in a private repository on GitHub We do not share this links on this public website. To access our code and any example notebooks, please use the notebook provided in the links to our submission via the link in our main paper or the code submission checklist. </p> <p>This page contains usage examples and installation instructions of TabPFN. Please find additional instructions on our Classifiers and Regressors on the respective subpages. An in-depth technical documentation of our software interfaces can be found in the API Reference</p>"},{"location":"tabpfn-nature/#installation","title":"Installation","text":"<p>To install our software, we use pip the python package installer in combination with Git for code-management. Please find the code for installation via the private link shared with you, that also contains the private access tokens to the code. An installation typically takes 5 minutes in a setup python environment. </p> <p>Tip</p> <p>The easiest way to install and run our code is via the Colab Notebooks shared in the link in our submission.</p>"},{"location":"tabpfn-nature/#software-dependencies-and-operating-systems","title":"Software Dependencies and Operating Systems","text":"<p>Python: Version &gt;= 3.9</p> <p>Operating Systems: The software has been tested on major operating systems including:</p> <ul> <li> <p>Ubuntu 20.04, 22.04</p> </li> <li> <p>Windows 10, 11</p> </li> <li> <p>macOS 11.0 (Big Sur) and later</p> </li> </ul> <p>Git Version 2 or later (https://git-scm.com/)</p>"},{"location":"tabpfn-nature/#software-dependencies-as-specified-in-requirementstxt","title":"Software Dependencies (as specified in <code>requirements.txt</code>):","text":"TabPFNTabPFN and Baselines <pre><code>torch&gt;=2.1 (Includes CUDA support in version 2.1 and later)\nscikit-learn&gt;=1.4.2\ntqdm&gt;=4.66.\nnumpy&gt;=1.21.2\nhyperopt==0.2.7 (Note: Earlier versions fail with numpy number generator change)\npre-commit&gt;=3.3.3\neinops&gt;=0.6.0\nscipy&gt;=1.8.0\ntorchmetrics==1.2.0\npytest&gt;=7.1.3\npandas[plot,output_formatting]&gt;=2.0.3,&lt;2.2 (Note: Version 2.2 has a bug with multi-index tables (https://github.com/pandas-dev/pandas/issues/57663), recheck when fixed)\npyyaml&gt;=6.0.1\nkditransform&gt;=0.2.0\n</code></pre> <pre><code>torch&gt;=2.1 (Includes CUDA support in version 2.1 and later)\nscikit-learn&gt;=1.4.2\ntqdm&gt;=4.66.\nnumpy&gt;=1.21.2\nhyperopt==0.2.7 (Note: Earlier versions fail with numpy number generator change)\npre-commit&gt;=3.3.3\neinops&gt;=0.6.0\nscipy&gt;=1.8.0\ntorchmetrics==1.2.0\npytest&gt;=7.1.3\npandas[plot,output_formatting]&gt;=2.0.3,&lt;2.2 (Note: Version 2.2 has a bug with multi-index tables (https://github.com/pandas-dev/pandas/issues/57663), recheck when fixed)\npyyaml&gt;=6.0.1\nkditransform&gt;=0.2.0\nseaborn==0.12.2\nopenml==0.14.1\nnumba&gt;=0.58.1\nshap&gt;=0.44.1\n\n# Baselines\nlightgbm==3.3.5\nxgboost&gt;=2.0.0\ncatboost&gt;=1.1.1\n#auto-sklearn==0.14.5\n#autogluon==0.4.0\n\n# -- Quantile Baseline\nquantile-forest==1.2.4\n</code></pre> <p>For GPU usage CUDA 12.1 has been tested.</p>"},{"location":"tabpfn-nature/#non-standard-hardware","title":"Non-Standard Hardware","text":"<p>GPU: A CUDA-enabled GPU is recommended for optimal performance, though the software can also run on a CPU.</p>"},{"location":"tabpfn-nature/#example-usage","title":"Example usage","text":"ClassificationRegression <pre><code>import numpy as np\nimport sklearn\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\nfrom tabpfn import TabPFNClassifier\n\n# Create a classifier\nclf = TabPFNClassifier(fit_at_predict_time=True)\n\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf.fit(X_train, y_train)\npreds = clf.predict_proba(X_test)\ny_eval = np.argmax(preds, axis=1)\n\nprint('ROC AUC: ', sklearn.metrics.roc_auc_score(y_test, preds, multi_class='ovr'), 'Accuracy', sklearn.metrics.accuracy_score(y_test, y_eval))\n</code></pre> <pre><code>from tabpfn import TabPFNRegressor\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport sklearn\n\nreg = TabPFNRegressor(device='auto')\nX, y = load_diabetes(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg.fit(X_train, y_train)\npreds = reg.predict(X_test)\n\nprint('Mean Squared Error (MSE): ', sklearn.metrics.mean_squared_error(y_test, preds))\nprint('Mean Absolute Error (MAE): ', sklearn.metrics.mean_absolute_error(y_test, preds))\nprint('R-squared (R^2): ', sklearn.metrics.r2_score(y_test, preds))\n</code></pre>"},{"location":"tabpfn-nature/#expected-output","title":"Expected Output","text":"<p>Our models follow the interfaces provided by sklearn, so you can expect the same output as you would from sklearn models. TabPFNClassifier will return a numpy array of shape <code>(n_samples, n_classes)</code> with the probabilities of each class, while TabPFNRegressor will return a numpy array of shape <code>(n_samples,)</code> with the predicted values. For more detailed documentation please check the technical documentation of scripts.estimator.TabPFNClassifier.predict_proba.</p>"},{"location":"tabpfn-nature/#expected-runtime","title":"Expected Runtime","text":"<p>The runtime of the model is dependent on the number of estimators and the size of the dataset. For a dataset of 1000 samples and 4 features, the runtime on GPU is typically less than 1 second. For a dataset of 10000 samples and 4 features, the runtime on GPU is typically less than 10 seconds.</p>"},{"location":"terms-eu-en/","title":"Terms of Service Agreement","text":"<p>This Agreement outlines the terms governing your use of TabPFN and our associated services, software, and websites (\"Services\"). By accepting these Terms or using the Services, you enter into a contractual agreement with us.</p>"},{"location":"terms-eu-en/#about-us","title":"About Us","text":"<p>We are PriorLabs, a team from the Machine Learning Lab at the University of Freiburg, committed to democratizing data science.</p>"},{"location":"terms-eu-en/#specific-terms-for-certain-services","title":"Specific Terms for Certain Services","text":"<p>Your use of our Services may be subject to additional terms depending on the specific Services or features you utilize. These include:</p> <ul> <li>Usage Guidelines: outlining permissible uses of our Services and Content</li> <li>Specific Service Terms: applicable when engaging with certain Services or features</li> <li>Content Sharing and Publication Rules: governing the sharing of Content</li> <li>Terms for Service Credits: relating to the acquisition and utilization of service credits</li> <li>Brand Usage Norms: detailing permissible uses of our trademarks and logos</li> </ul>"},{"location":"terms-eu-en/#account-creation-and-use","title":"Account Creation and Use","text":""},{"location":"terms-eu-en/#age-requirement","title":"Age Requirement","text":"<p>Users must be at least 13 years old or the minimum legal age in their country, with parental or guardian consent if under 18.</p>"},{"location":"terms-eu-en/#account-registration","title":"Account Registration","text":"<p>Accurate and complete information is required for account registration. Your account is personal and should not be shared. You are accountable for all activities under your account. If you are registering on behalf of another individual or entity, you must be authorized to accept these Terms on their behalf.</p>"},{"location":"terms-eu-en/#beta-services","title":"Beta Services","text":"<p>Beta Services, offered in alpha, preview, early access, or beta stages, are provided \"as-is\" for testing purposes.</p> <p>We offer no guarantees regarding these Beta Services, including their up-time, availability, uninterrupted functioning, security of Content, or error-free operation. All warranties, explicit or implied, are disclaimed for Beta Services to the extent allowable by law.</p>"},{"location":"terms-eu-en/#usage-of-our-services","title":"Usage of Our Services","text":""},{"location":"terms-eu-en/#permitted-uses","title":"Permitted Uses","text":"<p>You may access and use our Services in compliance with these Terms and all relevant laws, along with the specific service terms and policies mentioned above.</p>"},{"location":"terms-eu-en/#prohibited-uses","title":"Prohibited Uses","text":"<p>Our Services must not be used for any illegal or harmful activities. This includes:</p> <ul> <li>Violating rights or intellectual property</li> <li>Altering, replicating, leasing, selling, or distributing our Services</li> <li>Engaging in or aiding reverse engineering or extraction of code, models, algorithms, or systems</li> <li>Data extraction or Output use in an unauthorized manner</li> <li>Disrupting our Services or bypassing security measures</li> <li>Utilizing Output to create competing models</li> </ul>"},{"location":"terms-eu-en/#software-use","title":"Software Use","text":"<p>Software provided through our Services may update automatically. This includes open-source components governed by their own licenses.</p>"},{"location":"terms-eu-en/#third-party-services","title":"Third-Party Services","text":"<p>We include third-party software or services, which are subject to their own terms. We are not responsible for these third-party elements.</p>"},{"location":"terms-eu-en/#feedback","title":"Feedback","text":"<p>Your input about our Services is valuable, and we may use it to enhance our offerings without any obligation for compensation.</p>"},{"location":"terms-eu-en/#content-responsibilities","title":"Content Responsibilities","text":""},{"location":"terms-eu-en/#your-content","title":"Your Content","text":"<p>You are responsible for any input (\"Input\") and the resultant output (\"Output\") from our Services (\"Content\"). You must ensure that your Content complies with laws and these Terms. You warrant that you have all necessary rights and permissions for the Input.</p> <p>You are obliged to observe all legal provisions for the collection, processing and use of data that is transmitted to and processed in connection with the Services. In particular, you shall promptly enter into a data processing agreement with PriorLabs (which we will provide) if you intend to transmit personal data to PriorLabs when using the Services. You warrant that you will not collect, process or use any personal data in connection with the use of the Services without the express consent of the data subject or another legal basis.</p>"},{"location":"terms-eu-en/#our-content-usage","title":"Our Content Usage","text":"<p>We may use your Content globally to enhance, maintain, and develop our Services and comply with legal obligations.</p>"},{"location":"terms-eu-en/#opt-out-option","title":"Opt-Out Option","text":"<p>You can opt-out of having your Content used to train our models by adjusting your account settings. Opting out may affect the Services' performance for your use case.</p>"},{"location":"terms-eu-en/#accuracy-and-reliability","title":"Accuracy and Reliability","text":"<p>We constantly strive to improve our Services, but due to the nature of machine learning, results may not always be accurate. You should not solely rely on the Output and are responsible for assessing its accuracy and suitability.</p>"},{"location":"terms-eu-en/#intellectual-property-rights","title":"Intellectual Property Rights","text":"<p>All intellectual property rights in the Services are owned by us and our affiliates.</p>"},{"location":"terms-eu-en/#termination-and-suspension","title":"Termination and Suspension","text":""},{"location":"terms-eu-en/#our-rights","title":"Our Rights","text":"<p>The Services are provided to you free of charge. Therefore, we may cease, suspend, or limit the Services at any time.</p> <p>We reserve the right to suspend or terminate access to our Services or close accounts if:</p> <ul> <li>There is a breach of these Terms or Usage Policies</li> <li>Compliance with legal requirements necessitates it</li> <li>Your use poses a risk to us, our users, or others</li> <li>Your account is inactive for over a year</li> </ul>"},{"location":"terms-eu-en/#limitation-of-liability","title":"Limitation of Liability","text":"<p>The Services are provided to you free of charge. Therefore, our liability is in any cases limited to acts of intent or gross negligence.</p> <p>The strict liability for damages for defects of the Service already existing at the beginning of the Service Term in terms of sec. 536a German Civil Code is excluded. We provide the Services on an \"as is\" basis, which refers in particular to the marketability, availability and security aspects of the contractual software.</p>"},{"location":"terms-eu-en/#final-provisions","title":"Final Provisions","text":"<p>Should individual provisions of the contract be or become invalid in whole or in part, this shall not affect the validity of the remaining provisions.</p> <p>The exclusive place of jurisdiction for all disputes arising from or in connection with the contract is Berlin. PriorLabs shall also be entitled to bring an action at your place of business or at any other competent court.</p> <p>The law of the Federal Republic of Germany shall apply with the exception of its provisions on the choice of law which would lead to the application of another legal system. The validity of the CISG (\"UN Sales Convention\") is excluded.</p>"},{"location":"terms/","title":"Terms of Service Agreement","text":"<p>This Agreement outlines the terms governing your use of TabPFN and our associated services, software, and websites (\"Services\"). By accepting these Terms or using the Services, you enter into a contractual agreement with us.</p>"},{"location":"terms/#about-us","title":"About Us","text":"<p>We are PriorLabs, a team from the Machine Learning Lab at the University of Freiburg, committed to democratizing data science.</p>"},{"location":"terms/#specific-terms-for-certain-services","title":"Specific Terms for Certain Services","text":"<p>Your use of our Services may be subject to additional terms depending on the specific Services or features you utilize. These include:</p> <ul> <li>Usage Guidelines: outlining permissible uses of our Services and Content</li> <li>Specific Service Terms: applicable when engaging with certain Services or features</li> <li>Content Sharing and Publication Rules: governing the sharing of Content</li> <li>Terms for Service Credits: relating to the acquisition and utilization of service credits</li> <li>Brand Usage Norms: detailing permissible uses of our trademarks and logos</li> </ul>"},{"location":"terms/#account-creation-and-use","title":"Account Creation and Use","text":""},{"location":"terms/#age-requirement","title":"Age Requirement","text":"<p>Users must be at least 13 years old or the minimum legal age in their country, with parental or guardian consent if under 18.</p>"},{"location":"terms/#account-registration","title":"Account Registration","text":"<p>Accurate and complete information is required for account registration. Your account is personal and should not be shared. You are accountable for all activities under your account. If you are registering on behalf of another individual or entity, you must be authorized to accept these Terms on their behalf.</p>"},{"location":"terms/#beta-services","title":"Beta Services","text":"<p>Beta Services, offered in alpha, preview, early access, or beta stages, are provided \"as-is\" for testing purposes.</p> <p>We offer no guarantees regarding these Beta Services, including their up-time, availability, uninterrupted functioning, security of Content, or error-free operation. All warranties, explicit or implied, are disclaimed for Beta Services to the extent allowable by law.</p>"},{"location":"terms/#usage-of-our-services","title":"Usage of Our Services","text":""},{"location":"terms/#permitted-uses","title":"Permitted Uses","text":"<p>You may access and use our Services in compliance with these Terms and all relevant laws, along with the specific service terms and policies mentioned above.</p>"},{"location":"terms/#prohibited-uses","title":"Prohibited Uses","text":"<p>Our Services must not be used for any illegal or harmful activities. This includes:</p> <ul> <li>Violating rights or intellectual property</li> <li>Altering, replicating, leasing, selling, or distributing our Services</li> <li>Engaging in or aiding reverse engineering or extraction of code, models, algorithms, or systems</li> <li>Data extraction or Output use in an unauthorized manner</li> <li>Disrupting our Services or bypassing security measures</li> <li>Utilizing Output to create competing models</li> </ul>"},{"location":"terms/#software-use","title":"Software Use","text":"<p>Software provided through our Services may update automatically. This includes open-source components governed by their own licenses.</p>"},{"location":"terms/#third-party-services","title":"Third-Party Services","text":"<p>We include third-party software or services, which are subject to their own terms. We are not responsible for these third-party elements.</p>"},{"location":"terms/#feedback","title":"Feedback","text":"<p>Your input about our Services is valuable, and we may use it to enhance our offerings without any obligation for compensation.</p>"},{"location":"terms/#content-responsibilities","title":"Content Responsibilities","text":""},{"location":"terms/#your-content","title":"Your Content","text":"<p>You are responsible for any input (\"Input\") and the resultant output (\"Output\") from our Services (\"Content\"). You must ensure that your Content complies with laws and these Terms. You warrant that you have all necessary rights and permissions for the Input.</p> <p>You are obliged to observe all legal provisions for the collection, processing and use of data that is transmitted to and processed in connection with the Services. In particular, you shall promptly enter into a data processing agreement with PriorLabs (which we will provide) if you intend to transmit personal data to PriorLabs when using the Services. You warrant that you will not collect, process or use any personal data in connection with the use of the Services without the express consent of the data subject or another legal basis.</p>"},{"location":"terms/#our-content-usage","title":"Our Content Usage","text":"<p>We may use your Content globally to enhance, maintain, and develop our Services and comply with legal obligations.</p>"},{"location":"terms/#opt-out-option","title":"Opt-Out Option","text":"<p>You can opt-out of having your Content used to train our models by adjusting your account settings. Opting out may affect the Services' performance for your use case.</p>"},{"location":"terms/#accuracy-and-reliability","title":"Accuracy and Reliability","text":"<p>We constantly strive to improve our Services, but due to the nature of machine learning, results may not always be accurate. You should not solely rely on the Output and are responsible for assessing its accuracy and suitability.</p>"},{"location":"terms/#intellectual-property-rights","title":"Intellectual Property Rights","text":"<p>All intellectual property rights in the Services are owned by us and our affiliates.</p>"},{"location":"terms/#termination-and-suspension","title":"Termination and Suspension","text":""},{"location":"terms/#our-rights","title":"Our Rights","text":"<p>The Services are provided to you free of charge. Therefore, we may cease, suspend, or limit the Services at any time.</p> <p>We reserve the right to suspend or terminate access to our Services or close accounts if:</p> <ul> <li>There is a breach of these Terms or Usage Policies</li> <li>Compliance with legal requirements necessitates it</li> <li>Your use poses a risk to us, our users, or others</li> <li>Your account is inactive for over a year</li> </ul>"},{"location":"terms/#limitation-of-liability","title":"Limitation of Liability","text":"<p>The Services are provided to you free of charge. Therefore, our liability is in any cases limited to acts of intent or gross negligence.</p> <p>The strict liability for damages for defects of the Service already existing at the beginning of the Service Term in terms of sec. 536a German Civil Code is excluded. We provide the Services on an \"as is\" basis, which refers in particular to the marketability, availability and security aspects of the contractual software.</p>"},{"location":"terms/#final-provisions","title":"Final Provisions","text":"<p>Should individual provisions of the contract be or become invalid in whole or in part, this shall not affect the validity of the remaining provisions.</p> <p>The exclusive place of jurisdiction for all disputes arising from or in connection with the contract is Berlin. PriorLabs shall also be entitled to bring an action at your place of business or at any other competent court.</p> <p>The law of the Federal Republic of Germany shall apply with the exception of its provisions on the choice of law which would lead to the application of another legal system. The validity of the CISG (\"UN Sales Convention\") is excluded.</p>"},{"location":"getting_started/getting_started/","title":"Installation","text":"<p>To install TabPFN, please use the notebooks provided in this review. After review we are going to release our models as a python package on the python repository pypi.</p>"},{"location":"getting_started/getting_started/#example","title":"Example","text":"<p>A simple way to get started with TabPFN using our sklearn interface is demonstrated below. This example shows how to train a classifier on the breast cancer dataset and evaluate its accuracy.</p> <p><pre><code>from sklearn.metrics import accuracy_score\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\n\nfrom tabpfn import TabPFNClassifier\n\n# Load data\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n# Initialize classifier\nclassifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=32)\n\n# Train classifier\nclassifier.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = classifier.predict(X_test)\nprint('Accuracy:', accuracy_score(y_test, y_pred))\n</code></pre> This example demonstrates the basic workflow of training and predicting with TabPFN models. For more advanced usage, including handling of categorical data, please refer to the Advanced Usage section.</p>"},{"location":"getting_started/install/","title":"Installation","text":"<p>You can access our models through our API (https://github.com/automl/tabpfn-client) or via our user interface built on top of the API (https://www.priorlabs.ai/tabpfn-gui). We will release open weights models soon, currently we are available via api and via our user interface built on top of the API.</p> Python API Client (No GPU, Online)Python Local (GPU) <pre><code>pip install tabpfn-client\n</code></pre> <p>To log into your account, create an account through our website or through the programmatic interface. Then log into that account by setting the token with</p> <pre><code>from tabpfn_client import config\n\n# Retrieve Token\nwith open(config.g_tabpfn_config.user_auth_handler.CACHED_TOKEN_FILE, 'r') as file:\n    token = file.read()\nprint(f\"TOKEN: {token}\")\nfrom tabpfn_client import config\n\n# Set Token\nservice_client = config.ServiceClient()\nconfig.g_tabpfn_config.user_auth_handler = config.UserAuthenticationClient(service_client=service_client)\nuser_auth = config.g_tabpfn_config.user_auth_handler.set_token(token)\n</code></pre> <p>Warning</p> <p>Not released yet</p>"},{"location":"getting_started/intended_use/","title":"Usage tips","text":""},{"location":"getting_started/intended_use/#when-to-use-tabpfn","title":"When to use TabPFN","text":"<p>TabPFN excels in handling small to medium-sized datasets with up to 10,000 samples and 500 features. For larger datasets, approaches such as CatBoost, XGB, or AutoGluon are likely to outperform TabPFN.</p>"},{"location":"getting_started/intended_use/#intended-use-of-tabpfn","title":"Intended Use of TabPFN","text":"<p>While TabPFN provides a powerful drop-in replacement for traditional tabular data models, achieving top performance on real-world problems often requires domain expertise and the ingenuity of data scientists. Data scientists should continue to apply their skills in feature engineering, data cleaning, and problem framing to get the most out of TabPFN.</p>"},{"location":"getting_started/intended_use/#limitations-of-tabpfn","title":"Limitations of TabPFN","text":"<ol> <li>TabPFN's inference speed may be slower than highly optimized approaches like CatBoost.</li> <li>TabPFN's memory usage scales linearly with dataset size, which can be prohibitive for very large datasets.</li> <li>Our evaluation focused on datasets with up to 10,000 samples and 500 features; scalability to larger datasets requires further study.</li> </ol>"},{"location":"getting_started/intended_use/#computational-and-time-requirements","title":"Computational and Time Requirements","text":"<p>TabPFN is computationally efficient and can run on consumer hardware for most datasets. Training on a new dataset is recommended to run on a GPU as this speeds it up significantly. However, TabPFN is not optimized for real-time inference tasks.</p>"},{"location":"getting_started/intended_use/#data-preparation","title":"Data Preparation","text":"<p>TabPFN can handle raw data with minimal preprocessing. Provide the data in a tabular format, and TabPFN will automatically handle missing values, encode categorical variables, and normalize features. While TabPFN works well out-of-the-box, performance can further be improved using dataset-specific preprocessings.</p>"},{"location":"getting_started/intended_use/#interpreting-results","title":"Interpreting Results","text":"<p>TabPFN's predictions come with uncertainty estimates, allowing you to assess the reliability of the results. You can use SHAP to interpret TabPFN's predictions and identify the most important features driving the model's decisions.</p>"},{"location":"getting_started/intended_use/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<p>TabPFN provides strong performance out-of-the-box without extensive hyperparameter tuning. If you have additional computational resources, you can further optimize TabPFN's performance using random hyperparameter tuning or the Post-Hoc Ensembling (PHE) technique.</p>"},{"location":"integrations/R/","title":"R","text":""},{"location":"integrations/R/#tabpfn-followups","title":"TabPFN Followups","text":"<p>Forecastpfn: Synthetically-trained zero-shot forecasting    Dooley, Khurana, Mohapatra, Naidu, White Advances in Neural Information Processing Systems, 2024, Volume 36.</p> <p>Interpretable machine learning for TabPFN    Rundel, Kobialka, von Crailsheim, Feurer, Nagler, R{\"u}gamer World Conference on Explainable Artificial Intelligence, 2024, Pages 465--476.</p> <p>Scaling tabpfn: Sketching and feature selection for tabular prior-data fitted networks    Feuer, Hegde, Cohen arXiv preprint arXiv:2311.10609, 2023.</p> <p>In-Context Data Distillation with TabPFN    Ma, Thomas, Yu, Caterini arXiv preprint arXiv:2402.06971, 2024.</p> <p>Tokenize features, enhancing tables: the FT-TABPFN model for tabular classification    Liu, Yang, Liang, Pang, Zou arXiv preprint arXiv:2406.06891, 2024.</p> <p>Towards Localization via Data Embedding for TabPFN    Koshil, Nagler, Feurer, Eggensperger NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Enhancing Classification Performance Through the Synergistic Use of XGBoost, TABPFN, and LGBM Models    Prabowo, others 2023 15<sup>th</sup> International Congress on Advanced Applied Informatics Winter (IIAI-AAI-Winter), 2023, Pages 255--259.</p> <p>The Tabular Foundation Model TabPFN Outperforms Specialized Time Series Forecasting Models Based on Simple Features    Hoo, M{\"u}ller, Salinas, Hutter NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabPFGen--Tabular Data Generation with TabPFN    Ma, Dankar, Stein, Yu, Caterini arXiv preprint arXiv:2406.05216, 2024.</p> <p>Drift-Resilient TabPFN: In-Context Learning Temporal Distribution Shifts on Tabular Data    Helli, Schnurr, Hollmann, M{\"u}ller, Hutter arXiv preprint arXiv:2411.10634, 2024.</p> <p>TabFlex: Scaling Tabular Learning to Millions with Linear Attention    Zeng, Kang, Mueller NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Retrieval \\&amp; Fine-Tuning for In-Context Tabular Models    Thomas, Ma, Hosseinzadeh, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2406.05207, 2024.</p> <p>TabDPT: Scaling Tabular Foundation Models    Ma, Thomas, Hosseinzadeh, Kamkari, Labach, Cresswell, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2410.18164, 2024.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    Breejen, Bae, Cha, Yun arXiv preprint arXiv:2405.13396, 2024.</p> <p>MotherNet: Fast Training and Inference via Hyper-Network Transformers    Mueller, Curino, Ramakrishnan NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Mixture of In-Context Prompters for Tabular PFNs    Xu, Cirit, Asadi, Sun, Wang arXiv preprint arXiv:2405.16156, 2024.</p> <p>Fast and Accurate Zero-Training Classification for Tabular Engineering Data    Picard, Ahmed arXiv preprint arXiv:2401.06948, 2024.</p> <p>Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning    den Breejen, Bae, Cha, Kim, Koh, Yun NeurIPS 2023 Second Table Representation Learning Workshop, 2023.</p> <p>TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks    Feuer, Schirrmeister, Cherepanova, Hegde, Hutter, Goldblum, Cohen, White arXiv preprint arXiv:2402.11137, 2024.</p> <p>Exploration of autoregressive models for in-context learning on tabular data    Baur, Kim NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting    Margeloiu, Bazaga, Simidjievski, Li{`o}, Jamnik arXiv preprint arXiv:2406.01805, 2024.</p> <p>Large Scale Transfer Learning for Tabular Data via Language Modeling    Gardner, Perdomo, Schmidt arXiv preprint arXiv:2406.12031, 2024.</p> <p>AnnotatedTables: A Large Tabular Dataset with Language Model Annotations    Hu, Fountalis, Tian, Vasiloglou arXiv preprint arXiv:2406.16349, 2024.</p> <p>TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling    Gorishniy, Kotelnikov, Babenko arXiv preprint arXiv:2410.24210, 2024.</p> <p>Pre-Trained Tabular Transformer for Real-Time, Efficient, Stable Radiomics Data Processing: A Comprehensive Study    Jiang, Jia, Zhang, Li 2023 IEEE International Conference on E-health Networking, Application \\&amp; Services (Healthcom), 2023, Pages 276--281.</p> <p>TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik arXiv preprint arXiv:2409.16118, 2024.</p> <p>Augmenting Small-size Tabular Data with Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>FORECASTPFN: ZERO-SHOT LOW-RESOURCE FORECASTING    Khurana, Dooley, Naidu, White, AI No Source, No Year.</p> <p>What exactly has TabPFN learned to do?    McCarter The Third Blogpost Track at ICLR 2024, No Year.</p> <p>Statistical foundations of prior-data fitted networks    Nagler International Conference on Machine Learning, 2023, Pages 25660--25676.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    den Breejen, Bae, Cha, Yun arXiv e-prints, 2024, Pages arXiv--2405.</p>"},{"location":"integrations/R/#tabpfn-application","title":"TabPFN Application","text":"<p>Large-scale chemoproteomics expedites ligand discovery and predicts ligand behavior in cells    Offensperger, Tin, Duran-Frigola, Hahn, Dobner, Ende, Strohbach, Rukavina, Brennsteiner, Ogilvie, others Science, 2024, Volume 384, Issue 6694, Pages eadk5864.</p> <p>Deep learning for cross-selling health insurance classification    Chu, Than, Jo 2024 International Conference on Green Energy, Computing and Sustainable Technology (GECOST), 2024, Pages 453--457.</p> <p>Early fault classification in rotating machinery with limited data using TabPFN    Magad{'a}n, Rold{'a}n-G{'o}mez, Granda, Su{'a}rez IEEE Sensors Journal, 2023.</p> <p>Artificial intelligence-driven predictive framework for early detection of still birth    Alzakari, Aldrees, Umer, Cascone, Innab, Ashraf SLAS technology, 2024, Volume 29, Issue 6, Pages 100203.</p> <p>Prostate Cancer Diagnosis via Visual Representation of Tabular Data and Deep Transfer Learning    El-Melegy, Mamdouh, Ali, Badawy, El-Ghar, Alghamdi, El-Baz Bioengineering, 2024, Volume 11, Issue 7, Pages 635.</p> <p>A machine learning-based approach for individualized prediction of short-term outcomes after anterior cervical corpectomy    Karabacak, Schupper, Carr, Margetis Asian Spine Journal, 2024, Volume 18, Issue 4, Pages 541.</p> <p>Comparing the Performance of a Deep Learning Model (TabPFN) for Predicting River Algal Blooms with Varying Data Composition    Yang, Park Journal of Wetlands Research, 2024, Volume 26, Issue 3, Pages 197--203.</p> <p>Adapting TabPFN for Zero-Inflated Metagenomic Data    Perciballi, Granese, Fall, Zehraoui, Prifti, Zucker NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Comprehensive peripheral blood immunoprofiling reveals five immunotypes with immunotherapy response characteristics in patients with cancer    Dyikanov, Zaitsev, Vasileva, Wang, Sokolov, Bolshakov, Frank, Turova, Golubeva, Gantseva, others Cancer Cell, 2024, Volume 42, Issue 5, Pages 759--779.</p> <p>Predicting dementia in Parkinson's disease on a small tabular dataset using hybrid LightGBM--TabPFN and SHAP    Tran, Byeon Digital Health, 2024, Volume 10, Pages 20552076241272585.</p> <p>Enhancing actuarial non-life pricing models via transformers    Brauer European Actuarial Journal, 2024, Pages 1--22.</p> <p>Machine learning-based diagnostic prediction of minimal change disease: model development study    Noda, Ichikawa, Shibagaki Scientific Reports, 2024, Volume 14, Issue 1, Pages 23460.</p> <p>Using AutoML and generative AI to predict the type of wildfire propagation in Canadian conifer forests    Khanmohammadi, Cruz, Perrakis, Alexander, Arashpour Ecological Informatics, 2024, Volume 82, Pages 102711.</p> <p>Machine learning applications on lunar meteorite minerals: From classification to mechanical properties prediction    Pe{~n}a-Asensio, Trigo-Rodr{'\\i}guez, Sort, Ib{'a}{~n}ez-Insa, Rimola International Journal of Mining Science and Technology, 2024.</p> <p>Data-Driven Prognostication in Distal Medium Vessel Occlusions Using Explainable Machine Learning    Karabacak, Ozkara, Faizy, Hardigan, Heit, Lakhani, Margetis, Mocco, Nael, Wintermark, others American Journal of Neuroradiology, 2024.</p>"},{"location":"integrations/UI/","title":"UI","text":""},{"location":"integrations/UI/#tabpfn-followups","title":"TabPFN Followups","text":"<p>Forecastpfn: Synthetically-trained zero-shot forecasting    Dooley, Khurana, Mohapatra, Naidu, White Advances in Neural Information Processing Systems, 2024, Volume 36.</p> <p>Interpretable machine learning for TabPFN    Rundel, Kobialka, von Crailsheim, Feurer, Nagler, R{\"u}gamer World Conference on Explainable Artificial Intelligence, 2024, Pages 465--476.</p> <p>Scaling tabpfn: Sketching and feature selection for tabular prior-data fitted networks    Feuer, Hegde, Cohen arXiv preprint arXiv:2311.10609, 2023.</p> <p>In-Context Data Distillation with TabPFN    Ma, Thomas, Yu, Caterini arXiv preprint arXiv:2402.06971, 2024.</p> <p>Tokenize features, enhancing tables: the FT-TABPFN model for tabular classification    Liu, Yang, Liang, Pang, Zou arXiv preprint arXiv:2406.06891, 2024.</p> <p>Towards Localization via Data Embedding for TabPFN    Koshil, Nagler, Feurer, Eggensperger NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Enhancing Classification Performance Through the Synergistic Use of XGBoost, TABPFN, and LGBM Models    Prabowo, others 2023 15<sup>th</sup> International Congress on Advanced Applied Informatics Winter (IIAI-AAI-Winter), 2023, Pages 255--259.</p> <p>The Tabular Foundation Model TabPFN Outperforms Specialized Time Series Forecasting Models Based on Simple Features    Hoo, M{\"u}ller, Salinas, Hutter NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabPFGen--Tabular Data Generation with TabPFN    Ma, Dankar, Stein, Yu, Caterini arXiv preprint arXiv:2406.05216, 2024.</p> <p>Drift-Resilient TabPFN: In-Context Learning Temporal Distribution Shifts on Tabular Data    Helli, Schnurr, Hollmann, M{\"u}ller, Hutter arXiv preprint arXiv:2411.10634, 2024.</p> <p>TabFlex: Scaling Tabular Learning to Millions with Linear Attention    Zeng, Kang, Mueller NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Retrieval \\&amp; Fine-Tuning for In-Context Tabular Models    Thomas, Ma, Hosseinzadeh, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2406.05207, 2024.</p> <p>TabDPT: Scaling Tabular Foundation Models    Ma, Thomas, Hosseinzadeh, Kamkari, Labach, Cresswell, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2410.18164, 2024.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    Breejen, Bae, Cha, Yun arXiv preprint arXiv:2405.13396, 2024.</p> <p>MotherNet: Fast Training and Inference via Hyper-Network Transformers    Mueller, Curino, Ramakrishnan NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Mixture of In-Context Prompters for Tabular PFNs    Xu, Cirit, Asadi, Sun, Wang arXiv preprint arXiv:2405.16156, 2024.</p> <p>Fast and Accurate Zero-Training Classification for Tabular Engineering Data    Picard, Ahmed arXiv preprint arXiv:2401.06948, 2024.</p> <p>Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning    den Breejen, Bae, Cha, Kim, Koh, Yun NeurIPS 2023 Second Table Representation Learning Workshop, 2023.</p> <p>TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks    Feuer, Schirrmeister, Cherepanova, Hegde, Hutter, Goldblum, Cohen, White arXiv preprint arXiv:2402.11137, 2024.</p> <p>Exploration of autoregressive models for in-context learning on tabular data    Baur, Kim NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting    Margeloiu, Bazaga, Simidjievski, Li{`o}, Jamnik arXiv preprint arXiv:2406.01805, 2024.</p> <p>Large Scale Transfer Learning for Tabular Data via Language Modeling    Gardner, Perdomo, Schmidt arXiv preprint arXiv:2406.12031, 2024.</p> <p>AnnotatedTables: A Large Tabular Dataset with Language Model Annotations    Hu, Fountalis, Tian, Vasiloglou arXiv preprint arXiv:2406.16349, 2024.</p> <p>TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling    Gorishniy, Kotelnikov, Babenko arXiv preprint arXiv:2410.24210, 2024.</p> <p>Pre-Trained Tabular Transformer for Real-Time, Efficient, Stable Radiomics Data Processing: A Comprehensive Study    Jiang, Jia, Zhang, Li 2023 IEEE International Conference on E-health Networking, Application \\&amp; Services (Healthcom), 2023, Pages 276--281.</p> <p>TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik arXiv preprint arXiv:2409.16118, 2024.</p> <p>Augmenting Small-size Tabular Data with Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>FORECASTPFN: ZERO-SHOT LOW-RESOURCE FORECASTING    Khurana, Dooley, Naidu, White, AI No Source, No Year.</p> <p>What exactly has TabPFN learned to do?    McCarter The Third Blogpost Track at ICLR 2024, No Year.</p> <p>Statistical foundations of prior-data fitted networks    Nagler International Conference on Machine Learning, 2023, Pages 25660--25676.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    den Breejen, Bae, Cha, Yun arXiv e-prints, 2024, Pages arXiv--2405.</p>"},{"location":"integrations/UI/#tabpfn-application","title":"TabPFN Application","text":"<p>Large-scale chemoproteomics expedites ligand discovery and predicts ligand behavior in cells    Offensperger, Tin, Duran-Frigola, Hahn, Dobner, Ende, Strohbach, Rukavina, Brennsteiner, Ogilvie, others Science, 2024, Volume 384, Issue 6694, Pages eadk5864.</p> <p>Deep learning for cross-selling health insurance classification    Chu, Than, Jo 2024 International Conference on Green Energy, Computing and Sustainable Technology (GECOST), 2024, Pages 453--457.</p> <p>Early fault classification in rotating machinery with limited data using TabPFN    Magad{'a}n, Rold{'a}n-G{'o}mez, Granda, Su{'a}rez IEEE Sensors Journal, 2023.</p> <p>Artificial intelligence-driven predictive framework for early detection of still birth    Alzakari, Aldrees, Umer, Cascone, Innab, Ashraf SLAS technology, 2024, Volume 29, Issue 6, Pages 100203.</p> <p>Prostate Cancer Diagnosis via Visual Representation of Tabular Data and Deep Transfer Learning    El-Melegy, Mamdouh, Ali, Badawy, El-Ghar, Alghamdi, El-Baz Bioengineering, 2024, Volume 11, Issue 7, Pages 635.</p> <p>A machine learning-based approach for individualized prediction of short-term outcomes after anterior cervical corpectomy    Karabacak, Schupper, Carr, Margetis Asian Spine Journal, 2024, Volume 18, Issue 4, Pages 541.</p> <p>Comparing the Performance of a Deep Learning Model (TabPFN) for Predicting River Algal Blooms with Varying Data Composition    Yang, Park Journal of Wetlands Research, 2024, Volume 26, Issue 3, Pages 197--203.</p> <p>Adapting TabPFN for Zero-Inflated Metagenomic Data    Perciballi, Granese, Fall, Zehraoui, Prifti, Zucker NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Comprehensive peripheral blood immunoprofiling reveals five immunotypes with immunotherapy response characteristics in patients with cancer    Dyikanov, Zaitsev, Vasileva, Wang, Sokolov, Bolshakov, Frank, Turova, Golubeva, Gantseva, others Cancer Cell, 2024, Volume 42, Issue 5, Pages 759--779.</p> <p>Predicting dementia in Parkinson's disease on a small tabular dataset using hybrid LightGBM--TabPFN and SHAP    Tran, Byeon Digital Health, 2024, Volume 10, Pages 20552076241272585.</p> <p>Enhancing actuarial non-life pricing models via transformers    Brauer European Actuarial Journal, 2024, Pages 1--22.</p> <p>Machine learning-based diagnostic prediction of minimal change disease: model development study    Noda, Ichikawa, Shibagaki Scientific Reports, 2024, Volume 14, Issue 1, Pages 23460.</p> <p>Using AutoML and generative AI to predict the type of wildfire propagation in Canadian conifer forests    Khanmohammadi, Cruz, Perrakis, Alexander, Arashpour Ecological Informatics, 2024, Volume 82, Pages 102711.</p> <p>Machine learning applications on lunar meteorite minerals: From classification to mechanical properties prediction    Pe{~n}a-Asensio, Trigo-Rodr{'\\i}guez, Sort, Ib{'a}{~n}ez-Insa, Rimola International Journal of Mining Science and Technology, 2024.</p> <p>Data-Driven Prognostication in Distal Medium Vessel Occlusions Using Explainable Machine Learning    Karabacak, Ozkara, Faizy, Hardigan, Heit, Lakhani, Margetis, Mocco, Nael, Wintermark, others American Journal of Neuroradiology, 2024.</p>"},{"location":"integrations/local/","title":"Local","text":""},{"location":"integrations/local/#tabpfn-followups","title":"TabPFN Followups","text":"<p>Forecastpfn: Synthetically-trained zero-shot forecasting    Dooley, Khurana, Mohapatra, Naidu, White Advances in Neural Information Processing Systems, 2024, Volume 36.</p> <p>Interpretable machine learning for TabPFN    Rundel, Kobialka, von Crailsheim, Feurer, Nagler, R{\"u}gamer World Conference on Explainable Artificial Intelligence, 2024, Pages 465--476.</p> <p>Scaling tabpfn: Sketching and feature selection for tabular prior-data fitted networks    Feuer, Hegde, Cohen arXiv preprint arXiv:2311.10609, 2023.</p> <p>In-Context Data Distillation with TabPFN    Ma, Thomas, Yu, Caterini arXiv preprint arXiv:2402.06971, 2024.</p> <p>Tokenize features, enhancing tables: the FT-TABPFN model for tabular classification    Liu, Yang, Liang, Pang, Zou arXiv preprint arXiv:2406.06891, 2024.</p> <p>Towards Localization via Data Embedding for TabPFN    Koshil, Nagler, Feurer, Eggensperger NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Enhancing Classification Performance Through the Synergistic Use of XGBoost, TABPFN, and LGBM Models    Prabowo, others 2023 15<sup>th</sup> International Congress on Advanced Applied Informatics Winter (IIAI-AAI-Winter), 2023, Pages 255--259.</p> <p>The Tabular Foundation Model TabPFN Outperforms Specialized Time Series Forecasting Models Based on Simple Features    Hoo, M{\"u}ller, Salinas, Hutter NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabPFGen--Tabular Data Generation with TabPFN    Ma, Dankar, Stein, Yu, Caterini arXiv preprint arXiv:2406.05216, 2024.</p> <p>Drift-Resilient TabPFN: In-Context Learning Temporal Distribution Shifts on Tabular Data    Helli, Schnurr, Hollmann, M{\"u}ller, Hutter arXiv preprint arXiv:2411.10634, 2024.</p> <p>TabFlex: Scaling Tabular Learning to Millions with Linear Attention    Zeng, Kang, Mueller NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Retrieval \\&amp; Fine-Tuning for In-Context Tabular Models    Thomas, Ma, Hosseinzadeh, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2406.05207, 2024.</p> <p>TabDPT: Scaling Tabular Foundation Models    Ma, Thomas, Hosseinzadeh, Kamkari, Labach, Cresswell, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2410.18164, 2024.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    Breejen, Bae, Cha, Yun arXiv preprint arXiv:2405.13396, 2024.</p> <p>MotherNet: Fast Training and Inference via Hyper-Network Transformers    Mueller, Curino, Ramakrishnan NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Mixture of In-Context Prompters for Tabular PFNs    Xu, Cirit, Asadi, Sun, Wang arXiv preprint arXiv:2405.16156, 2024.</p> <p>Fast and Accurate Zero-Training Classification for Tabular Engineering Data    Picard, Ahmed arXiv preprint arXiv:2401.06948, 2024.</p> <p>Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning    den Breejen, Bae, Cha, Kim, Koh, Yun NeurIPS 2023 Second Table Representation Learning Workshop, 2023.</p> <p>TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks    Feuer, Schirrmeister, Cherepanova, Hegde, Hutter, Goldblum, Cohen, White arXiv preprint arXiv:2402.11137, 2024.</p> <p>Exploration of autoregressive models for in-context learning on tabular data    Baur, Kim NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting    Margeloiu, Bazaga, Simidjievski, Li{`o}, Jamnik arXiv preprint arXiv:2406.01805, 2024.</p> <p>Large Scale Transfer Learning for Tabular Data via Language Modeling    Gardner, Perdomo, Schmidt arXiv preprint arXiv:2406.12031, 2024.</p> <p>AnnotatedTables: A Large Tabular Dataset with Language Model Annotations    Hu, Fountalis, Tian, Vasiloglou arXiv preprint arXiv:2406.16349, 2024.</p> <p>TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling    Gorishniy, Kotelnikov, Babenko arXiv preprint arXiv:2410.24210, 2024.</p> <p>Pre-Trained Tabular Transformer for Real-Time, Efficient, Stable Radiomics Data Processing: A Comprehensive Study    Jiang, Jia, Zhang, Li 2023 IEEE International Conference on E-health Networking, Application \\&amp; Services (Healthcom), 2023, Pages 276--281.</p> <p>TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik arXiv preprint arXiv:2409.16118, 2024.</p> <p>Augmenting Small-size Tabular Data with Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>FORECASTPFN: ZERO-SHOT LOW-RESOURCE FORECASTING    Khurana, Dooley, Naidu, White, AI No Source, No Year.</p> <p>What exactly has TabPFN learned to do?    McCarter The Third Blogpost Track at ICLR 2024, No Year.</p> <p>Statistical foundations of prior-data fitted networks    Nagler International Conference on Machine Learning, 2023, Pages 25660--25676.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    den Breejen, Bae, Cha, Yun arXiv e-prints, 2024, Pages arXiv--2405.</p>"},{"location":"integrations/local/#tabpfn-application","title":"TabPFN Application","text":"<p>Large-scale chemoproteomics expedites ligand discovery and predicts ligand behavior in cells    Offensperger, Tin, Duran-Frigola, Hahn, Dobner, Ende, Strohbach, Rukavina, Brennsteiner, Ogilvie, others Science, 2024, Volume 384, Issue 6694, Pages eadk5864.</p> <p>Deep learning for cross-selling health insurance classification    Chu, Than, Jo 2024 International Conference on Green Energy, Computing and Sustainable Technology (GECOST), 2024, Pages 453--457.</p> <p>Early fault classification in rotating machinery with limited data using TabPFN    Magad{'a}n, Rold{'a}n-G{'o}mez, Granda, Su{'a}rez IEEE Sensors Journal, 2023.</p> <p>Artificial intelligence-driven predictive framework for early detection of still birth    Alzakari, Aldrees, Umer, Cascone, Innab, Ashraf SLAS technology, 2024, Volume 29, Issue 6, Pages 100203.</p> <p>Prostate Cancer Diagnosis via Visual Representation of Tabular Data and Deep Transfer Learning    El-Melegy, Mamdouh, Ali, Badawy, El-Ghar, Alghamdi, El-Baz Bioengineering, 2024, Volume 11, Issue 7, Pages 635.</p> <p>A machine learning-based approach for individualized prediction of short-term outcomes after anterior cervical corpectomy    Karabacak, Schupper, Carr, Margetis Asian Spine Journal, 2024, Volume 18, Issue 4, Pages 541.</p> <p>Comparing the Performance of a Deep Learning Model (TabPFN) for Predicting River Algal Blooms with Varying Data Composition    Yang, Park Journal of Wetlands Research, 2024, Volume 26, Issue 3, Pages 197--203.</p> <p>Adapting TabPFN for Zero-Inflated Metagenomic Data    Perciballi, Granese, Fall, Zehraoui, Prifti, Zucker NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Comprehensive peripheral blood immunoprofiling reveals five immunotypes with immunotherapy response characteristics in patients with cancer    Dyikanov, Zaitsev, Vasileva, Wang, Sokolov, Bolshakov, Frank, Turova, Golubeva, Gantseva, others Cancer Cell, 2024, Volume 42, Issue 5, Pages 759--779.</p> <p>Predicting dementia in Parkinson's disease on a small tabular dataset using hybrid LightGBM--TabPFN and SHAP    Tran, Byeon Digital Health, 2024, Volume 10, Pages 20552076241272585.</p> <p>Enhancing actuarial non-life pricing models via transformers    Brauer European Actuarial Journal, 2024, Pages 1--22.</p> <p>Machine learning-based diagnostic prediction of minimal change disease: model development study    Noda, Ichikawa, Shibagaki Scientific Reports, 2024, Volume 14, Issue 1, Pages 23460.</p> <p>Using AutoML and generative AI to predict the type of wildfire propagation in Canadian conifer forests    Khanmohammadi, Cruz, Perrakis, Alexander, Arashpour Ecological Informatics, 2024, Volume 82, Pages 102711.</p> <p>Machine learning applications on lunar meteorite minerals: From classification to mechanical properties prediction    Pe{~n}a-Asensio, Trigo-Rodr{'\\i}guez, Sort, Ib{'a}{~n}ez-Insa, Rimola International Journal of Mining Science and Technology, 2024.</p> <p>Data-Driven Prognostication in Distal Medium Vessel Occlusions Using Explainable Machine Learning    Karabacak, Ozkara, Faizy, Hardigan, Heit, Lakhani, Margetis, Mocco, Nael, Wintermark, others American Journal of Neuroradiology, 2024.</p>"},{"location":"reference/tabpfn_client/client/","title":"Client","text":""},{"location":"reference/tabpfn_client/client/#tabpfn_client.client","title":"client","text":""},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.DatasetUIDCacheManager","title":"DatasetUIDCacheManager","text":"<p>Manages a cache of the last 50 uploaded datasets, tracking dataset hashes and their UIDs.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.DatasetUIDCacheManager.add_dataset_uid","title":"add_dataset_uid","text":"<pre><code>add_dataset_uid(hash: str, dataset_uid: str)\n</code></pre> <p>Adds a new dataset to the cache, removing the oldest item if the cache exceeds 50 entries. Assumes the dataset is not already in the cache.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.DatasetUIDCacheManager.delete_uid","title":"delete_uid","text":"<pre><code>delete_uid(dataset_uid: str) -&gt; Optional[str]\n</code></pre> <p>Deletes an entry from the cache based on the dataset UID.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.DatasetUIDCacheManager.get_dataset_uid","title":"get_dataset_uid","text":"<pre><code>get_dataset_uid(*args)\n</code></pre> <p>Generates hash by all received arguments and returns cached dataset uid if in cache, otherwise None.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.DatasetUIDCacheManager.load_cache","title":"load_cache","text":"<pre><code>load_cache()\n</code></pre> <p>Loads the cache from disk if it exists, otherwise initializes an empty cache.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.DatasetUIDCacheManager.save_cache","title":"save_cache","text":"<pre><code>save_cache()\n</code></pre> <p>Saves the current cache to disk.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient","title":"ServiceClient","text":"<p>Singleton class for handling communication with the server. It encapsulates all the API calls to the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.delete_all_datasets","title":"delete_all_datasets","text":"<pre><code>delete_all_datasets() -&gt; [str]\n</code></pre> <p>Delete all datasets uploaded by the user from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.delete_all_datasets--returns","title":"Returns","text":"<p>deleted_dataset_uids : [str]     The list of deleted dataset UIDs.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.delete_dataset","title":"delete_dataset","text":"<pre><code>delete_dataset(dataset_uid: str) -&gt; [str]\n</code></pre> <p>Delete the dataset with the provided UID from the server. Note that deleting a train set with lead to deleting all associated test sets.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.delete_dataset--parameters","title":"Parameters","text":"<p>dataset_uid : str     The UID of the dataset to be deleted.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.delete_dataset--returns","title":"Returns","text":"<p>deleted_dataset_uids : [str]     The list of deleted dataset UIDs.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.download_all_data","title":"download_all_data","text":"<pre><code>download_all_data(save_dir: Path) -&gt; Path | None\n</code></pre> <p>Download all data uploaded by the user from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.download_all_data--returns","title":"Returns","text":"<p>save_path : Path | None     The path to the downloaded file. Return None if download fails.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.get_data_summary","title":"get_data_summary","text":"<pre><code>get_data_summary() -&gt; {}\n</code></pre> <p>Get the data summary of the user from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.get_data_summary--returns","title":"Returns","text":"<p>data_summary : {}     The data summary returned from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.get_password_policy","title":"get_password_policy","text":"<pre><code>get_password_policy() -&gt; {}\n</code></pre> <p>Get the password policy from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.get_password_policy--returns","title":"Returns","text":"<p>password_policy : {}     The password policy returned from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.is_auth_token_outdated","title":"is_auth_token_outdated","text":"<pre><code>is_auth_token_outdated(access_token) -&gt; bool | None\n</code></pre> <p>Check if the provided access token is valid and return True if successful.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.login","title":"login","text":"<pre><code>login(email: str, password: str) -&gt; tuple[str, str]\n</code></pre> <p>Login with the provided credentials and return the access token if successful.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.login--parameters","title":"Parameters","text":"<p>email : str password : str</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.login--returns","title":"Returns","text":"<p>access_token : str | None     The access token returned from the server. Return None if login fails. message : str     The message returned from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.predict","title":"predict","text":"<pre><code>predict(\n    train_set_uid: str,\n    x_test,\n    task: Literal[\"classification\", \"regression\"],\n    tabpfn_config: dict | None = None,\n    X_train=None,\n    y_train=None,\n) -&gt; dict[str, ndarray]\n</code></pre> <p>Predict the class labels for the provided data (test set).</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.predict--parameters","title":"Parameters","text":"<p>train_set_uid : str     The unique ID of the train set in the server. x_test : array-like of shape (n_samples, n_features)     The test input.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.predict--returns","title":"Returns","text":"<p>y_pred : array-like of shape (n_samples,)     The predicted class labels.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.register","title":"register","text":"<pre><code>register(\n    email: str,\n    password: str,\n    password_confirm: str,\n    validation_link: str,\n    additional_info: dict,\n)\n</code></pre> <p>Register a new user with the provided credentials.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.register--parameters","title":"Parameters","text":"<p>email : str password : str password_confirm : str validation_link: str additional_info : dict</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.register--returns","title":"Returns","text":"<p>is_created : bool     True if the user is created successfully. message : str     The message returned from the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.retrieve_greeting_messages","title":"retrieve_greeting_messages","text":"<pre><code>retrieve_greeting_messages() -&gt; list[str]\n</code></pre> <p>Retrieve greeting messages that are new for the user.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.send_reset_password_email","title":"send_reset_password_email","text":"<pre><code>send_reset_password_email(email: str) -&gt; tuple[bool, str]\n</code></pre> <p>Let the server send an email for resetting the password.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.send_verification_email","title":"send_verification_email","text":"<pre><code>send_verification_email(\n    access_token: str,\n) -&gt; tuple[bool, str]\n</code></pre> <p>Let the server send an email for verifying the email.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.try_connection","title":"try_connection","text":"<pre><code>try_connection() -&gt; bool\n</code></pre> <p>Check if server is reachable and accepts the connection.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.upload_train_set","title":"upload_train_set","text":"<pre><code>upload_train_set(X, y) -&gt; str\n</code></pre> <p>Upload a train set to server and return the train set UID if successful.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.upload_train_set--parameters","title":"Parameters","text":"<p>X : array-like of shape (n_samples, n_features)     The training input samples. y : array-like of shape (n_samples,) or (n_samples, n_outputs)     The target values.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.upload_train_set--returns","title":"Returns","text":"<p>train_set_uid : str     The unique ID of the train set in the server.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.validate_email","title":"validate_email","text":"<pre><code>validate_email(email: str) -&gt; tuple[bool, str]\n</code></pre> <p>Send entered email to server that checks if it is valid and not already in use.</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.validate_email--parameters","title":"Parameters","text":"<p>email : str</p>"},{"location":"reference/tabpfn_client/client/#tabpfn_client.client.ServiceClient.validate_email--returns","title":"Returns","text":"<p>is_valid : bool     True if the email is valid. message : str     The message returned from the server.</p>"},{"location":"reference/tabpfn_client/config/","title":"Config","text":""},{"location":"reference/tabpfn_client/config/#tabpfn_client.config","title":"config","text":""},{"location":"reference/tabpfn_client/constants/","title":"Constants","text":""},{"location":"reference/tabpfn_client/constants/#tabpfn_client.constants","title":"constants","text":""},{"location":"reference/tabpfn_client/estimator/","title":"Estimator","text":""},{"location":"reference/tabpfn_client/estimator/#tabpfn_client.estimator","title":"estimator","text":""},{"location":"reference/tabpfn_client/estimator/#tabpfn_client.estimator.PreprocessorConfig","title":"PreprocessorConfig  <code>dataclass</code>","text":"<p>Configuration for data preprocessors.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal</code> <p>Name of the preprocessor.</p> <code>categorical_name</code> <code>Literal</code> <p>Name of the categorical encoding method. Valid options are \"none\", \"numeric\",                     \"onehot\", \"ordinal\", \"ordinal_shuffled\". Default is \"none\".</p> <code>append_original</code> <code>bool</code> <p>Whether to append the original features to the transformed features. Default is False.</p> <code>subsample_features</code> <code>float</code> <p>Fraction of features to subsample. -1 means no subsampling. Default is -1.</p> <code>global_transformer_name</code> <code>str</code> <p>Name of the global transformer to use. Default is None.</p>"},{"location":"reference/tabpfn_client/estimator/#tabpfn_client.estimator.TabPFNClassifier","title":"TabPFNClassifier","text":"<p>             Bases: <code>BaseEstimator</code>, <code>ClassifierMixin</code>, <code>TabPFNModelSelection</code></p>"},{"location":"reference/tabpfn_client/estimator/#tabpfn_client.estimator.TabPFNModelSelection","title":"TabPFNModelSelection","text":"<p>Base class for TabPFN model selection and path handling.</p>"},{"location":"reference/tabpfn_client/estimator/#tabpfn_client.estimator.TabPFNRegressor","title":"TabPFNRegressor","text":"<p>             Bases: <code>BaseEstimator</code>, <code>RegressorMixin</code>, <code>TabPFNModelSelection</code></p>"},{"location":"reference/tabpfn_client/estimator/#tabpfn_client.estimator.validate_data_size","title":"validate_data_size","text":"<pre><code>validate_data_size(X: ndarray, y: ndarray | None = None)\n</code></pre> <p>Check the integrity of the training data. - check if the number of rows between X and y is consistent     if y is not None (ValueError) - check if the number of rows is less than MAX_ROWS (ValueError) - check if the number of columns is less than MAX_COLS (ValueError)</p>"},{"location":"reference/tabpfn_client/prompt_agent/","title":"Prompt agent","text":""},{"location":"reference/tabpfn_client/prompt_agent/#tabpfn_client.prompt_agent","title":"prompt_agent","text":""},{"location":"reference/tabpfn_client/prompt_agent/#tabpfn_client.prompt_agent.PromptAgent","title":"PromptAgent","text":""},{"location":"reference/tabpfn_client/prompt_agent/#tabpfn_client.prompt_agent.PromptAgent.password_req_to_policy","title":"password_req_to_policy  <code>staticmethod</code>","text":"<pre><code>password_req_to_policy(password_req: list[str])\n</code></pre> <p>Small function that receives password requirements as a list of strings like \"Length(8)\" and returns a corresponding PasswordPolicy object.</p>"},{"location":"reference/tabpfn_client/service_wrapper/","title":"Service wrapper","text":""},{"location":"reference/tabpfn_client/service_wrapper/#tabpfn_client.service_wrapper","title":"service_wrapper","text":""},{"location":"reference/tabpfn_client/service_wrapper/#tabpfn_client.service_wrapper.InferenceClient","title":"InferenceClient","text":"<p>             Bases: <code>ServiceClientWrapper</code></p> <p>Wrapper of ServiceClient to handle inference, including: - fitting - prediction</p>"},{"location":"reference/tabpfn_client/service_wrapper/#tabpfn_client.service_wrapper.UserAuthenticationClient","title":"UserAuthenticationClient","text":"<p>             Bases: <code>ServiceClientWrapper</code></p> <p>Wrapper of ServiceClient to handle user authentication, including: - user registration and login - access token caching</p>"},{"location":"reference/tabpfn_client/service_wrapper/#tabpfn_client.service_wrapper.UserDataClient","title":"UserDataClient","text":"<p>             Bases: <code>ServiceClientWrapper</code></p> <p>Wrapper of ServiceClient to handle user data, including: - query, or delete user account data - query, download, or delete uploaded data</p>"},{"location":"reference/tabpfn_client/tabpfn_common_utils/regression_pred_result/","title":"Regression pred result","text":""},{"location":"reference/tabpfn_client/tabpfn_common_utils/regression_pred_result/#tabpfn_client.tabpfn_common_utils.regression_pred_result","title":"regression_pred_result","text":""},{"location":"reference/tabpfn_client/tabpfn_common_utils/utils/","title":"Utils","text":""},{"location":"reference/tabpfn_client/tabpfn_common_utils/utils/#tabpfn_client.tabpfn_common_utils.utils","title":"utils","text":""},{"location":"research/papers/","title":"Papers","text":""},{"location":"research/papers/#tabpfn-followups","title":"TabPFN Followups","text":"<p>Forecastpfn: Synthetically-trained zero-shot forecasting    Dooley, Khurana, Mohapatra, Naidu, White Advances in Neural Information Processing Systems, 2024, Volume 36.</p> <p>Interpretable machine learning for TabPFN    Rundel, Kobialka, von Crailsheim, Feurer, Nagler, R{\"u}gamer World Conference on Explainable Artificial Intelligence, 2024, Pages 465--476.</p> <p>Scaling tabpfn: Sketching and feature selection for tabular prior-data fitted networks    Feuer, Hegde, Cohen arXiv preprint arXiv:2311.10609, 2023.</p> <p>In-Context Data Distillation with TabPFN    Ma, Thomas, Yu, Caterini arXiv preprint arXiv:2402.06971, 2024.</p> <p>Tokenize features, enhancing tables: the FT-TABPFN model for tabular classification    Liu, Yang, Liang, Pang, Zou arXiv preprint arXiv:2406.06891, 2024.</p> <p>Towards Localization via Data Embedding for TabPFN    Koshil, Nagler, Feurer, Eggensperger NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Enhancing Classification Performance Through the Synergistic Use of XGBoost, TABPFN, and LGBM Models    Prabowo, others 2023 15<sup>th</sup> International Congress on Advanced Applied Informatics Winter (IIAI-AAI-Winter), 2023, Pages 255--259.</p> <p>The Tabular Foundation Model TabPFN Outperforms Specialized Time Series Forecasting Models Based on Simple Features    Hoo, M{\"u}ller, Salinas, Hutter NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabPFGen--Tabular Data Generation with TabPFN    Ma, Dankar, Stein, Yu, Caterini arXiv preprint arXiv:2406.05216, 2024.</p> <p>Drift-Resilient TabPFN: In-Context Learning Temporal Distribution Shifts on Tabular Data    Helli, Schnurr, Hollmann, M{\"u}ller, Hutter arXiv preprint arXiv:2411.10634, 2024.</p> <p>TabFlex: Scaling Tabular Learning to Millions with Linear Attention    Zeng, Kang, Mueller NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Retrieval \\&amp; Fine-Tuning for In-Context Tabular Models    Thomas, Ma, Hosseinzadeh, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2406.05207, 2024.</p> <p>TabDPT: Scaling Tabular Foundation Models    Ma, Thomas, Hosseinzadeh, Kamkari, Labach, Cresswell, Golestan, Yu, Volkovs, Caterini arXiv preprint arXiv:2410.18164, 2024.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    Breejen, Bae, Cha, Yun arXiv preprint arXiv:2405.13396, 2024.</p> <p>MotherNet: Fast Training and Inference via Hyper-Network Transformers    Mueller, Curino, Ramakrishnan NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Mixture of In-Context Prompters for Tabular PFNs    Xu, Cirit, Asadi, Sun, Wang arXiv preprint arXiv:2405.16156, 2024.</p> <p>Fast and Accurate Zero-Training Classification for Tabular Engineering Data    Picard, Ahmed arXiv preprint arXiv:2401.06948, 2024.</p> <p>Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning    den Breejen, Bae, Cha, Kim, Koh, Yun NeurIPS 2023 Second Table Representation Learning Workshop, 2023.</p> <p>TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks    Feuer, Schirrmeister, Cherepanova, Hegde, Hutter, Goldblum, Cohen, White arXiv preprint arXiv:2402.11137, 2024.</p> <p>Exploration of autoregressive models for in-context learning on tabular data    Baur, Kim NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting    Margeloiu, Bazaga, Simidjievski, Li{`o}, Jamnik arXiv preprint arXiv:2406.01805, 2024.</p> <p>Large Scale Transfer Learning for Tabular Data via Language Modeling    Gardner, Perdomo, Schmidt arXiv preprint arXiv:2406.12031, 2024.</p> <p>AnnotatedTables: A Large Tabular Dataset with Language Model Annotations    Hu, Fountalis, Tian, Vasiloglou arXiv preprint arXiv:2406.16349, 2024.</p> <p>TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling    Gorishniy, Kotelnikov, Babenko arXiv preprint arXiv:2410.24210, 2024.</p> <p>Pre-Trained Tabular Transformer for Real-Time, Efficient, Stable Radiomics Data Processing: A Comprehensive Study    Jiang, Jia, Zhang, Li 2023 IEEE International Conference on E-health Networking, Application \\&amp; Services (Healthcom), 2023, Pages 276--281.</p> <p>TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik arXiv preprint arXiv:2409.16118, 2024.</p> <p>Augmenting Small-size Tabular Data with Class-Specific Energy-Based Models    Margeloiu, Jiang, Simidjievski, Jamnik NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>FORECASTPFN: ZERO-SHOT LOW-RESOURCE FORECASTING    Khurana, Dooley, Naidu, White, AI No Source, No Year.</p> <p>What exactly has TabPFN learned to do?    McCarter The Third Blogpost Track at ICLR 2024, No Year.</p> <p>Statistical foundations of prior-data fitted networks    Nagler International Conference on Machine Learning, 2023, Pages 25660--25676.</p> <p>Why In-Context Learning Transformers are Tabular Data Classifiers    den Breejen, Bae, Cha, Yun arXiv e-prints, 2024, Pages arXiv--2405.</p>"},{"location":"research/papers/#tabpfn-application","title":"TabPFN Application","text":"<p>Large-scale chemoproteomics expedites ligand discovery and predicts ligand behavior in cells    Offensperger, Tin, Duran-Frigola, Hahn, Dobner, Ende, Strohbach, Rukavina, Brennsteiner, Ogilvie, others Science, 2024, Volume 384, Issue 6694, Pages eadk5864.</p> <p>Deep learning for cross-selling health insurance classification    Chu, Than, Jo 2024 International Conference on Green Energy, Computing and Sustainable Technology (GECOST), 2024, Pages 453--457.</p> <p>Early fault classification in rotating machinery with limited data using TabPFN    Magad{'a}n, Rold{'a}n-G{'o}mez, Granda, Su{'a}rez IEEE Sensors Journal, 2023.</p> <p>Artificial intelligence-driven predictive framework for early detection of still birth    Alzakari, Aldrees, Umer, Cascone, Innab, Ashraf SLAS technology, 2024, Volume 29, Issue 6, Pages 100203.</p> <p>Prostate Cancer Diagnosis via Visual Representation of Tabular Data and Deep Transfer Learning    El-Melegy, Mamdouh, Ali, Badawy, El-Ghar, Alghamdi, El-Baz Bioengineering, 2024, Volume 11, Issue 7, Pages 635.</p> <p>A machine learning-based approach for individualized prediction of short-term outcomes after anterior cervical corpectomy    Karabacak, Schupper, Carr, Margetis Asian Spine Journal, 2024, Volume 18, Issue 4, Pages 541.</p> <p>Comparing the Performance of a Deep Learning Model (TabPFN) for Predicting River Algal Blooms with Varying Data Composition    Yang, Park Journal of Wetlands Research, 2024, Volume 26, Issue 3, Pages 197--203.</p> <p>Adapting TabPFN for Zero-Inflated Metagenomic Data    Perciballi, Granese, Fall, Zehraoui, Prifti, Zucker NeurIPS 2024 Third Table Representation Learning Workshop, No Year.</p> <p>Comprehensive peripheral blood immunoprofiling reveals five immunotypes with immunotherapy response characteristics in patients with cancer    Dyikanov, Zaitsev, Vasileva, Wang, Sokolov, Bolshakov, Frank, Turova, Golubeva, Gantseva, others Cancer Cell, 2024, Volume 42, Issue 5, Pages 759--779.</p> <p>Predicting dementia in Parkinson's disease on a small tabular dataset using hybrid LightGBM--TabPFN and SHAP    Tran, Byeon Digital Health, 2024, Volume 10, Pages 20552076241272585.</p> <p>Enhancing actuarial non-life pricing models via transformers    Brauer European Actuarial Journal, 2024, Pages 1--22.</p> <p>Machine learning-based diagnostic prediction of minimal change disease: model development study    Noda, Ichikawa, Shibagaki Scientific Reports, 2024, Volume 14, Issue 1, Pages 23460.</p> <p>Using AutoML and generative AI to predict the type of wildfire propagation in Canadian conifer forests    Khanmohammadi, Cruz, Perrakis, Alexander, Arashpour Ecological Informatics, 2024, Volume 82, Pages 102711.</p> <p>Machine learning applications on lunar meteorite minerals: From classification to mechanical properties prediction    Pe{~n}a-Asensio, Trigo-Rodr{'\\i}guez, Sort, Ib{'a}{~n}ez-Insa, Rimola International Journal of Mining Science and Technology, 2024.</p> <p>Data-Driven Prognostication in Distal Medium Vessel Occlusions Using Explainable Machine Learning    Karabacak, Ozkara, Faizy, Hardigan, Heit, Lakhani, Margetis, Mocco, Nael, Wintermark, others American Journal of Neuroradiology, 2024.</p>"},{"location":"tutorials/cheat_sheet/","title":"Cheat Sheet / Best practices","text":"<p>Look at Autogluon cheat sheet [https://auto.gluon.ai/stable/cheatsheet.html]</p>"},{"location":"tutorials/classification/","title":"Classification","text":"<p>TabPFN provides a powerful interface for handling classification tasks on tabular data. The <code>TabPFNClassifier</code> class can be used for binary and multi-class classification problems.</p>"},{"location":"tutorials/classification/#example","title":"Example","text":"<p>Below is an example of how to use <code>TabPFNClassifier</code> for a multi-class classification task:</p> Python API Client (No GPU, Online)Python Local (GPU) <pre><code>from tabpfn_client import TabPFNClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load the Iris dataset\nX, y = load_iris(return_X_y=True)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train classifier\nclassifier = TabPFNClassifier(device='cuda', N_ensemble_configurations=10)\nclassifier.fit(X_train, y_train)\n\n# Evaluate\ny_pred = classifier.predict(X_test)\nprint('Test Accuracy:', accuracy_score(y_test, y_pred))\n</code></pre> <pre><code>from tabpfn import TabPFNClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load the Iris dataset\nX, y = load_iris(return_X_y=True)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train classifier\nclassifier = TabPFNClassifier(device='cuda', N_ensemble_configurations=10)\nclassifier.fit(X_train, y_train)\n\n# Evaluate\ny_pred = classifier.predict(X_test)\nprint('Test Accuracy:', accuracy_score(y_test, y_pred))\n</code></pre>"},{"location":"tutorials/classification/#example-with-autotabpfnclassifier","title":"Example with AutoTabPFNClassifier","text":"<p>Abstract</p> <p>The AutoTabPFNClassifier and AutoTabPFNRegressor automatically run a hyperparameter search and build an ensemble of strong hyperparameters. You can control the runtime using \u00b4max_time\u00b4 and need to make no further adjustments to get best results.</p> <pre><code>from tabpfn.scripts.estimator.post_hoc_ensembles import AutoTabPFNClassifier, AutoTabPFNRegressor\n# we refer to the PHE variant of TabPFN as AutoTabPFN in the code\nclf = AutoTabPFNClassifier(device='auto', max_time=30)\nX, y = load_breast_cancer(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nclf.fit(X_train, y_train)\n\npreds = clf.predict_proba(X_test)\ny_eval = np.argmax(preds, axis=1)\n\nprint('ROC AUC: ',  sklearn.metrics.roc_auc_score(y_test, preds[:,1], multi_class='ovr'), 'Accuracy', sklearn.metrics.accuracy_score(y_test, y_eval))\n</code></pre>"},{"location":"tutorials/distshift/","title":"Cheat Sheet / Best practices","text":"<p>Look at Autogluon</p>"},{"location":"tutorials/example_competitions/","title":"Cheat Sheet / Best practices","text":"<p>Look at Autogluon</p>"},{"location":"tutorials/regression/","title":"Regression","text":"<p>TabPFN can also be applied to regression tasks using the <code>TabPFNRegressor</code> class. This allows for predictive modeling of continuous outcomes.</p>"},{"location":"tutorials/regression/#example","title":"Example","text":"<p>An example usage of <code>TabPFNRegressor</code> is shown below:</p> Python API Client (No GPU, Online)Python Local (GPU) <pre><code>from tabpfn_client import TabPFNRegressor\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport sklearn\n\nreg = TabPFNRegressor(device='auto')\nX, y = load_diabetes(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg.fit(X_train, y_train)\npreds = reg.predict(X_test)\n\nprint('Mean Squared Error (MSE): ', sklearn.metrics.mean_squared_error(y_test, preds))\nprint('Mean Absolute Error (MAE): ', sklearn.metrics.mean_absolute_error(y_test, preds))\nprint('R-squared (R^2): ', sklearn.metrics.r2_score(y_test, preds))\n</code></pre> <pre><code>from tabpfn import TabPFNRegressor\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport sklearn\n\nreg = TabPFNRegressor(device='auto')\nX, y = load_diabetes(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg.fit(X_train, y_train)\npreds = reg.predict(X_test)\n\nprint('Mean Squared Error (MSE): ', sklearn.metrics.mean_squared_error(y_test, preds))\nprint('Mean Absolute Error (MAE): ', sklearn.metrics.mean_absolute_error(y_test, preds))\nprint('R-squared (R^2): ', sklearn.metrics.r2_score(y_test, preds))\n</code></pre> <p>This example demonstrates how to train and evaluate a regression model. For more details on TabPFNRegressor and its parameters, refer to the API Reference section.</p>"},{"location":"tutorials/regression/#example-with-autotabpfnregressor","title":"Example with AutoTabPFNRegressor","text":"<pre><code>from tabpfn.scripts.estimator.post_hoc_ensembles import AutoTabPFNRegressor\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport sklearn\n\nreg = AutoTabPFNRegressor(device='auto\u2019, max_time=30)\nX, y = load_diabetes(return_X_y=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nreg.fit(X_train, y_train)\npreds = reg.predict(X_test)\n\nprint('Mean Squared Error (MSE): ', sklearn.metrics.mean_squared_error(y_test, preds))\nprint('Mean Absolute Error (MAE): ', sklearn.metrics.mean_absolute_error(y_test, preds))\nprint('R-squared (R^2): ', sklearn.metrics.r2_score(y_test, preds))\n</code></pre>"},{"location":"tutorials/reproduction/","title":"Experimental Reproduction","text":"<p>Our code is currently stored in a private repository on GitHub, to avoid indexing at this point. We do not share this links on this public website. To access our code and any example notebooks, please use the notebook provided in the links to our submission via the \u201clinktree\u201d in our main paper or the code submission checklist. </p>"},{"location":"tutorials/timeseries/","title":"Cheat Sheet / Best practices","text":"<p>Look at Autogluon</p>"},{"location":"tutorials/unsupervised/","title":"Unsupervised functionalities","text":"<pre><code>from tabpfn.scripts.estimator import TabPFNUnsupervisedModel, TabPFNClassifier, TabPFNRegressor\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nmodel_unsupervised = TabPFNUnsupervisedModel(TabPFNClassifier(), TabPFNRegressor())\n\n# Load the Iris dataset\nX, y = load_iris(return_X_y=True)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n\nmodel_unsupervised.fit(X_train, y_train)\nembeddings = model_unsupervised.get_embeddings(X_test)\nX_outliers = model_unsupervised.outliers(X_test)\nX_synthetic = model_unsupervised.generate_synthetic_data(n_samples=100)\n</code></pre>"}]}