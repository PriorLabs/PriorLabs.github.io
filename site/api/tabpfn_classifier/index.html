
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../regression/">
      
      
        <link rel="next" href="../tabpfn_regressor/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.10">
    
    
      
        <title>TabPFNClassifier - TabPFN</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e359304.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#scripts.estimator.TabPFNClassifier" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="TabPFN" class="md-header__button md-logo" aria-label="TabPFN" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            TabPFN
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              TabPFNClassifier
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="TabPFN" class="md-nav__button md-logo" aria-label="TabPFN" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    TabPFN
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting_started/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Classification
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Regression
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    TabPFNClassifier
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    TabPFNClassifier
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.predict_proba" class="md-nav__link">
    <span class="md-ellipsis">
      predict_proba
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.predict_y_proba" class="md-nav__link">
    <span class="md-ellipsis">
      predict_y_proba
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.set_categorical_features" class="md-nav__link">
    <span class="md-ellipsis">
      set_categorical_features
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.score" class="md-nav__link">
    <span class="md-ellipsis">
      score
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.estimate_memory_usage" class="md-nav__link">
    <span class="md-ellipsis">
      estimate_memory_usage
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.estimate_computation_usage" class="md-nav__link">
    <span class="md-ellipsis">
      estimate_computation_usage
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tabpfn_regressor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TabPFNRegressor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model.transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model.mlp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MLP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model.encoders/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Encoders
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.fit" class="md-nav__link">
    <span class="md-ellipsis">
      fit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.predict" class="md-nav__link">
    <span class="md-ellipsis">
      predict
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.predict_proba" class="md-nav__link">
    <span class="md-ellipsis">
      predict_proba
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.predict_y_proba" class="md-nav__link">
    <span class="md-ellipsis">
      predict_y_proba
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.set_categorical_features" class="md-nav__link">
    <span class="md-ellipsis">
      set_categorical_features
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.score" class="md-nav__link">
    <span class="md-ellipsis">
      score
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.estimate_memory_usage" class="md-nav__link">
    <span class="md-ellipsis">
      estimate_memory_usage
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#scripts.estimator.TabPFNClassifier.estimate_computation_usage" class="md-nav__link">
    <span class="md-ellipsis">
      estimate_computation_usage
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<div class="doc doc-object doc-class">



<h1 id="scripts.estimator.TabPFNClassifier" class="doc doc-heading">
          <span class="doc doc-object-name doc-class-name">TabPFNClassifier</span>


<a href="#scripts.estimator.TabPFNClassifier" class="headerlink" title="Permanent link">&para;</a></h1>


  <div class="doc doc-contents first">
          <p class="doc doc-class-bases">
            Bases: <code><span title="scripts.estimator.base.TabPFNBaseModel">TabPFNBaseModel</span></code>, <code><span title="sklearn.base.ClassifierMixin">ClassifierMixin</span></code></p>


            <details class="quote">
              <summary>Source code in <code>scripts/estimator/base.py</code></summary>
              <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2735</span>
<span class="normal">2736</span>
<span class="normal">2737</span>
<span class="normal">2738</span>
<span class="normal">2739</span>
<span class="normal">2740</span>
<span class="normal">2741</span>
<span class="normal">2742</span>
<span class="normal">2743</span>
<span class="normal">2744</span>
<span class="normal">2745</span>
<span class="normal">2746</span>
<span class="normal">2747</span>
<span class="normal">2748</span>
<span class="normal">2749</span>
<span class="normal">2750</span>
<span class="normal">2751</span>
<span class="normal">2752</span>
<span class="normal">2753</span>
<span class="normal">2754</span>
<span class="normal">2755</span>
<span class="normal">2756</span>
<span class="normal">2757</span>
<span class="normal">2758</span>
<span class="normal">2759</span>
<span class="normal">2760</span>
<span class="normal">2761</span>
<span class="normal">2762</span>
<span class="normal">2763</span>
<span class="normal">2764</span>
<span class="normal">2765</span>
<span class="normal">2766</span>
<span class="normal">2767</span>
<span class="normal">2768</span>
<span class="normal">2769</span>
<span class="normal">2770</span>
<span class="normal">2771</span>
<span class="normal">2772</span>
<span class="normal">2773</span>
<span class="normal">2774</span>
<span class="normal">2775</span>
<span class="normal">2776</span>
<span class="normal">2777</span>
<span class="normal">2778</span>
<span class="normal">2779</span>
<span class="normal">2780</span>
<span class="normal">2781</span>
<span class="normal">2782</span>
<span class="normal">2783</span>
<span class="normal">2784</span>
<span class="normal">2785</span>
<span class="normal">2786</span>
<span class="normal">2787</span>
<span class="normal">2788</span>
<span class="normal">2789</span>
<span class="normal">2790</span>
<span class="normal">2791</span>
<span class="normal">2792</span>
<span class="normal">2793</span>
<span class="normal">2794</span>
<span class="normal">2795</span>
<span class="normal">2796</span>
<span class="normal">2797</span>
<span class="normal">2798</span>
<span class="normal">2799</span>
<span class="normal">2800</span>
<span class="normal">2801</span>
<span class="normal">2802</span>
<span class="normal">2803</span>
<span class="normal">2804</span>
<span class="normal">2805</span>
<span class="normal">2806</span>
<span class="normal">2807</span>
<span class="normal">2808</span>
<span class="normal">2809</span>
<span class="normal">2810</span>
<span class="normal">2811</span>
<span class="normal">2812</span>
<span class="normal">2813</span>
<span class="normal">2814</span>
<span class="normal">2815</span>
<span class="normal">2816</span>
<span class="normal">2817</span>
<span class="normal">2818</span>
<span class="normal">2819</span>
<span class="normal">2820</span>
<span class="normal">2821</span>
<span class="normal">2822</span>
<span class="normal">2823</span>
<span class="normal">2824</span>
<span class="normal">2825</span>
<span class="normal">2826</span>
<span class="normal">2827</span>
<span class="normal">2828</span>
<span class="normal">2829</span>
<span class="normal">2830</span>
<span class="normal">2831</span>
<span class="normal">2832</span>
<span class="normal">2833</span>
<span class="normal">2834</span>
<span class="normal">2835</span>
<span class="normal">2836</span>
<span class="normal">2837</span>
<span class="normal">2838</span>
<span class="normal">2839</span>
<span class="normal">2840</span>
<span class="normal">2841</span>
<span class="normal">2842</span>
<span class="normal">2843</span>
<span class="normal">2844</span>
<span class="normal">2845</span>
<span class="normal">2846</span>
<span class="normal">2847</span>
<span class="normal">2848</span>
<span class="normal">2849</span>
<span class="normal">2850</span>
<span class="normal">2851</span>
<span class="normal">2852</span>
<span class="normal">2853</span>
<span class="normal">2854</span>
<span class="normal">2855</span>
<span class="normal">2856</span>
<span class="normal">2857</span>
<span class="normal">2858</span>
<span class="normal">2859</span>
<span class="normal">2860</span>
<span class="normal">2861</span>
<span class="normal">2862</span>
<span class="normal">2863</span>
<span class="normal">2864</span>
<span class="normal">2865</span>
<span class="normal">2866</span>
<span class="normal">2867</span>
<span class="normal">2868</span>
<span class="normal">2869</span>
<span class="normal">2870</span>
<span class="normal">2871</span>
<span class="normal">2872</span>
<span class="normal">2873</span>
<span class="normal">2874</span>
<span class="normal">2875</span>
<span class="normal">2876</span>
<span class="normal">2877</span>
<span class="normal">2878</span>
<span class="normal">2879</span>
<span class="normal">2880</span>
<span class="normal">2881</span>
<span class="normal">2882</span>
<span class="normal">2883</span>
<span class="normal">2884</span>
<span class="normal">2885</span>
<span class="normal">2886</span>
<span class="normal">2887</span>
<span class="normal">2888</span>
<span class="normal">2889</span>
<span class="normal">2890</span>
<span class="normal">2891</span>
<span class="normal">2892</span>
<span class="normal">2893</span>
<span class="normal">2894</span>
<span class="normal">2895</span>
<span class="normal">2896</span>
<span class="normal">2897</span>
<span class="normal">2898</span>
<span class="normal">2899</span>
<span class="normal">2900</span>
<span class="normal">2901</span>
<span class="normal">2902</span>
<span class="normal">2903</span>
<span class="normal">2904</span>
<span class="normal">2905</span>
<span class="normal">2906</span>
<span class="normal">2907</span>
<span class="normal">2908</span>
<span class="normal">2909</span>
<span class="normal">2910</span>
<span class="normal">2911</span>
<span class="normal">2912</span>
<span class="normal">2913</span>
<span class="normal">2914</span>
<span class="normal">2915</span>
<span class="normal">2916</span>
<span class="normal">2917</span>
<span class="normal">2918</span>
<span class="normal">2919</span>
<span class="normal">2920</span>
<span class="normal">2921</span>
<span class="normal">2922</span>
<span class="normal">2923</span>
<span class="normal">2924</span>
<span class="normal">2925</span>
<span class="normal">2926</span>
<span class="normal">2927</span>
<span class="normal">2928</span>
<span class="normal">2929</span>
<span class="normal">2930</span>
<span class="normal">2931</span>
<span class="normal">2932</span>
<span class="normal">2933</span>
<span class="normal">2934</span>
<span class="normal">2935</span>
<span class="normal">2936</span>
<span class="normal">2937</span>
<span class="normal">2938</span>
<span class="normal">2939</span>
<span class="normal">2940</span>
<span class="normal">2941</span>
<span class="normal">2942</span>
<span class="normal">2943</span>
<span class="normal">2944</span>
<span class="normal">2945</span>
<span class="normal">2946</span>
<span class="normal">2947</span>
<span class="normal">2948</span>
<span class="normal">2949</span>
<span class="normal">2950</span>
<span class="normal">2951</span>
<span class="normal">2952</span>
<span class="normal">2953</span>
<span class="normal">2954</span>
<span class="normal">2955</span>
<span class="normal">2956</span>
<span class="normal">2957</span>
<span class="normal">2958</span>
<span class="normal">2959</span>
<span class="normal">2960</span>
<span class="normal">2961</span>
<span class="normal">2962</span>
<span class="normal">2963</span>
<span class="normal">2964</span>
<span class="normal">2965</span>
<span class="normal">2966</span>
<span class="normal">2967</span>
<span class="normal">2968</span>
<span class="normal">2969</span>
<span class="normal">2970</span>
<span class="normal">2971</span>
<span class="normal">2972</span>
<span class="normal">2973</span>
<span class="normal">2974</span>
<span class="normal">2975</span>
<span class="normal">2976</span>
<span class="normal">2977</span>
<span class="normal">2978</span>
<span class="normal">2979</span>
<span class="normal">2980</span>
<span class="normal">2981</span>
<span class="normal">2982</span>
<span class="normal">2983</span>
<span class="normal">2984</span>
<span class="normal">2985</span>
<span class="normal">2986</span>
<span class="normal">2987</span>
<span class="normal">2988</span>
<span class="normal">2989</span>
<span class="normal">2990</span>
<span class="normal">2991</span>
<span class="normal">2992</span>
<span class="normal">2993</span>
<span class="normal">2994</span>
<span class="normal">2995</span>
<span class="normal">2996</span>
<span class="normal">2997</span>
<span class="normal">2998</span>
<span class="normal">2999</span>
<span class="normal">3000</span>
<span class="normal">3001</span>
<span class="normal">3002</span>
<span class="normal">3003</span>
<span class="normal">3004</span>
<span class="normal">3005</span>
<span class="normal">3006</span>
<span class="normal">3007</span>
<span class="normal">3008</span>
<span class="normal">3009</span>
<span class="normal">3010</span>
<span class="normal">3011</span>
<span class="normal">3012</span>
<span class="normal">3013</span>
<span class="normal">3014</span>
<span class="normal">3015</span>
<span class="normal">3016</span>
<span class="normal">3017</span>
<span class="normal">3018</span>
<span class="normal">3019</span>
<span class="normal">3020</span>
<span class="normal">3021</span>
<span class="normal">3022</span>
<span class="normal">3023</span>
<span class="normal">3024</span>
<span class="normal">3025</span>
<span class="normal">3026</span>
<span class="normal">3027</span>
<span class="normal">3028</span>
<span class="normal">3029</span>
<span class="normal">3030</span>
<span class="normal">3031</span>
<span class="normal">3032</span>
<span class="normal">3033</span>
<span class="normal">3034</span>
<span class="normal">3035</span>
<span class="normal">3036</span>
<span class="normal">3037</span>
<span class="normal">3038</span>
<span class="normal">3039</span>
<span class="normal">3040</span>
<span class="normal">3041</span>
<span class="normal">3042</span>
<span class="normal">3043</span>
<span class="normal">3044</span>
<span class="normal">3045</span>
<span class="normal">3046</span>
<span class="normal">3047</span>
<span class="normal">3048</span>
<span class="normal">3049</span>
<span class="normal">3050</span>
<span class="normal">3051</span>
<span class="normal">3052</span>
<span class="normal">3053</span>
<span class="normal">3054</span>
<span class="normal">3055</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TabPFNClassifier</span><span class="p">(</span><span class="n">TabPFNBaseModel</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="n">semisupervised_indicator</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
    <span class="n">metric_type</span> <span class="o">=</span> <span class="n">ClassificationOptimizationMetricType</span>

    <span class="n">predict_function_for_shap</span> <span class="o">=</span> <span class="s2">&quot;predict_proba&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;model_hans_classification.ckpt&quot;</span><span class="p">,</span>
        <span class="n">n_estimators</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">preprocess_transforms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">PreprocessorConfig</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">PreprocessorConfig</span><span class="p">(</span>
                <span class="s2">&quot;quantile_uni_coarse&quot;</span><span class="p">,</span>
                <span class="n">append_original</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">categorical_name</span><span class="o">=</span><span class="s2">&quot;ordinal_very_common_categories_shuffled&quot;</span><span class="p">,</span>
                <span class="n">global_transformer_name</span><span class="o">=</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span>
                <span class="n">subsample_features</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">PreprocessorConfig</span><span class="p">(</span>
                <span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">categorical_name</span><span class="o">=</span><span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="n">subsample_features</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="n">feature_shift_decoder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">,</span>
        <span class="n">normalize_with_test</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">average_logits</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">optimize_metric</span><span class="p">:</span> <span class="n">ClassificationOptimizationMetricType</span> <span class="o">=</span> <span class="s2">&quot;roc&quot;</span><span class="p">,</span>
        <span class="n">transformer_predict_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">multiclass_decoder</span><span class="o">=</span><span class="s2">&quot;shuffle&quot;</span><span class="p">,</span>
        <span class="n">softmax_temperature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">use_poly_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">max_poly_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">transductive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">remove_outliers</span><span class="o">=</span><span class="mf">12.0</span><span class="p">,</span>
        <span class="n">add_fingerprint_features</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">subsample_samples</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="c1"># you can also pass the model directly as torch module and a config dict</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">model_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># The following parameters are not tunable, but specify the execution mode</span>
        <span class="n">fit_at_predict_time</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">batch_size_inference</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">fp16_inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">save_peak_memory</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;True&quot;</span><span class="p">,</span> <span class="s2">&quot;False&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;True&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters:</span>
<span class="sd">            model_path: The model string is the path to the model.</span>
<span class="sd">            n_estimators: The number of ensemble configurations to use, the most important setting.</span>
<span class="sd">            preprocess_transforms: A tuple of strings, specifying the preprocessing steps to use.</span>
<span class="sd">                You can use the following strings as elements &#39;(none|power|quantile|robust)[_all][_and_none]&#39;, where the first</span>
<span class="sd">                part specifies the preprocessing step and the second part specifies the features to apply it to and</span>
<span class="sd">                finally &#39;_and_none&#39; specifies that the original features should be added back to the features in plain.</span>
<span class="sd">                Finally, you can combine all strings without `_all` with `_onehot` to apply one-hot encoding to the categorical</span>
<span class="sd">                features specified with `self.fit(..., categorical_features=...)`.</span>
<span class="sd">            feature_shift_decoder: [&quot;shuffle&quot;, &quot;none&quot;, &quot;local_shuffle&quot;, &quot;rotate&quot;, &quot;auto_rotate&quot;] Whether to shift features for each ensemble configuration.</span>
<span class="sd">            normalize_with_test: If True, the test set is used to normalize the data, otherwise the training set is used only.</span>
<span class="sd">            average_logits: Whether to average logits or probabilities for ensemble members.</span>
<span class="sd">            optimize_metric: The optimization metric to use.</span>
<span class="sd">            transformer_predict_kwargs: Additional keyword arguments to pass to the transformer predict method.</span>
<span class="sd">            multiclass_decoder: The multiclass decoder to use.</span>
<span class="sd">            softmax_temperature: A log spaced temperature, it will be applied as logits &lt;- logits/exp(softmax_temperature).</span>
<span class="sd">            use_poly_features: Whether to use polynomial features as the last preprocessing step.</span>
<span class="sd">            max_poly_features: Maximum number of polynomial features to use, None means unlimited.</span>
<span class="sd">            transductive: Whether to use transductive learning.</span>
<span class="sd">            remove_outliers: If not 0.0, will remove outliers from the input features, where values with a standard deviation</span>
<span class="sd">                larger than remove_outliers will be removed.</span>
<span class="sd">            add_fingerprint_features: If True, will add one feature of random values, that will be added to</span>
<span class="sd">                the input features. This helps discern duplicated samples in the transformer model.</span>
<span class="sd">            subsample_samples: If not None, will use a random subset of the samples for training in each ensemble configuration.</span>
<span class="sd">                If 1 or above, this will subsample to the specified number of samples.</span>
<span class="sd">                If in 0 to 1, the value is viewed as a fraction of the training set size.</span>
<span class="sd">            model: The model, if you want to specify it directly, this is used in combination with model_config.</span>
<span class="sd">            model_config: The config, if you want to specify it directly, this is used in combination with model.</span>
<span class="sd">            fit_at_predict_time: Whether to train the model lazily, i.e. only when it is needed for inference in predict[_proba].</span>
<span class="sd">            device: The device to use for inference, &quot;auto&quot; means that it will use cuda if available, otherwise cpu.</span>
<span class="sd">            seed: The default seed to use for the order of the ensemble configurations, a seed of None will not.</span>
<span class="sd">            show_progress: Whether to show progress bars during training and inference.</span>
<span class="sd">            batch_size_inference: The batch size to use for inference, this does not affect the results, just the</span>
<span class="sd">                memory usage and speed. A higher batch size is faster but uses more memory. Setting the batch size to None</span>
<span class="sd">                means that the batch size is automatically determined based on the memory usage and the maximum free memory</span>
<span class="sd">                specified with `maximum_free_memory_in_gb`.</span>
<span class="sd">            fp16_inference: Whether to use fp16 for inference on GPU, does not affect CPU inference.</span>
<span class="sd">            save_peak_memory: Whether to save the peak memory usage of the model, can enable up to 8 times larger datasets to fit into memory.</span>
<span class="sd">                &quot;True&quot;, means always enabled, &quot;False&quot;, means always disabled, &quot;auto&quot; means that it will be set based on the memory usage.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">optimize_metric</span> <span class="ow">in</span> <span class="n">tp</span><span class="o">.</span><span class="n">get_args</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiclass_decoder</span> <span class="o">=</span> <span class="n">multiclass_decoder</span>

        <span class="c1"># Pass all parameters to super class constructor</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span>
            <span class="n">batch_size_inference</span><span class="o">=</span><span class="n">batch_size_inference</span><span class="p">,</span>
            <span class="n">fp16_inference</span><span class="o">=</span><span class="n">fp16_inference</span><span class="p">,</span>
            <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
            <span class="n">preprocess_transforms</span><span class="o">=</span><span class="n">preprocess_transforms</span><span class="p">,</span>
            <span class="n">feature_shift_decoder</span><span class="o">=</span><span class="n">feature_shift_decoder</span><span class="p">,</span>
            <span class="n">normalize_with_test</span><span class="o">=</span><span class="n">normalize_with_test</span><span class="p">,</span>
            <span class="n">average_logits</span><span class="o">=</span><span class="n">average_logits</span><span class="p">,</span>
            <span class="n">optimize_metric</span><span class="o">=</span><span class="n">optimize_metric</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">transformer_predict_kwargs</span><span class="o">=</span><span class="n">transformer_predict_kwargs</span><span class="p">,</span>
            <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
            <span class="n">softmax_temperature</span><span class="o">=</span><span class="n">softmax_temperature</span><span class="p">,</span>
            <span class="n">save_peak_memory</span><span class="o">=</span><span class="n">save_peak_memory</span><span class="p">,</span>
            <span class="n">use_poly_features</span><span class="o">=</span><span class="n">use_poly_features</span><span class="p">,</span>
            <span class="n">max_poly_features</span><span class="o">=</span><span class="n">max_poly_features</span><span class="p">,</span>
            <span class="n">transductive</span><span class="o">=</span><span class="n">transductive</span><span class="p">,</span>
            <span class="n">remove_outliers</span><span class="o">=</span><span class="n">remove_outliers</span><span class="p">,</span>
            <span class="n">add_fingerprint_features</span><span class="o">=</span><span class="n">add_fingerprint_features</span><span class="p">,</span>
            <span class="n">subsample_samples</span><span class="o">=</span><span class="n">subsample_samples</span><span class="p">,</span>
            <span class="n">fit_at_predict_time</span><span class="o">=</span><span class="n">fit_at_predict_time</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">y_</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">warn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">check_classification_targets</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Get classes and encode before type conversion to guarantee correct class labels.</span>
        <span class="n">not_nan_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">y_</span><span class="p">[</span><span class="n">not_nan_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_</span><span class="p">[</span><span class="n">not_nan_mask</span><span class="p">],</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The number of classes has to be greater than one; got </span><span class="si">%d</span><span class="s2"> class&quot;</span>
                <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="bp">cls</span>

        <span class="c1"># convert type to align with the negative value of the indicator (e.g., avoid uint8)</span>
        <span class="n">y_</span> <span class="o">=</span> <span class="n">y_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">y_</span><span class="p">[</span><span class="o">~</span><span class="n">not_nan_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">TabPFNClassifier</span><span class="o">.</span><span class="n">semisupervised_indicator</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">check_training_data</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">:</span> <span class="n">TabPFNClassifier</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
        <span class="n">y</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">semisupervised_indicator</span>

        <span class="n">unique_labels_</span> <span class="o">=</span> <span class="n">unique_labels</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">has_nan_class_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">clf</span><span class="o">.</span><span class="n">semisupervised_indicator</span> <span class="ow">in</span> <span class="n">unique_labels_</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">clf</span><span class="o">.</span><span class="n">c_processed_</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;semisupervised_enabled&quot;</span><span class="p">,</span> <span class="kc">False</span>
            <span class="p">),</span> <span class="s2">&quot;Semisupervised not enabled for this model&quot;</span>
            <span class="n">has_nan_class_count</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">print_once</span><span class="p">(</span>
                <span class="s2">&quot;Found nan class in training data, will be used as semisupervsied&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels_</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">clf</span><span class="o">.</span><span class="n">max_num_classes_</span> <span class="o">+</span> <span class="n">has_nan_class_count</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The number of classes for this classifier is restricted to </span><span class="si">{</span><span class="n">clf</span><span class="o">.</span><span class="n">max_num_classes_</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Consider wrapping the estimator with `tabpfn.estimator.ManyClassClassifier` to be &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;able to predict more classes&quot;</span>
            <span class="p">)</span>

        <span class="n">clf</span><span class="o">.</span><span class="n">num_classes_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels_</span><span class="p">)</span> <span class="o">-</span> <span class="n">has_nan_class_count</span>

        <span class="c1"># Check that X and y have correct shape</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">force_all_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Store the classes seen during fit</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">_validate_targets</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">label_encoder_</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        <span class="n">y</span><span class="p">[</span>
            <span class="n">y</span> <span class="o">!=</span> <span class="n">TabPFNClassifier</span><span class="o">.</span><span class="n">semisupervised_indicator</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">label_encoder_</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span>
            <span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="n">TabPFNClassifier</span><span class="o">.</span><span class="n">semisupervised_indicator</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">TabPFNBaseModel</span><span class="o">.</span><span class="n">check_training_data</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">init_model_and_get_model_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">init_model_and_get_model_config</span><span class="p">()</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_classification_</span><span class="p">,</span> <span class="s2">&quot;This should be a classification model&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_num_classes_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">c_processed_</span><span class="p">[</span><span class="s2">&quot;max_num_classes&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_post_process_predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prediction</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">:</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sklearn_compatible_precision</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SKLEARN COMPATIBLE PREDICTION FOR DEBUG PURPOSE&quot;</span><span class="p">)</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span>
                <span class="n">prediction</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">16</span>
            <span class="p">)</span>  <span class="c1"># TODO: Do we want this, its just for sklearn</span>
            <span class="n">prediction</span><span class="p">[</span><span class="n">prediction</span> <span class="o">&lt;</span> <span class="mf">0.001</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">/</span> <span class="n">prediction</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabPFNClassifier</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the TabPFNClassifier model to the input data `X` and `y`.</span>

<span class="sd">        The actual training logic is delegated to the `_fit` method, which should be implemented by subclasses.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            X (Union[ndarray, torch.Tensor]): The input feature matrix of shape (n_samples, n_features).</span>
<span class="sd">            y (Union[ndarray, torch.Tensor]): The target labels of shape (n_samples,).</span>
<span class="sd">            additional_y (Optional[Dict[str, torch.Tensor]]): Additional labels to use during training.</span>

<span class="sd">        Returns:</span>
<span class="sd">            TabPFNClassifier: The fitted model object (self).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">additional_y</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_predict</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_</span><span class="p">),</span>
            <span class="n">additional_ys</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">additional_y_</span><span class="p">,</span>
            <span class="n">cache_trainset_representations</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_at_predict_time</span><span class="p">,</span>  <span class="c1"># this will always be true here</span>
            <span class="o">**</span><span class="n">get_params_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">c_processed_</span><span class="p">),</span>
            <span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_predict_kwargs</span> <span class="ow">or</span> <span class="p">{}),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_full</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">get_additional_outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">timing_start</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>
        <span class="n">X_full</span><span class="p">,</span> <span class="n">y_full</span><span class="p">,</span> <span class="n">additional_y</span><span class="p">,</span> <span class="n">eval_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_common_setup</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">additional_y_eval</span><span class="o">=</span><span class="n">additional_y</span>
        <span class="p">)</span>

        <span class="n">prediction</span><span class="p">,</span> <span class="n">additional_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_predict</span><span class="p">(</span>
            <span class="n">X_full</span><span class="p">,</span>
            <span class="n">y_full</span><span class="p">,</span>
            <span class="n">eval_pos</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_at_predict_time</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">additional_ys</span><span class="o">=</span><span class="n">additional_y</span><span class="p">,</span>
            <span class="n">cache_trainset_representations</span><span class="o">=</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_at_predict_time</span><span class="p">,</span>
            <span class="n">reweight_probs_based_on_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizes_balanced_metric</span><span class="p">(),</span>
            <span class="n">get_additional_outputs</span><span class="o">=</span><span class="n">get_additional_outputs</span><span class="p">,</span>
            <span class="o">**</span><span class="n">get_params_from_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">c_processed_</span><span class="p">),</span>
            <span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_predict_kwargs</span> <span class="ow">or</span> <span class="p">{}),</span>
        <span class="p">)</span>

        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_process_predict_proba</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
        <span class="n">timing_end</span><span class="p">(</span><span class="s2">&quot;predict&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">LOG_COMPUTE_TIME_PATH</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_compute_time</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;proba&quot;</span><span class="p">:</span> <span class="n">prediction</span><span class="p">,</span> <span class="o">**</span><span class="n">additional_outputs</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls the transformer to predict the probabilities of the classes of the X test inputs given the previous set</span>
<span class="sd">        training dataset</span>

<span class="sd">        Parameters:</span>
<span class="sd">            X: test datapoints</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_full</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="n">additional_y</span><span class="p">)[</span><span class="s2">&quot;proba&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_winning_probability</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the class labels for the input samples.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            X (array-like): The input samples.</span>
<span class="sd">            return_winning_probability (bool): Whether to return the winning probability.</span>

<span class="sd">        Returns:</span>
<span class="sd">            array: The predicted class labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_winning_probability</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

    <span class="k">def</span> <span class="nf">predict_y_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the probability of the target labels `y` given the input samples `X`.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            X (array-like): The input samples.</span>
<span class="sd">            y (array-like): The target labels.</span>

<span class="sd">        Returns:</span>
<span class="sd">            array: The predicted probabilities of the target labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y_prob</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">y_prob</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the score of the model on the given test data and labels.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            X (array-like): The input samples.</span>
<span class="sd">            y (array-like): The true labels for `X`.</span>
<span class="sd">            sample_weight (array-like, optional): Sample weights.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The computed score.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimize_metric</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;roc&quot;</span><span class="p">,</span> <span class="s2">&quot;auroc&quot;</span><span class="p">,</span> <span class="s2">&quot;log_loss&quot;</span><span class="p">]:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">score_classification</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimize_metric</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.__init__" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#scripts.estimator.TabPFNClassifier.__init__" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span><span class="n">model_path</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">)</span> <span class="o">/</span> <span class="s1">&#39;model_hans_classification.ckpt&#39;</span><span class="p">,</span> <span class="n">n_estimators</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">preprocess_transforms</span><span class="p">:</span> <span class="n"><span title="typing.Tuple">Tuple</span></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="scripts.estimator.configs.PreprocessorConfig" href="../../api_reference/#scripts.estimator.PreprocessorConfig">PreprocessorConfig</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">PreprocessorConfig</span><span class="p">(</span><span class="s1">&#39;quantile_uni_coarse&#39;</span><span class="p">,</span> <span class="n">append_original</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">categorical_name</span><span class="o">=</span><span class="s1">&#39;ordinal_very_common_categories_shuffled&#39;</span><span class="p">,</span> <span class="n">global_transformer_name</span><span class="o">=</span><span class="s1">&#39;svd&#39;</span><span class="p">,</span> <span class="n">subsample_features</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">PreprocessorConfig</span><span class="p">(</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">categorical_name</span><span class="o">=</span><span class="s1">&#39;numeric&#39;</span><span class="p">,</span> <span class="n">subsample_features</span><span class="o">=-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">feature_shift_decoder</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="s1">&#39;shuffle&#39;</span><span class="p">,</span> <span class="n">normalize_with_test</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">average_logits</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">optimize_metric</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="scripts.estimator.base.ClassificationOptimizationMetricType" href="../../api_reference/#scripts.estimator.ClassificationOptimizationMetricType">ClassificationOptimizationMetricType</a></span> <span class="o">=</span> <span class="s1">&#39;roc&#39;</span><span class="p">,</span> <span class="n">transformer_predict_kwargs</span><span class="p">:</span> <span class="n"><span title="typing.Optional">Optional</span></span><span class="p">[</span><span class="n"><span title="typing.Dict">Dict</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">multiclass_decoder</span><span class="o">=</span><span class="s1">&#39;shuffle&#39;</span><span class="p">,</span> <span class="n">softmax_temperature</span><span class="p">:</span> <span class="n"><span title="typing.Optional">Optional</span></span><span class="p">[</span><span class="n">float</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">use_poly_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_poly_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">transductive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">remove_outliers</span><span class="o">=</span><span class="mf">12.0</span><span class="p">,</span> <span class="n">add_fingerprint_features</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">subsample_samples</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n"><span title="typing.Optional">Optional</span></span><span class="p">[</span><span class="n"><span title="torch.nn.Module">Module</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n"><span title="typing.Optional">Optional</span></span><span class="p">[</span><span class="n"><span title="typing.Dict">Dict</span></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">fit_at_predict_time</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="n"><span title="typing.Optional">Optional</span></span><span class="p">[</span><span class="n">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">show_progress</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">batch_size_inference</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fp16_inference</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">save_peak_memory</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="s1">&#39;True&#39;</span><span class="p">,</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span><span class="p">)</span>
</code></pre></div>

  <div class="doc doc-contents ">
  



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model_path</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The model string is the path to the model.</p>
            </div>
          </td>
          <td>
                <code><span title="pathlib.Path">Path</span>(<span title="tabpfn.local_settings.local_model_path">local_model_path</span>) / &#39;model_hans_classification.ckpt&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>n_estimators</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The number of ensemble configurations to use, the most important setting.</p>
            </div>
          </td>
          <td>
                <code>4</code>
          </td>
        </tr>
        <tr>
          <td><code>preprocess_transforms</code></td>
          <td>
                <code><span title="typing.Tuple">Tuple</span>[<a class="autorefs autorefs-internal" title="scripts.estimator.configs.PreprocessorConfig" href="../../api_reference/#scripts.estimator.PreprocessorConfig">PreprocessorConfig</a>, ...]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A tuple of strings, specifying the preprocessing steps to use.
You can use the following strings as elements '(none|power|quantile|robust)[_all][_and_none]', where the first
part specifies the preprocessing step and the second part specifies the features to apply it to and
finally '_and_none' specifies that the original features should be added back to the features in plain.
Finally, you can combine all strings without <code>_all</code> with <code>_onehot</code> to apply one-hot encoding to the categorical
features specified with <code>self.fit(..., categorical_features=...)</code>.</p>
            </div>
          </td>
          <td>
                <code>(<a class="autorefs autorefs-internal" title="scripts.estimator.configs.PreprocessorConfig" href="../../api_reference/#scripts.estimator.PreprocessorConfig">PreprocessorConfig</a>(&#39;quantile_uni_coarse&#39;, append_original=True, categorical_name=&#39;ordinal_very_common_categories_shuffled&#39;, global_transformer_name=&#39;svd&#39;, subsample_features=-1), <a class="autorefs autorefs-internal" title="scripts.estimator.configs.PreprocessorConfig" href="../../api_reference/#scripts.estimator.PreprocessorConfig">PreprocessorConfig</a>(&#39;none&#39;, categorical_name=&#39;numeric&#39;, subsample_features=-1))</code>
          </td>
        </tr>
        <tr>
          <td><code>feature_shift_decoder</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>["shuffle", "none", "local_shuffle", "rotate", "auto_rotate"] Whether to shift features for each ensemble configuration.</p>
            </div>
          </td>
          <td>
                <code>&#39;shuffle&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>normalize_with_test</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If True, the test set is used to normalize the data, otherwise the training set is used only.</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>average_logits</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to average logits or probabilities for ensemble members.</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>optimize_metric</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="scripts.estimator.base.ClassificationOptimizationMetricType" href="../../api_reference/#scripts.estimator.ClassificationOptimizationMetricType">ClassificationOptimizationMetricType</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The optimization metric to use.</p>
            </div>
          </td>
          <td>
                <code>&#39;roc&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>transformer_predict_kwargs</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Additional keyword arguments to pass to the transformer predict method.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>multiclass_decoder</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The multiclass decoder to use.</p>
            </div>
          </td>
          <td>
                <code>&#39;shuffle&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>softmax_temperature</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[float]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A log spaced temperature, it will be applied as logits &lt;- logits/exp(softmax_temperature).</p>
            </div>
          </td>
          <td>
                <code>-0.1</code>
          </td>
        </tr>
        <tr>
          <td><code>use_poly_features</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to use polynomial features as the last preprocessing step.</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>max_poly_features</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Maximum number of polynomial features to use, None means unlimited.</p>
            </div>
          </td>
          <td>
                <code>50</code>
          </td>
        </tr>
        <tr>
          <td><code>transductive</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to use transductive learning.</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>remove_outliers</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If not 0.0, will remove outliers from the input features, where values with a standard deviation
larger than remove_outliers will be removed.</p>
            </div>
          </td>
          <td>
                <code>12.0</code>
          </td>
        </tr>
        <tr>
          <td><code>add_fingerprint_features</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If True, will add one feature of random values, that will be added to
the input features. This helps discern duplicated samples in the transformer model.</p>
            </div>
          </td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>subsample_samples</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If not None, will use a random subset of the samples for training in each ensemble configuration.
If 1 or above, this will subsample to the specified number of samples.
If in 0 to 1, the value is viewed as a fraction of the training set size.</p>
            </div>
          </td>
          <td>
                <code>-1</code>
          </td>
        </tr>
        <tr>
          <td><code>model</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="torch.nn.Module">Module</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The model, if you want to specify it directly, this is used in combination with model_config.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>model_config</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The config, if you want to specify it directly, this is used in combination with model.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>fit_at_predict_time</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to train the model lazily, i.e. only when it is needed for inference in predict[_proba].</p>
            </div>
          </td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>device</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;cuda&#39;, &#39;cpu&#39;, &#39;auto&#39;]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The device to use for inference, "auto" means that it will use cuda if available, otherwise cpu.</p>
            </div>
          </td>
          <td>
                <code>&#39;auto&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>seed</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[int]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The default seed to use for the order of the ensemble configurations, a seed of None will not.</p>
            </div>
          </td>
          <td>
                <code>0</code>
          </td>
        </tr>
        <tr>
          <td><code>show_progress</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to show progress bars during training and inference.</p>
            </div>
          </td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>batch_size_inference</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The batch size to use for inference, this does not affect the results, just the
memory usage and speed. A higher batch size is faster but uses more memory. Setting the batch size to None
means that the batch size is automatically determined based on the memory usage and the maximum free memory
specified with <code>maximum_free_memory_in_gb</code>.</p>
            </div>
          </td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>fp16_inference</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to use fp16 for inference on GPU, does not affect CPU inference.</p>
            </div>
          </td>
          <td>
                <code>True</code>
          </td>
        </tr>
        <tr>
          <td><code>save_peak_memory</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;True&#39;, &#39;False&#39;, &#39;auto&#39;]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to save the peak memory usage of the model, can enable up to 8 times larger datasets to fit into memory.
"True", means always enabled, "False", means always disabled, "auto" means that it will be set based on the memory usage.</p>
            </div>
          </td>
          <td>
                <code>&#39;True&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2741</span>
<span class="normal">2742</span>
<span class="normal">2743</span>
<span class="normal">2744</span>
<span class="normal">2745</span>
<span class="normal">2746</span>
<span class="normal">2747</span>
<span class="normal">2748</span>
<span class="normal">2749</span>
<span class="normal">2750</span>
<span class="normal">2751</span>
<span class="normal">2752</span>
<span class="normal">2753</span>
<span class="normal">2754</span>
<span class="normal">2755</span>
<span class="normal">2756</span>
<span class="normal">2757</span>
<span class="normal">2758</span>
<span class="normal">2759</span>
<span class="normal">2760</span>
<span class="normal">2761</span>
<span class="normal">2762</span>
<span class="normal">2763</span>
<span class="normal">2764</span>
<span class="normal">2765</span>
<span class="normal">2766</span>
<span class="normal">2767</span>
<span class="normal">2768</span>
<span class="normal">2769</span>
<span class="normal">2770</span>
<span class="normal">2771</span>
<span class="normal">2772</span>
<span class="normal">2773</span>
<span class="normal">2774</span>
<span class="normal">2775</span>
<span class="normal">2776</span>
<span class="normal">2777</span>
<span class="normal">2778</span>
<span class="normal">2779</span>
<span class="normal">2780</span>
<span class="normal">2781</span>
<span class="normal">2782</span>
<span class="normal">2783</span>
<span class="normal">2784</span>
<span class="normal">2785</span>
<span class="normal">2786</span>
<span class="normal">2787</span>
<span class="normal">2788</span>
<span class="normal">2789</span>
<span class="normal">2790</span>
<span class="normal">2791</span>
<span class="normal">2792</span>
<span class="normal">2793</span>
<span class="normal">2794</span>
<span class="normal">2795</span>
<span class="normal">2796</span>
<span class="normal">2797</span>
<span class="normal">2798</span>
<span class="normal">2799</span>
<span class="normal">2800</span>
<span class="normal">2801</span>
<span class="normal">2802</span>
<span class="normal">2803</span>
<span class="normal">2804</span>
<span class="normal">2805</span>
<span class="normal">2806</span>
<span class="normal">2807</span>
<span class="normal">2808</span>
<span class="normal">2809</span>
<span class="normal">2810</span>
<span class="normal">2811</span>
<span class="normal">2812</span>
<span class="normal">2813</span>
<span class="normal">2814</span>
<span class="normal">2815</span>
<span class="normal">2816</span>
<span class="normal">2817</span>
<span class="normal">2818</span>
<span class="normal">2819</span>
<span class="normal">2820</span>
<span class="normal">2821</span>
<span class="normal">2822</span>
<span class="normal">2823</span>
<span class="normal">2824</span>
<span class="normal">2825</span>
<span class="normal">2826</span>
<span class="normal">2827</span>
<span class="normal">2828</span>
<span class="normal">2829</span>
<span class="normal">2830</span>
<span class="normal">2831</span>
<span class="normal">2832</span>
<span class="normal">2833</span>
<span class="normal">2834</span>
<span class="normal">2835</span>
<span class="normal">2836</span>
<span class="normal">2837</span>
<span class="normal">2838</span>
<span class="normal">2839</span>
<span class="normal">2840</span>
<span class="normal">2841</span>
<span class="normal">2842</span>
<span class="normal">2843</span>
<span class="normal">2844</span>
<span class="normal">2845</span>
<span class="normal">2846</span>
<span class="normal">2847</span>
<span class="normal">2848</span>
<span class="normal">2849</span>
<span class="normal">2850</span>
<span class="normal">2851</span>
<span class="normal">2852</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;model_hans_classification.ckpt&quot;</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">preprocess_transforms</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">PreprocessorConfig</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">PreprocessorConfig</span><span class="p">(</span>
            <span class="s2">&quot;quantile_uni_coarse&quot;</span><span class="p">,</span>
            <span class="n">append_original</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">categorical_name</span><span class="o">=</span><span class="s2">&quot;ordinal_very_common_categories_shuffled&quot;</span><span class="p">,</span>
            <span class="n">global_transformer_name</span><span class="o">=</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span>
            <span class="n">subsample_features</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">PreprocessorConfig</span><span class="p">(</span>
            <span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">categorical_name</span><span class="o">=</span><span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="n">subsample_features</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">),</span>
    <span class="p">),</span>
    <span class="n">feature_shift_decoder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;shuffle&quot;</span><span class="p">,</span>
    <span class="n">normalize_with_test</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">average_logits</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">optimize_metric</span><span class="p">:</span> <span class="n">ClassificationOptimizationMetricType</span> <span class="o">=</span> <span class="s2">&quot;roc&quot;</span><span class="p">,</span>
    <span class="n">transformer_predict_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">multiclass_decoder</span><span class="o">=</span><span class="s2">&quot;shuffle&quot;</span><span class="p">,</span>
    <span class="n">softmax_temperature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">use_poly_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">max_poly_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">transductive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">remove_outliers</span><span class="o">=</span><span class="mf">12.0</span><span class="p">,</span>
    <span class="n">add_fingerprint_features</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">subsample_samples</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1"># you can also pass the model directly as torch module and a config dict</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># The following parameters are not tunable, but specify the execution mode</span>
    <span class="n">fit_at_predict_time</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">show_progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">batch_size_inference</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">fp16_inference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">save_peak_memory</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;True&quot;</span><span class="p">,</span> <span class="s2">&quot;False&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;True&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters:</span>
<span class="sd">        model_path: The model string is the path to the model.</span>
<span class="sd">        n_estimators: The number of ensemble configurations to use, the most important setting.</span>
<span class="sd">        preprocess_transforms: A tuple of strings, specifying the preprocessing steps to use.</span>
<span class="sd">            You can use the following strings as elements &#39;(none|power|quantile|robust)[_all][_and_none]&#39;, where the first</span>
<span class="sd">            part specifies the preprocessing step and the second part specifies the features to apply it to and</span>
<span class="sd">            finally &#39;_and_none&#39; specifies that the original features should be added back to the features in plain.</span>
<span class="sd">            Finally, you can combine all strings without `_all` with `_onehot` to apply one-hot encoding to the categorical</span>
<span class="sd">            features specified with `self.fit(..., categorical_features=...)`.</span>
<span class="sd">        feature_shift_decoder: [&quot;shuffle&quot;, &quot;none&quot;, &quot;local_shuffle&quot;, &quot;rotate&quot;, &quot;auto_rotate&quot;] Whether to shift features for each ensemble configuration.</span>
<span class="sd">        normalize_with_test: If True, the test set is used to normalize the data, otherwise the training set is used only.</span>
<span class="sd">        average_logits: Whether to average logits or probabilities for ensemble members.</span>
<span class="sd">        optimize_metric: The optimization metric to use.</span>
<span class="sd">        transformer_predict_kwargs: Additional keyword arguments to pass to the transformer predict method.</span>
<span class="sd">        multiclass_decoder: The multiclass decoder to use.</span>
<span class="sd">        softmax_temperature: A log spaced temperature, it will be applied as logits &lt;- logits/exp(softmax_temperature).</span>
<span class="sd">        use_poly_features: Whether to use polynomial features as the last preprocessing step.</span>
<span class="sd">        max_poly_features: Maximum number of polynomial features to use, None means unlimited.</span>
<span class="sd">        transductive: Whether to use transductive learning.</span>
<span class="sd">        remove_outliers: If not 0.0, will remove outliers from the input features, where values with a standard deviation</span>
<span class="sd">            larger than remove_outliers will be removed.</span>
<span class="sd">        add_fingerprint_features: If True, will add one feature of random values, that will be added to</span>
<span class="sd">            the input features. This helps discern duplicated samples in the transformer model.</span>
<span class="sd">        subsample_samples: If not None, will use a random subset of the samples for training in each ensemble configuration.</span>
<span class="sd">            If 1 or above, this will subsample to the specified number of samples.</span>
<span class="sd">            If in 0 to 1, the value is viewed as a fraction of the training set size.</span>
<span class="sd">        model: The model, if you want to specify it directly, this is used in combination with model_config.</span>
<span class="sd">        model_config: The config, if you want to specify it directly, this is used in combination with model.</span>
<span class="sd">        fit_at_predict_time: Whether to train the model lazily, i.e. only when it is needed for inference in predict[_proba].</span>
<span class="sd">        device: The device to use for inference, &quot;auto&quot; means that it will use cuda if available, otherwise cpu.</span>
<span class="sd">        seed: The default seed to use for the order of the ensemble configurations, a seed of None will not.</span>
<span class="sd">        show_progress: Whether to show progress bars during training and inference.</span>
<span class="sd">        batch_size_inference: The batch size to use for inference, this does not affect the results, just the</span>
<span class="sd">            memory usage and speed. A higher batch size is faster but uses more memory. Setting the batch size to None</span>
<span class="sd">            means that the batch size is automatically determined based on the memory usage and the maximum free memory</span>
<span class="sd">            specified with `maximum_free_memory_in_gb`.</span>
<span class="sd">        fp16_inference: Whether to use fp16 for inference on GPU, does not affect CPU inference.</span>
<span class="sd">        save_peak_memory: Whether to save the peak memory usage of the model, can enable up to 8 times larger datasets to fit into memory.</span>
<span class="sd">            &quot;True&quot;, means always enabled, &quot;False&quot;, means always disabled, &quot;auto&quot; means that it will be set based on the memory usage.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">optimize_metric</span> <span class="ow">in</span> <span class="n">tp</span><span class="o">.</span><span class="n">get_args</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_type</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">multiclass_decoder</span> <span class="o">=</span> <span class="n">multiclass_decoder</span>

    <span class="c1"># Pass all parameters to super class constructor</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span>
        <span class="n">batch_size_inference</span><span class="o">=</span><span class="n">batch_size_inference</span><span class="p">,</span>
        <span class="n">fp16_inference</span><span class="o">=</span><span class="n">fp16_inference</span><span class="p">,</span>
        <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>
        <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
        <span class="n">preprocess_transforms</span><span class="o">=</span><span class="n">preprocess_transforms</span><span class="p">,</span>
        <span class="n">feature_shift_decoder</span><span class="o">=</span><span class="n">feature_shift_decoder</span><span class="p">,</span>
        <span class="n">normalize_with_test</span><span class="o">=</span><span class="n">normalize_with_test</span><span class="p">,</span>
        <span class="n">average_logits</span><span class="o">=</span><span class="n">average_logits</span><span class="p">,</span>
        <span class="n">optimize_metric</span><span class="o">=</span><span class="n">optimize_metric</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">transformer_predict_kwargs</span><span class="o">=</span><span class="n">transformer_predict_kwargs</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="o">=</span><span class="n">show_progress</span><span class="p">,</span>
        <span class="n">softmax_temperature</span><span class="o">=</span><span class="n">softmax_temperature</span><span class="p">,</span>
        <span class="n">save_peak_memory</span><span class="o">=</span><span class="n">save_peak_memory</span><span class="p">,</span>
        <span class="n">use_poly_features</span><span class="o">=</span><span class="n">use_poly_features</span><span class="p">,</span>
        <span class="n">max_poly_features</span><span class="o">=</span><span class="n">max_poly_features</span><span class="p">,</span>
        <span class="n">transductive</span><span class="o">=</span><span class="n">transductive</span><span class="p">,</span>
        <span class="n">remove_outliers</span><span class="o">=</span><span class="n">remove_outliers</span><span class="p">,</span>
        <span class="n">add_fingerprint_features</span><span class="o">=</span><span class="n">add_fingerprint_features</span><span class="p">,</span>
        <span class="n">subsample_samples</span><span class="o">=</span><span class="n">subsample_samples</span><span class="p">,</span>
        <span class="n">fit_at_predict_time</span><span class="o">=</span><span class="n">fit_at_predict_time</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.fit" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">fit</span>


<a href="#scripts.estimator.TabPFNClassifier.fit" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="scripts.estimator.base.TabPFNClassifier" href="#scripts.estimator.TabPFNClassifier">TabPFNClassifier</a></span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Fits the TabPFNClassifier model to the input data <code>X</code> and <code>y</code>.</p>
<p>The actual training logic is delegated to the <code>_fit</code> method, which should be implemented by subclasses.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
                <code>Union[ndarray, <span title="torch.Tensor">Tensor</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The input feature matrix of shape (n_samples, n_features).</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td>
                <code>Union[ndarray, <span title="torch.Tensor">Tensor</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The target labels of shape (n_samples,).</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>additional_y</code></td>
          <td>
                <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Additional labels to use during training.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>TabPFNClassifier</code></td>          <td>
                <code><a class="autorefs autorefs-internal" title="scripts.estimator.base.TabPFNClassifier" href="#scripts.estimator.TabPFNClassifier">TabPFNClassifier</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The fitted model object (self).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2938</span>
<span class="normal">2939</span>
<span class="normal">2940</span>
<span class="normal">2941</span>
<span class="normal">2942</span>
<span class="normal">2943</span>
<span class="normal">2944</span>
<span class="normal">2945</span>
<span class="normal">2946</span>
<span class="normal">2947</span>
<span class="normal">2948</span>
<span class="normal">2949</span>
<span class="normal">2950</span>
<span class="normal">2951</span>
<span class="normal">2952</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TabPFNClassifier</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fits the TabPFNClassifier model to the input data `X` and `y`.</span>

<span class="sd">    The actual training logic is delegated to the `_fit` method, which should be implemented by subclasses.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        X (Union[ndarray, torch.Tensor]): The input feature matrix of shape (n_samples, n_features).</span>
<span class="sd">        y (Union[ndarray, torch.Tensor]): The target labels of shape (n_samples,).</span>
<span class="sd">        additional_y (Optional[Dict[str, torch.Tensor]]): Additional labels to use during training.</span>

<span class="sd">    Returns:</span>
<span class="sd">        TabPFNClassifier: The fitted model object (self).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">additional_y</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.predict" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">predict</span>


<a href="#scripts.estimator.TabPFNClassifier.predict" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_winning_probability</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Predict the class labels for the input samples.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
                <code>array - like</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The input samples.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>return_winning_probability</code></td>
          <td>
                <code>bool</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to return the winning probability.</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>array</code></td>          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The predicted class labels.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">3000</span>
<span class="normal">3001</span>
<span class="normal">3002</span>
<span class="normal">3003</span>
<span class="normal">3004</span>
<span class="normal">3005</span>
<span class="normal">3006</span>
<span class="normal">3007</span>
<span class="normal">3008</span>
<span class="normal">3009</span>
<span class="normal">3010</span>
<span class="normal">3011</span>
<span class="normal">3012</span>
<span class="normal">3013</span>
<span class="normal">3014</span>
<span class="normal">3015</span>
<span class="normal">3016</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_winning_probability</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Predict the class labels for the input samples.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        X (array-like): The input samples.</span>
<span class="sd">        return_winning_probability (bool): Whether to return the winning probability.</span>

<span class="sd">    Returns:</span>
<span class="sd">        array: The predicted class labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">return_winning_probability</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.predict_proba" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">predict_proba</span>


<a href="#scripts.estimator.TabPFNClassifier.predict_proba" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Calls the transformer to predict the probabilities of the classes of the X test inputs given the previous set
training dataset</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>test datapoints</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2990</span>
<span class="normal">2991</span>
<span class="normal">2992</span>
<span class="normal">2993</span>
<span class="normal">2994</span>
<span class="normal">2995</span>
<span class="normal">2996</span>
<span class="normal">2997</span>
<span class="normal">2998</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calls the transformer to predict the probabilities of the classes of the X test inputs given the previous set</span>
<span class="sd">    training dataset</span>

<span class="sd">    Parameters:</span>
<span class="sd">        X: test datapoints</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_full</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">additional_y</span><span class="o">=</span><span class="n">additional_y</span><span class="p">)[</span><span class="s2">&quot;proba&quot;</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.predict_y_proba" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">predict_y_proba</span>


<a href="#scripts.estimator.TabPFNClassifier.predict_y_proba" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">predict_y_proba</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Predict the probability of the target labels <code>y</code> given the input samples <code>X</code>.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
                <code>array - like</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The input samples.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td>
                <code>array - like</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The target labels.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>array</code></td>          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The predicted probabilities of the target labels.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">3018</span>
<span class="normal">3019</span>
<span class="normal">3020</span>
<span class="normal">3021</span>
<span class="normal">3022</span>
<span class="normal">3023</span>
<span class="normal">3024</span>
<span class="normal">3025</span>
<span class="normal">3026</span>
<span class="normal">3027</span>
<span class="normal">3028</span>
<span class="normal">3029</span>
<span class="normal">3030</span>
<span class="normal">3031</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">predict_y_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Predict the probability of the target labels `y` given the input samples `X`.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        X (array-like): The input samples.</span>
<span class="sd">        y (array-like): The target labels.</span>

<span class="sd">    Returns:</span>
<span class="sd">        array: The predicted probabilities of the target labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">y_prob</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">y_prob</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.set_categorical_features" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">set_categorical_features</span>


<a href="#scripts.estimator.TabPFNClassifier.set_categorical_features" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">set_categorical_features</span><span class="p">(</span><span class="n">categorical_features</span><span class="p">:</span> <span class="n"><span title="typing.List">List</span></span><span class="p">[</span><span class="n">int</span><span class="p">])</span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Set the categorical features to use for the model.</p>
<p>These categorical features might be overridden by the preprocessing steps.
This is controlled by
i) <code>max_unique_values_as_categorical_feature</code>, the maximum number of unique values
a feature can have to be considered a categorical feature. Features with more unique values
are considered numerical features.
ii) <code>min_unique_values_as_numerical_feature</code> the minimum number of unique values
a feature can have to be considered a numerical feature. Features with less unique values
are considered categorical features.</p>
<p>:param categorical_features: The feature indices of the categorical features</p>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_categorical_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set the categorical features to use for the model.</span>

<span class="sd">    These categorical features might be overridden by the preprocessing steps.</span>
<span class="sd">    This is controlled by</span>
<span class="sd">    i) `max_unique_values_as_categorical_feature`, the maximum number of unique values</span>
<span class="sd">    a feature can have to be considered a categorical feature. Features with more unique values</span>
<span class="sd">    are considered numerical features.</span>
<span class="sd">    ii) `min_unique_values_as_numerical_feature` the minimum number of unique values</span>
<span class="sd">    a feature can have to be considered a numerical feature. Features with less unique values</span>
<span class="sd">    are considered categorical features.</span>

<span class="sd">    :param categorical_features: The feature indices of the categorical features</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">categorical_features</span> <span class="o">=</span> <span class="n">categorical_features</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.score" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">score</span>


<a href="#scripts.estimator.TabPFNClassifier.score" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Compute the score of the model on the given test data and labels.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
                <code>array - like</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The input samples.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td>
                <code>array - like</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The true labels for <code>X</code>.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>sample_weight</code></td>
          <td>
                <code>array - like</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Sample weights.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>float</code></td>          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The computed score.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">3033</span>
<span class="normal">3034</span>
<span class="normal">3035</span>
<span class="normal">3036</span>
<span class="normal">3037</span>
<span class="normal">3038</span>
<span class="normal">3039</span>
<span class="normal">3040</span>
<span class="normal">3041</span>
<span class="normal">3042</span>
<span class="normal">3043</span>
<span class="normal">3044</span>
<span class="normal">3045</span>
<span class="normal">3046</span>
<span class="normal">3047</span>
<span class="normal">3048</span>
<span class="normal">3049</span>
<span class="normal">3050</span>
<span class="normal">3051</span>
<span class="normal">3052</span>
<span class="normal">3053</span>
<span class="normal">3054</span>
<span class="normal">3055</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the score of the model on the given test data and labels.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        X (array-like): The input samples.</span>
<span class="sd">        y (array-like): The true labels for `X`.</span>
<span class="sd">        sample_weight (array-like, optional): Sample weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: The computed score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimize_metric</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;roc&quot;</span><span class="p">,</span> <span class="s2">&quot;auroc&quot;</span><span class="p">,</span> <span class="s2">&quot;log_loss&quot;</span><span class="p">]:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">score_classification</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimize_metric</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.estimate_memory_usage" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">estimate_memory_usage</span>


<a href="#scripts.estimator.TabPFNClassifier.estimate_memory_usage" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">estimate_memory_usage</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n"><span title="numpy.ndarray">ndarray</span></span> <span class="o">|</span> <span class="n"><span title="torch.tensor">tensor</span></span><span class="p">,</span> <span class="n">unit</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;mb&#39;</span><span class="p">,</span> <span class="s1">&#39;gb&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;gb&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">overwrite_params</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">float</span> <span class="o">|</span> <span class="kc">None</span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Estimates the memory usage of the model.</p>
<p>Peak memory usage is accurate for ´save_peak_mem_factor´ in O(n_feats, n_samples) on average but with
significant outliers (2x). Also this calculation does not include baseline usage and constant offsets.
Baseline memory usage can be ignored if we set the maximum memory usage to the default None which uses
the free memory of the system. The constant offsets are not significant for large datasets.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
                <code>ndarray</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The feature matrix. X should represent the concat of train and test in if
<code>self.fit_at_predict_time</code> and train only otherwise. If you add a batch dimension at position 1 to the
table this is used as the batch size used during inference, otherwise this depends on the
<code>batch_size_inference</code> and <code>n_estimators</code>.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>unit</code></td>
          <td>
                <code><span title="typing.Literal">Literal</span>[&#39;b&#39;, &#39;mb&#39;, &#39;gb&#39;]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The unit to return the memory usage in (bytes, megabytes, or gigabytes).</p>
            </div>
          </td>
          <td>
                <code>&#39;gb&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>int</code></td>          <td>
                <code>float | None</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The estimated memory usage in bytes.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1969</span>
<span class="normal">1970</span>
<span class="normal">1971</span>
<span class="normal">1972</span>
<span class="normal">1973</span>
<span class="normal">1974</span>
<span class="normal">1975</span>
<span class="normal">1976</span>
<span class="normal">1977</span>
<span class="normal">1978</span>
<span class="normal">1979</span>
<span class="normal">1980</span>
<span class="normal">1981</span>
<span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span>
<span class="normal">2002</span>
<span class="normal">2003</span>
<span class="normal">2004</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">estimate_memory_usage</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
    <span class="n">unit</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;mb&quot;</span><span class="p">,</span> <span class="s2">&quot;gb&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;gb&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">overwrite_params</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimates the memory usage of the model.</span>

<span class="sd">    Peak memory usage is accurate for ´save_peak_mem_factor´ in O(n_feats, n_samples) on average but with</span>
<span class="sd">    significant outliers (2x). Also this calculation does not include baseline usage and constant offsets.</span>
<span class="sd">    Baseline memory usage can be ignored if we set the maximum memory usage to the default None which uses</span>
<span class="sd">    the free memory of the system. The constant offsets are not significant for large datasets.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        X (ndarray): The feature matrix. X should represent the concat of train and test in if</span>
<span class="sd">            `self.fit_at_predict_time` and train only otherwise. If you add a batch dimension at position 1 to the</span>
<span class="sd">            table this is used as the batch size used during inference, otherwise this depends on the</span>
<span class="sd">            `batch_size_inference` and `n_estimators`.</span>
<span class="sd">        unit (Literal[&quot;b&quot;, &quot;mb&quot;, &quot;gb&quot;]): The unit to return the memory usage in (bytes, megabytes, or gigabytes).</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: The estimated memory usage in bytes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">byte_usage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate_model_usage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;memory&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">overwrite_params</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">byte_usage</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">unit</span> <span class="o">==</span> <span class="s2">&quot;mb&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">byte_usage</span> <span class="o">/</span> <span class="mf">1e6</span>
    <span class="k">elif</span> <span class="n">unit</span> <span class="o">==</span> <span class="s2">&quot;gb&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">byte_usage</span> <span class="o">/</span> <span class="mf">1e9</span>
    <span class="k">elif</span> <span class="n">unit</span> <span class="o">==</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">byte_usage</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown unit </span><span class="si">{</span><span class="n">unit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">



<h2 id="scripts.estimator.TabPFNClassifier.estimate_computation_usage" class="doc doc-heading">
          <span class="doc doc-object-name doc-function-name">estimate_computation_usage</span>


<a href="#scripts.estimator.TabPFNClassifier.estimate_computation_usage" class="headerlink" title="Permanent link">&para;</a></h2>
<div class="doc-signature codehilite"><pre><span></span><code><span class="n">estimate_computation_usage</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n"><span title="numpy.ndarray">ndarray</span></span><span class="p">,</span> <span class="n">unit</span><span class="p">:</span> <span class="n"><span title="typing.Literal">Literal</span></span><span class="p">[</span><span class="s1">&#39;sequential_flops&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sequential_flops&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">overwrite_params</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">float</span> <span class="o">|</span> <span class="kc">None</span>
</code></pre></div>

  <div class="doc doc-contents ">
  
      <p>Estimates the sequential computation usage of the model. Those are the operations that are not parallelizable
and are the main bottleneck for the computation time.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>X</code></td>
          <td>
                <code>ndarray</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The feature matrix. X should represent the concat of train and test in if</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>unit</code></td>
          <td>
                <code>str</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The unit to return the computation usage in.</p>
            </div>
          </td>
          <td>
                <code>&#39;sequential_flops&#39;</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>int</code></td>          <td>
                <code>float | None</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The estimated computation usage in unit of choice.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>scripts/estimator/base.py</code></summary>
            <div class="codehilite"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span>
<span class="normal">2023</span>
<span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">estimate_computation_usage</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">unit</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;sequential_flops&quot;</span><span class="p">,</span> <span class="s2">&quot;s&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;sequential_flops&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">overwrite_params</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimates the sequential computation usage of the model. Those are the operations that are not parallelizable</span>
<span class="sd">    and are the main bottleneck for the computation time.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        X (ndarray): The feature matrix. X should represent the concat of train and test in if</span>
<span class="sd">        ` self.fit_at_predict_time` and train only otherwise. If you add a batch dimension at position 1 to the</span>
<span class="sd">          table this is used as the batch size used during inference, otherwise this depends on the</span>
<span class="sd">         `batch_size_inference` and `n_estimators`.</span>
<span class="sd">        unit (str): The unit to return the computation usage in.</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: The estimated computation usage in unit of choice.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">computation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate_model_usage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s2">&quot;computation&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">overwrite_params</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">unit</span> <span class="o">==</span> <span class="s2">&quot;s&quot;</span><span class="p">:</span>
        <span class="n">computation</span> <span class="o">=</span> <span class="n">computation</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_processor_speed</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2e11</span>
    <span class="k">return</span> <span class="n">computation</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>


</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/PriorLabs" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["search.suggest"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.8fd75fb4.min.js"></script>
      
    
  </body>
</html>