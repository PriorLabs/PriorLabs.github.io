1:"$Sreact.fragment"
2:I[5328,["362","static/chunks/30a37ab2-b2120806d300c7b3.js","711","static/chunks/8e1d74a4-8f885b40f4f28395.js","970","static/chunks/970-5107e36f7be1fbe6.js","338","static/chunks/338-6a73c8697ef0c4f9.js","173","static/chunks/173-0ecac2ca7c4dbe70.js","900","static/chunks/900-f146e2d73e185f03.js","177","static/chunks/app/layout-fa2754dec0e9f15c.js"],"SiteHeader"]
3:I[5244,[],""]
4:I[3866,[],""]
5:I[1794,["362","static/chunks/30a37ab2-b2120806d300c7b3.js","711","static/chunks/8e1d74a4-8f885b40f4f28395.js","970","static/chunks/970-5107e36f7be1fbe6.js","338","static/chunks/338-6a73c8697ef0c4f9.js","173","static/chunks/173-0ecac2ca7c4dbe70.js","900","static/chunks/900-f146e2d73e185f03.js","177","static/chunks/app/layout-fa2754dec0e9f15c.js"],"Footer"]
6:I[814,["362","static/chunks/30a37ab2-b2120806d300c7b3.js","711","static/chunks/8e1d74a4-8f885b40f4f28395.js","970","static/chunks/970-5107e36f7be1fbe6.js","338","static/chunks/338-6a73c8697ef0c4f9.js","173","static/chunks/173-0ecac2ca7c4dbe70.js","900","static/chunks/900-f146e2d73e185f03.js","177","static/chunks/app/layout-fa2754dec0e9f15c.js"],"Toaster"]
7:I[4396,["970","static/chunks/970-5107e36f7be1fbe6.js","22","static/chunks/22-a9af9ab3e41c946f.js","351","static/chunks/app/vision/page-e2f71450d3fe5dc6.js"],"BlogBackground"]
8:I[7970,["970","static/chunks/970-5107e36f7be1fbe6.js","22","static/chunks/22-a9af9ab3e41c946f.js","351","static/chunks/app/vision/page-e2f71450d3fe5dc6.js"],"Image"]
9:I[6213,[],"OutletBoundary"]
b:I[6213,[],"MetadataBoundary"]
d:I[6213,[],"ViewportBoundary"]
f:I[4835,[],""]
:HL["/_next/static/media/13971731025ec697-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/1a4aa50920b5315c-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/904be59b21bd51cb-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/a22b1dc24103c00d-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/c441a7a257a6e5bf-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/e807dee2426166ad-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/3085f553265f8f45.css","style"]
:HL["/_next/static/css/42a99f9c51cc0e39.css","style"]
:HL["/_next/static/css/abd3ac67bf108b8b.css","style"]
0:{"P":null,"b":"_BR2Vyd44iqEE9tOSlWuT","p":"","c":["","vision"],"i":false,"f":[[["",{"children":["vision",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/3085f553265f8f45.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/42a99f9c51cc0e39.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/abd3ac67bf108b8b.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"min-h-screen bg-background font-sans antialiased __className_2fad4c __variable_fca8ee __variable_4db51b __variable_e6621c __variable_1826d0 __variable_0afda3 __variable_cf91a9","children":["$","div",null,{"className":"relative flex min-h-screen flex-col","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L5",null,{}],["$","$L6",null,{}]]}]}]}]]}],{"children":["vision",["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","vision","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","main",null,{"className":"relative min-h-screen flex items-center justify-center py-12 px-2","children":[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://priorlabs.ai/vision\"},\"headline\":\"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision\",\"description\":\"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry.\",\"image\":\"https://priorlabs.ai/vision/title.png\",\"author\":[{\"@type\":\"Person\",\"name\":\"Frank Hutter\"},{\"@type\":\"Person\",\"name\":\"Noah Hollmann\"},{\"@type\":\"Person\",\"name\":\"Sauraj Gambhir\"}],\"publisher\":{\"@type\":\"Organization\",\"name\":\"Prior Labs\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https://priorlabs.ai/prior_labs_logo.svg\"}},\"datePublished\":\"2025-04-24\",\"dateModified\":\"2025-04-24\"}"}}],["$","$L7",null,{}],["$","article",null,{"className":"relative z-10 max-w-3xl w-full mx-auto px-4 py-10 font-dmsans text-lg leading-relaxed text-foreground text-justify","children":[["$","h1",null,{"className":"font-header text-4xl md:text-5xl font-bold mb-8 text-primary","children":"AI's Blind Spot: The Structured Data Challenge"}],["$","div",null,{"className":"w-full flex justify-center items-center py-4 mb-4","children":["$","div",null,{"className":"w-[80%] max-w-3xl overflow-hidden rounded-xl shadow-lg","style":{"height":"420px"},"children":["$","div",null,{"className":"relative h-[500px] w-full","style":{"top":"-20px","right":"-10px"},"children":["$","$L8",null,{"src":"/vision/title.png","alt":"Prior Labs Team Collage","fill":true,"className":"object-cover","priority":true}]}]}]}],["$","div",null,{"className":"mb-10","children":["$","div",null,{"className":"border-l-4 border-primary/50 pl-5 text-base leading-relaxed text-foreground/90","children":[["$","span",null,{"className":"font-bold","children":"TL;DR:"}]," Structured data is the language of measurement and decision-making, yet AI still treats it as an afterthought. At Prior Labs, we're building Multimodal Tabular Foundation Models (TFMs), starting with TabPFN, that understand tables natively—learning statistical reasoning directly from data. Our vision is broader: truly agentic AI systems capable of understanding high-level goals, fusing tables, language, and images to reason, integrate domain knowledge, infer causality, and adapt dynamically. This isn't just better analytics—it's a new foundation for discovery across science, medicine, and the global economy."]}]}],["$","div",null,{"className":"mt-12"}],["$","p",null,{"className":"mb-6","children":"While artificial intelligence masters language and vision, it remains surprisingly inept with structured data. This isn't niche data – structured tables are the language of measurement and empirical observation. AI now generates art and poems but struggles to natively comprehend the core operational data in spreadsheets and databases driving most critical decisions across medicine, finance, science and virtually all industries. This isn't just a gap; it's a massive bottleneck holding back progress."}],["$","p",null,{"className":"mb-6","children":["Imagine, instead, a future where AI doesn't just interact with tables through brittle tools, but ",["$","em",null,{"children":"understands"}]," them. A future where intelligent agents can instantly forecast market trends from financial logs, accelerate the discovery of life-saving drugs by interpreting clinical trial data, optimize global supply chains using real-time sensor readings, prevent billions of dollars in fraud by spotting anomalies in transactions, and personalize medicine based on genomic insights. This isn't merely about better analytics; it's about transforming how discovery happens, how businesses operate, and how we tackle grand challenges like cancer and climate change. It promises to reshape data science itself, from university curricula to organizational structures. At Prior Labs, we are building this future."]}],["$","h2",null,{"className":"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary","children":"Why Structured Data Remains AI's Unconquered Frontier"}],["$","p",null,{"className":"mb-6","children":["Today, we witness iterative cycles where domain specialists brief data scientists, who then wrestle with outdated models, aggregate findings, report back, and painstakingly refine questions or data inputs—a process ill-suited to the pace of modern discovery and business. While LLMs can ",["$","em",null,{"children":"call"}]," tools to interact with tables, they lack a deep, ",["$","em",null,{"children":"internal"}]," understanding of the data itself, inheriting the limitations of the tools they use."]}],["$","p",null,{"className":"mb-6","children":["But, why has structured data proven so resistant to the foundation model revolution? Tables are different: ",["$","a",null,{"href":"https://www.vanderschaar-lab.com/why-tabular-foundation-models-should-be-a-research-priority/","target":"_blank","rel":"noopener noreferrer","className":"text-primary underline","children":"link"}]]}],["$","ul",null,{"className":"list-disc pl-8 mb-6 space-y-2","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Data Accessibility Bias:"}]," AI's growth was fuelled by public text/images. Critical tabular data often remains private (spreadsheets rarely go viral), reducing public data for large model training."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Architectural Mismatch:"}]," Standard LLM models lack native mechanisms for tabular layouts and numerics. Their 1-dimensional sequential architecture is made to understand language not numbers. This is like grasping an image by hearing its pixels read aloud. We need AI designed ",["$","em",null,{"children":"specifically"}]," for data patterns."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Inherent Complexity:"}]," Tables combine diverse data types while often encoding highly complex domains (e.g., genomics, physics, finance). Interpreting this deep semantic and structural complexity challenges standard AI architectures."]}]]}],["$","h2",null,{"className":"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary","children":"Building Native Intelligence for Tables"}],["$","p",null,{"className":"mb-6","children":["Prior Labs is tackling this challenge by developing ",["$","strong",null,{"children":"Tabular Foundation Models (TFMs)"}],", marking a paradigm shift, away from training on specific downstream tasks to ",["$","em",null,{"children":"teaching the model statistical reasoning itself"}],"."]}],["$","p",null,{"className":"mb-6","children":["Our first major breakthrough, ",["$","strong",null,{"children":"TabPFN"}],", exemplifies this. TabPFN is a Transformer model, leveraging the compute and architectural power of the modern AI era, but pre-trained ",["$","em",null,{"children":"exclusively"}]," on millions of synthetic tabular datasets encompassing a vast diversity of underlying structures and patterns. This unique pre-training process imbues TabPFN with a rich statistical \"prior,\" allowing it to implicitly understand tabular data through a native architecture. It treats numbers as numbers, grasps 2D relationships, and avoids the information loss common with standard tokenization approaches."]}],["$","p",null,{"className":"mb-6","children":["TabPFN uses ",["$","strong",null,{"children":"In-Context Learning (ICL)"}],", processing new data examples at inference time for state-of-the-art predictions in seconds – zero-shot, without retraining or tuning. Validated in ",["$","em",null,{"children":"Nature Magazine"}],", its speed, accuracy, and remarkable generalization confirm the power of this approach. ",["$","a",null,{"href":"https://www.nature.com/articles/s41586-024-08328-6","target":"_blank","rel":"noopener noreferrer","className":"text-primary underline","children":"link"}]]}],["$","h2",null,{"className":"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary","children":"Multimodal Models for Truly Agentic Data Science"}],["$","p",null,{"className":"mb-6","children":"TabPFN is a crucial first step, but our ultimate vision extends far beyond specialized tabular models. We are building the next generation: Multimodal TFMs designed for inherent multimodal understanding."}],["$","p",null,{"className":"mb-6","children":["Imagine AI that doesn't just call tools, but ",["$","em",null,{"children":"natively fuses"}]," the statistical patterns in tables with the semantic context of language and the perceptual information from images, all within a single, unified architecture."]}],["$","p",null,{"className":"mb-6","children":"Such integrated models will power AI agents capable of:"}],["$","ul",null,{"className":"list-disc pl-8 mb-6 space-y-2","children":[["$","li",null,{"children":"Understanding high-level analytical goals expressed in natural language."}],["$","li",null,{"children":"Intelligently gathering, querying, and integrating data from diverse sources."}],["$","li",null,{"children":"Integrating common sense, users domain knowledge and additional information sources with statistical information to improve predictions."}],["$","li",null,{"children":"Engaging in dynamic dialogue to explore results, refine hypotheses, and surface insights invisible to human analysis alone."}]]}],["$","p",null,{"className":"mb-6","children":"Just as LLMs provided a foundational layer for language tasks, we envision TFMs becoming the core intelligence engine for reasoning over structured and multimodal data. They are designed to empower platforms like Snowflake, Databricks, SAP, and the broader ecosystem of companies building in the application layer by providing deep, native data understanding capabilities – the missing predictive and analytical intelligence layer needed to unlock the full potential of modern data infrastructure. This extends to robust outlier detection, accurate forecasting, high-fidelity synthetic data generation, and enabling analysis across entire heterogeneous databases."}],["$","h2",null,{"className":"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary","children":"Tackling the Hard Questions"}],["$","p",null,{"className":"mb-6","children":"Realizing this vision requires solving some of the most complex and fundamental challenges in AI, problems that have stumped the field for decades:"}],["$","ul",null,{"className":"list-disc pl-8 mb-6 space-y-2","children":[["$","li",null,{"children":[["$","strong",null,{"children":"Semantic Reasoning:"}]," Truly blending statistical power with contextual and domain-specific knowledge within a unified architecture."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Inferring Causality:"}]," Moving beyond correlation to identify the causal drivers."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Ensuring Trust:"}]," Making complex AI reasoning transparent, fair, interpretable, and dependable."]}]]}],["$","p",null,{"className":"mb-6","children":"These questions define the cutting edge of AI, and answering them is core to our mission. Led and advised by pioneers in AI, AutoML and causality including Frank Hutter and Bernhard Schölkopf, we aim to build the world's best team of researchers tackling these questions, driven by creating the best possible products, and aided by world class engineers without whom this wouldn't be possible."}],["$","h2",null,{"className":"font-header text-2xl md:text-3xl font-bold mt-12 mb-4 text-primary","children":"Building the Future & Ecosystem at Prior Labs"}],["$","p",null,{"className":"mb-6","children":["Join us to solve deep AI problems with global impact, transforming how entire industries make decisions. We seek passionate world-class researchers and engineers to join our collaborative team, pioneer solutions to these fundamental challenges with significant compute resources, and build systems that unlock understanding, ",["$","em",null,{"children":"using intelligence truly native to the data itself"}],"."]}],["$","p",null,{"className":"mb-6","children":["Recognizing that optimal performance often requires domain-specific knowledge, we will launch a dedicated ",["$","strong",null,{"children":"fine-tuning program"}]," in the coming days. This initiative will help organizations, particularly in complex fields like genomics, clinical trials, trading, and financial modeling, to adapt our models – more to follow soon!"]}],["$","p",null,{"className":"mb-6","children":"Looking ahead throughout the year, we plan several impactful releases. Key developments will include scaling our models to handle up to one million samples, substantially reducing inference times, doubling down on time series forecasting, and introducing relational understanding. We will also launch a dedicated open-source repository to foster education, research and experimentation, alongside releasing a series of agentic features aimed at automating complex data science processes."}],["$","p",null,{"className":"mb-6","children":"We believe that just as LLMs democratized interaction with language, TFMs will democratize deep data analysis and decision making. Let's build the future of structured data together."}],["$","div",null,{"className":"mt-10 text-right font-semibold text-base","children":"Frank, Noah & Sauraj — April 24th, 2025"}]]}]]}],null,["$","$L9",null,{"children":"$La"}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","QC1qQHT-aPLKYJ7wSt69a",{"children":[["$","$Lb",null,{"children":"$Lc"}],["$","$Ld",null,{"children":"$Le"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$f","$undefined"],"s":false,"S":true}
e:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1, maximum-scale=5"}],["$","meta","1",{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#ffffff"}],["$","meta","2",{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#000000"}]]
c:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision | Prior Labs"}],["$","meta","2",{"name":"description","content":"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry."}],["$","link","3",{"rel":"author","href":"https://priorlabs.ai"}],["$","meta","4",{"name":"author","content":"Prior Labs"}],["$","meta","5",{"name":"keywords","content":"TabPFN,Tabular Foundation Model,Structured Data AI,Prior Labs,Machine Learning,Data Science,AI Vision,Tabular Data,Foundation Models,Artificial Intelligence"}],["$","meta","6",{"name":"creator","content":"Prior Labs"}],["$","meta","7",{"name":"publisher","content":"Prior Labs"}],["$","meta","8",{"name":"robots","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","9",{"rel":"canonical","href":"https://priorlabs.ai/vision"}],["$","meta","10",{"name":"format-detection","content":"telephone=no, address=no, email=no"}],["$","meta","11",{"property":"og:title","content":"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision"}],["$","meta","12",{"property":"og:description","content":"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry."}],["$","meta","13",{"property":"og:url","content":"https://priorlabs.ai/vision"}],["$","meta","14",{"property":"og:site_name","content":"Prior Labs Vision"}],["$","meta","15",{"property":"og:image","content":"https://priorlabs.ai/prior_labs_logo.svg"}],["$","meta","16",{"property":"og:image:width","content":"1200"}],["$","meta","17",{"property":"og:image:height","content":"630"}],["$","meta","18",{"property":"og:image:alt","content":"Prior Labs Logo"}],["$","meta","19",{"property":"og:image:type","content":"image/svg+xml"}],["$","meta","20",{"property":"og:type","content":"article"}],["$","meta","21",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","22",{"name":"twitter:title","content":"AI's Blind Spot: The Structured Data Challenge | Prior Labs Vision"}],["$","meta","23",{"name":"twitter:description","content":"Explore why AI struggles with structured data and how Prior Labs is building Tabular Foundation Models (TFMs) to unlock breakthroughs for data science, medicine, and industry."}],["$","meta","24",{"name":"twitter:image","content":"https://priorlabs.ai/prior_labs_logo.svg"}],["$","link","25",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"256x256"}],["$","link","26",{"rel":"icon","href":"/icon.ico?addd072660dee037","type":"image/x-icon","sizes":"256x256"}]]
a:null
