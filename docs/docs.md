<style>
.prior-labs-hero {
  margin-top: -4rem;
}

/* Style for the top boxes */
.grid.cards.up > ul > li  {
  background-color: rgba(25, 36, 74, 0.03); /* Primary color with slight opacity */
}
</style>
# TabPFN Integrations

<div class="grid cards up" markdown>

-   :material-cloud-check:{ .lg .middle } **API Client**

    ---

    **Best models, No GPU needed.** The fastest way to get started with TabPFN. Access our models through the cloud without requiring local GPU resources.

    [:octicons-arrow-right-24: TabPFN Client](https://github.com/PriorLabs/tabpfn-client)

-   :material-language-python:{ .lg .middle } **Python Package**

    ---

    **Most popular.** Local installation for research and privacy sensitive use cases with GPU support and scikit-learn compatible interface.

    [:octicons-arrow-right-24: TabPFN Local](https://github.com/PriorLabs/tabpfn)

-   :material-application:{ .lg .middle } **User Interface**

    ---

    **No Code.** Visual interface for no-code interaction with TabPFN. Perfect for quick experimentation and visualization.

    [:octicons-arrow-right-24: Access GUI](https://ux.priorlabs.ai/)

-   :material-language-r:{ .lg .middle } **R Integration**

    ---

    Bringing TabPFN's capabilities to the R ecosystem for data scientists and researchers. We have an [experimental R package](https://github.com/PriorLabs/R-tabpfn) and an [alternative tutorial on usage in R](https://github.com/mthulin/TabPFN_in_R). Contributions welcome!

</div>

&nbsp;</br>
&nbsp;</br>
&nbsp;</br>

## Why TabPFN

<div class="grid cards second" markdown>

-   :material-speedometer:{ .lg .middle } **Rapid Training**

    ---

    TabPFN significantly reduces training time, outperforming traditional models tuned for hours in just a few seconds. For instance, it surpasses an ensemble of the strongest baselines in 2.8 seconds compared to 4 hours of tuning.

    [comment]: <> ([:octicons-arrow-right-24: Learn More](#))

-   :material-chart-line:{ .lg .middle } **Superior Accuracy**

    ---

    TabPFN consistently outperforms state-of-the-art methods like gradient-boosted decision trees (GBDTs) on datasets with up to 10,000 samples. It achieves higher accuracy and better performance metrics across a range of classification and regression tasks.

-   :material-shield-check:{ .lg .middle } **Robustness**

    ---

    The model demonstrates robustness to various dataset characteristics, including uninformative features, outliers, and missing values, maintaining high performance where other methods struggle.

-   :material-creation-outline:{ .lg .middle } **Generative Capabilities**

    ---

    As a generative transformer-based model, TabPFN can be fine-tuned for specific tasks, generate synthetic data, estimate densities, and learn reusable embeddings. This makes it versatile for various applications beyond standard prediction tasks.

-   :material-code-tags-check:{ .lg .middle } **Sklearn Interface**

    ---

    TabPFN follows the interfaces provided by scikit-learn, making it easy to integrate into existing workflows and utilize familiar functions for fitting, predicting, and evaluating models.

-   :material-file-excel-box:{ .lg .middle } **Minimal Preprocessing**

    ---

    The model handles various types of raw data, including missing values and categorical variables, with minimal preprocessing. This reduces the burden on users to perform extensive data preparation.

</div>
